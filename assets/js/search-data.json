{
  
    
        "post0": {
            "title": "実践機械学習勉強会 Part 5 決定木系モデル",
            "content": ". 1 &#27770;&#23450;&#26408;&#12398;&#12450;&#12523;&#12468;&#12522;&#12474;&#12512; . 決定木は、予測値の解釈性に優れている点で魅力的なモデルである。一連の質問に基づいて決断を下すという方法を繰り返すことでデータを分類する。 . Classificationには分類木、Regressionには回帰木が対応する。 . . . 1.1 &#24773;&#22577;&#21033;&#24471;&#12398;&#26368;&#22823;&#21270; . 質問によるデータの分割は、情報利得（information gain: 分割された集合の要素のばらつきの減少）が最大となる特徴量で分割する方法をとる。情報利得$IG$は以下のように定式化される。 . $$IG(D_p,f)=I(D_p)- sum^m_{j=1} frac{N_j}{N_p}I(D_j)$$ . $f$は分割を行う特徴量、$D_p$は親（分割前）のデータセット、$D_j$はj番目の子ノード（分割後）のデータセット、$I$は不純度（impurity: 異なるクラスのサンプルがノードにどの程度でまざっているか定量化する指標）、$N_p$は親ノードのサンプル数、$N_j$はj番目の子ノードのサンプル数をそれぞれ指す。式の通り、$IG$は子ノードの不純度が低いほど大きくなる。不純度指標をエントロピーとして、親ノードから3つ以上の子ノードを生み出すことを繰り返すアルゴリズムは&quot;C4.5&quot;と呼ばれることで有名である。上式はm個の子ノードに分割する一般的な式だが、組み合わせ探索空間を減らすため、ほとんどのライブラリは二分決定木を実装している。つまり、親ノード$D_p$から、子ノード$D_{left}$・$D_{right}$に分割される。よって式は以下のようになる。 $$IG(D_p,f)=I(D_p)- frac{N_{left}}{N_p}I(D_{left})- frac{N_{right}}{N_p}I(D_{right})$$ . 親ノードから左右２つの子ノードを生み出すことを繰り返すアルゴリズムは&quot;CART&quot;（Classfication And Regression Tree）と呼ばれることで有名である。 . CARTでは分類タスクの時、twoing crietionという情報利得について別のメソッドをオプションに持っていて、 $$IG(Dp,f)= frac{N_{left}}{N_p} frac{N_{right}}{N_p}( sum^c_{i=1}|p(i|D_{left})-p(i|D_{right})|)^2$$ . で規定される。 . Note: あらゆるライブラリで実装されているfeature_importance、つまり、特徴量$f$の重要度は何を示しているのかというと、特徴量$f$で分割することでどのくらい情報利得が生じたかを表している。 . #collapse-show import numpy as np # 一般的な２分岐を想定する def IG(impurity_func, target_p, target_left, target_right): N_left = len(target_left) N_right = len(target_right) N_p = len(target_p) I_p = impurity_func(target_p) I_left = impurity_func(target_left) I_right = impurity_func(target_right) return I_p - N_left / N_p * I_left - N_right / N_p * I_right def IG_twoing(target_left, target_right): N_left = len(target_left) N_right = len(target_right) N_p = N_left + N_right classes = np.unique(np.hstack([target_right,target_left])) I = 0 for i in classes: I += np.abs(len(target_left[target_left==i])/N_left - len(target_right[target_right==i])/N_right) I = N_left * N_right / N_p**2 * I**2 return I . . . 1.2 &#19981;&#32020;&#24230;&#12398;&#25351;&#27161; . 不純度（impurity）を表す指標は分類木では、ジニ不純度（Gini impurity）:$I_G$、、エントロピー（entropy）:$I_H$、分類誤差（classification error）:$I_E$の３つ、回帰木では平均2乗和誤差（MSE）が存在する。 . . 1.2.1 &#12472;&#12491;&#19981;&#32020;&#24230; . 誤分類の確率を最小化する条件と解釈できる指標である。定義は以下。 $$I_G(t)= sum^c_{i=1}p(i|t)(1-p(i|t))=1- sum^c_{i=1}p(i|t)^2$$ . 最大になるのはクラスが完全に混合されている時である。 . #collapse-show def gini(target): N = len(target) _, counts = np.unique(target,return_counts=True) p = counts / N return 1 - np.sum(p**2) . . . 1.2.2 &#12456;&#12531;&#12488;&#12525;&#12500;&#12540; . すべての空でないクラス$i$を対象にしたエントロピーの定義は以下のようになる。 $$I_H(t)=- sum^c_{i=1}p(i|t)log_2p(i|t)$$ . $p(i|t)$はノード$t$においてラベルがクラス$i$のサンプルの割合を指す。エントロピーは平均情報量ともいわれる。 . 「情報量（じょうほうりょう）やエントロピー（英: entropy）は、情報理論の概念で、あるできごと（事象）が起きた際、それがどれほど起こりにくいかを表す尺度である。ありふれたできごと（たとえば「風の音」）が起こったことを知ってもそれはたいした「情報」にはならないが、逆に珍しいできごと（たとえば「曲の演奏」）が起これば、それはより多くの「情報」を含んでいると考えられる。情報量はそのできごとが本質的にどの程度の情報を持つかの尺度であるとみなすこともできる。」(by wiki) . ここで、 事象$E$が起こる確率を$P(E)$とするとき、 事象 $E$ が起こったことを知らされたとき受け取る（選択）情報量$I(E)$ を $$I(E)= log frac {1}{P(E)}=- log P(E)$$ と定義される。よってエントロピーは有限集合中、起きうる全事象から受け取る情報量をそれぞれの事象が起きる確率で重みづけ平均した情報量であり、平均情報量と呼ばれる所以である。 . よって今回$I_H$は有限集合であるノード$t$から受け取ることのできる平均情報量を表しているのである。 . 2値分類の場合、$p(i=1|t)=1or0$でエントロピーは最小$0$になる。エントロピーが最大になるのはジニ不純度と同様にクラスが完全に混合されている場合、つまり$p(i=1|t)=0.5$の時である。 . #collapse-show def entropy(target): N = len(target) _, counts = np.unique(target,return_counts=True) p = counts / N return -np.sum(p*np.log2(p)) . . . 1.2.3 &#20998;&#39006;&#35492;&#24046; . 以下のように定義される。 $$I_E(t)=1-max(p(i|t))$$ . 多数派がどれだけ大多数か示すことで純度を測っている。 . #collapse-show def error(target): N = len(target) _, counts = np.unique(target,return_counts=True) p = counts / N return 1 - np.max(p) . . 以上3つの指標を比較してみよう。 . ここでは2値分類を例として考える。クラス（0, 1）に対して親ノードのサンプル数を（40, 40）とする。以下の2通りの分岐を考えてみる。 $$A: (40,40)--&gt;(30,10)(10,30)$$ $$B: (40,40)--&gt;(20,40)(20,0)$$ それぞれのケースで情報利得はどのような値をとるのだろうか？ . #collapse-show target_p = np.hstack([np.zeros(40),np.ones(40)]) target_la = np.hstack([np.zeros(30),np.ones(10)]) target_ra = np.hstack([np.zeros(10),np.ones(30)]) target_lb = np.hstack([np.zeros(20),np.ones(40)]) target_rb = np.hstack([np.zeros(20),np.ones(0)]) . . ジニ不純度の場合、 . #collapse-show IG_a = IG(gini,target_p,target_la,target_ra) IG_b = IG(gini,target_p,target_lb,target_rb) print(&quot;A: {}, B: {}&quot;.format(IG_a,IG_b)) . . A: 0.125, B: 0.16666666666666669 . となり、Bでの分割を優先することがわかる。実際問題そちらの方がより純粋である。 . エントロピーの場合、 . #collapse-show IG_a = IG(entropy,target_p,target_la,target_ra) IG_b = IG(entropy,target_p,target_lb,target_rb) print(&quot;A: {}, B: {}&quot;.format(IG_a,IG_b)) . . A: 0.1887218755408671, B: 0.31127812445913283 . となり、同様にBでの分割を優先することがわかる。このように、ジニ不純度とエントロピーは非常によく似た結果になることが知られていて、2択に時間をかける優先性はあまりない。 . 分類誤差の場合、 . #collapse-show IG_a = IG(error,target_p,target_la,target_ra) IG_b = IG(error,target_p,target_lb,target_rb) print(&quot;A: {}, B: {}&quot;.format(IG_a,IG_b)) . . A: 0.25, B: 0.25 . となり、AとBを同等に評価していることがわかる。このように分類誤差はノードのクラス確率変化にあまり敏感ではないので決定木の成長に適していない。一方、過学習を防ぐため、決定木の分岐の深さに制限を設ける剪定（prune）には役立つ。 . ちなみにtwoingはどうなるのか、 . #collapse-show IG_a = IG_twoing(target_la,target_ra) IG_b = IG_twoing(target_lb,target_rb) print(&quot;A: {}, B: {}&quot;.format(IG_a,IG_b)) . . A: 0.25, B: 0.33333333333333337 . なるほど、一応Bをうまいこと優先しているようだ。 . . 1.2.4 &#26368;&#23567;2&#20055;&#21644;&#35492;&#24046; . 回帰に決定木を使用するには、連続値変数に適した不純度指標が必要である。そこで、ノード$t$の不純度指標として代わりにこの指標が使われ、 $$I(t)=MSE(t)= frac{1}{N_t} sum_{i in D_t}(y^{(i)}- hat{y}_t)^2$$ $$ hat{y}_t= frac{1}{N_t} sum_{i in D_t}y^{(i)}$$ と定義される。ここで、$N_t$はノード$t$のサンプル数、$D_t$はノード$t$のサブセットインデックスの集合、$y^{(i)}$はラベル（真の目的値）、$ hat{y}_t$はサンプルの平均（予測された目的値）として扱う。 . 決定木回帰の文脈で、この指標はよく「分割後のノード分散」と呼ばれる。分割条件はこれにならってよく「分散減少」（variance reduction）と呼ばれる。 . #collapse-show def mse(target): return np.mean((target - np.mean(target))**2) . . . 2 &#27770;&#23450;&#26408;&#12398;&#23455;&#35013; . それでは単純な1本だけの決定木を実装してみよう。ここでは単純のため分類木に焦点をあてて実装してみる。（前に作った関数を流用したいのでクラス内メソッドに書き直しません、後決定木の図示はめんどいのでSklearnに任せます..） . . 2.1 &#26368;&#36969;&#12394;&#29305;&#24500;&#37327;&#12392;&#38334;&#20516;&#12434;&#36984;&#25246;&#12377;&#12427; . 親ノードから左右ノードへ分岐する際に情報利得が最も大きくなるように、分岐の基準とする特徴量とその閾値を求める。 . #collapse-show def search_best_split(impurity_func, data, target): features = data.shape[1] best_thrs = None best_f = None IG_max = 0 for feat_idx in range(features): values = data[:, feat_idx] for val in values: target_left = target[values &lt; val] target_right = target[values &gt;= val] ig = IG(impurity_func, target, target_left, target_right) if IG_max &lt; ig: # 情報利得の最大値を更新 IG_max = ig best_thrs = val best_f = feat_idx return IG_max, best_thrs, best_f . . 今回はSklearnのIrisデータをお試しに使う。まずはデータを読み込む。 . #collapse-show from sklearn.datasets import load_iris from sklearn.model_selection import train_test_split iris = load_iris() features_name = iris.feature_names data = iris.data target = iris.target X_train, X_test, y_train, y_test = train_test_split(data, target, test_size=0.3, random_state=0) . . 先ほどの関数を使ってみると、 . #collapse-show IG_max, best_thrs, best_f = search_best_split(gini, X_train, y_train) print(&#39;Information gain: {}, Best threshold: {}, Best feature: {}&#39;.format(IG_max, best_thrs, features_name[best_f])) . . Information gain: 0.3294995369039634, Best threshold: 3.0, Best feature: petal length (cm) . petal length (cm) 特徴量で閾値を3にした時に初めのベストな分割が行えるようだ。 . . 2.2 &#20877;&#24112;&#30340;&#12395;&#12494;&#12540;&#12489;&#20998;&#21106;&#12434;&#34892;&#12358; . ノードクラスをつくって、クラス内でsplitメソッドにより子ノードを再帰的に繰り返す。これは左右分割後に、それぞれに対応するノードクラスをleftとright変数に格納してあげることで達成できる。 . 具体的に、変数left.method_nameはleftに格納されたノードクラスのmethod_nameを呼び出していて、そのメソッドでさらにleftノードクラスのleftとrightに分割されたノードクラスが格納され、さらに格納されたノードクラスのmethod_nameが呼び出されるというように繰り返される。制限をつけないと無限ループするので、ストップする基準としてmax_depthに達するか、左右子ノードの不純度が０（クラスが1種類しか含まない）という条件を使うことにする。 . 結果として学習後にこのノードクラスが成長後のすべてのノードを蓄えていることになる。また、IG_maxを特徴量ごとに足し合わせれば各特徴量の重要度を計算できる。 . #collapse-show feature_importances = {} class Node: def __init__(self, data, target, max_depth, impurity): self.left = None self.right = None self.max_depth = max_depth self.depth = None self.data = data self.target = target self.threshold = None self.feature = None self.IG_max = None self.importance = {} self.label = np.argmax(np.bincount(target)) # ノード内で一番多いラベル（いわゆるそのノードでの予測値） self.impurity = impurity if self.impurity == &#39;gini&#39;: self.impurity_func = gini elif self.impurity == &#39;entropy&#39;: self.impurity_func = entropy elif self.impurity == &#39;error&#39;: self.impurity_func = error # 再帰的分割メソッド def split(self, depth): self.depth = depth self.IG_max, self.threshold, self.feature = search_best_split(self.impurity_func, self.data, self.target) print(&#39;Depth: {}, Sep at Feature: {},Threshold: {}, Label: {}&#39;.format(self.depth, self.feature, self.threshold, self.label)) # 各特徴量の重要度をグローバル変数に記録 global feature_importances if self.IG_max != 0: if self.feature not in feature_importances: feature_importances[self.feature] = self.IG_max else: feature_importances[self.feature] += self.IG_max # 剪定（prune)して無限ループを防ぐ if self.depth == self.max_depth or self.IG_max == self.impurity_func(self.target): return # 得られた特徴量と閾値にしたがてデータを2分割する idx_left = self.data[:, self.feature] &gt;= self.threshold idx_right = self.data[:, self.feature] &lt; self.threshold # 分割された左右ノードを対応する変数に格納し、再帰的に分割を行う self.left = Node(self.data[idx_left], self.target[idx_left], self.max_depth, self.impurity) self.right = Node(self.data[idx_right], self.target[idx_right], self.max_depth, self.impurity) self.left.split(self.depth +1) self.right.split(self.depth +1) # 渡されたデータを末端（葉）ノードに達するまで分岐にそって流して、行きついた先の対応するラベルを予測値として返す def predict(self, data): if self.IG_max == self.impurity_func(self.target) or self.depth == self.max_depth: return self.label else: if data[self.feature] &gt; self.threshold: return self.left.predict(data) else: return self.right.predict(data) . . . 2.3 All in one . 最後に決定木分類器クラスを作ってデータへの学習と予測メソッドを設定する . #collapse-show class DesicionTreeClassifier: def __init__(self, max_depth, impurity): self.max_depth = max_depth self.impurity = impurity self.tree = None # ルートノードから分割を繰り返し決定木を成長させる def fit(self, data, target): initial_depth = 0 self.tree = Node(data, target, self.max_depth, self.impurity) self.tree.split(initial_depth) # 成長した決定木でデータのラベルを予測する def predict(self, data): pred = [] for s in data: pred.append(self.tree.predict(s)) return np.array(pred) . . 最後にIrisデータセットで学習してみると、 . #collapse-show clf = DesicionTreeClassifier(3, &#39;gini&#39;) clf.fit(X_train, y_train) y_pred = clf.predict(X_test) score = sum(y_pred == y_test)/float(len(y_test)) print(&#39;Classification accuracy: {}&#39;.format(score)) . . Depth: 0, Sep at Feature: 2,Threshold: 3.0, Label: 2 Depth: 1, Sep at Feature: 2,Threshold: 5.0, Label: 2 Depth: 2, Sep at Feature: 2,Threshold: 5.1, Label: 2 Depth: 3, Sep at Feature: None,Threshold: None, Label: 2 Depth: 3, Sep at Feature: 0,Threshold: 6.7, Label: 2 Depth: 2, Sep at Feature: 3,Threshold: 1.7, Label: 1 Depth: 3, Sep at Feature: 1,Threshold: 3.2, Label: 2 Depth: 3, Sep at Feature: None,Threshold: None, Label: 1 Depth: 1, Sep at Feature: None,Threshold: None, Label: 0 Classification accuracy: 0.9777777777777777 . のようになり、テストデータに対し98%程の正解率をだしており上手いこと成長しているのがわかる。また、左側のノードは深さが３まで、右側のノードは深さが１で止まっていることがわかる。各特徴量の重要度も求められていて、 . #collapse-show import matplotlib.pyplot as plt %matplotlib inline keys = [features_name[i] for i in feature_importances.keys()] values = list(feature_importances.values()) plt.figure(figsize=(10,7)) plt.title(&#39;Feature importances&#39;, fontsize=15) plt.bar(keys, values) plt.show() . . のように図示される。petal length (cm)、つまり花びらの長さが一番分類に寄与していることがわかる。 . sklearnと比較してみると、 . #collapse-show from sklearn.tree import DecisionTreeClassifier as DecisionTreeClassifier2 clf2 = DecisionTreeClassifier2(max_depth=3) clf2.fit(X_train,y_train) y_pred = clf2.predict(X_test) score = sum(y_pred == y_test)/float(len(y_test)) print(&#39;Classification accuracy: {}&#39;.format(score)) . . Classification accuracy: 0.9777777777777777 . となり、同様の精度まで決定木が成長していることがわかる。 . またSkleanのライブラリでは決定木の可視化ツールも用意していて以下のように使える。 . #collapse-show import graphviz from sklearn.tree import export_graphviz dot_data = export_graphviz( clf2, class_names=iris.target_names, feature_names=features_name, filled=True, rounded=True, out_file=None ) graph = graphviz.Source(dot_data) graph.render(&quot;iris-tree&quot;, format=&quot;png&quot;) . . &#39;iris-tree.png&#39; . #collapse-show from IPython.display import Image,display_png display_png(Image(&#39;iris-tree.png&#39;)) . . 決定木は半エキスパートシステムみたいなもので、この図のように最適化された質問分岐を表示してくれたり、解釈性に非常に優れている。 . Refrences . Python Machine Learning, 2nd Edition | http://darden.hatenablog.com/entry/2016/12/15/222447#%E5%86%8D%E5%B8%B0%E5%91%BC%E3%81%B3%E5%87%BA%E3%81%97 | http://hktech.hatenablog.com/entry/2018/10/05/004235 | https://techblog.nhn-techorus.com/archives/14801 | https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.GradientBoostingClassifier.html | https://en.wikipedia.org/wiki/Gradient_boosting | https://qiita.com/Quasi-quant2010/items/10f7ad4ed2e11004990f | https://zaburo-ch.github.io/post/xgboost/ | https://www.st-hakky-blog.com/entry/2017/08/07/163216 | https://ja.wikipedia.org/wiki/%E6%B1%BA%E5%AE%9A%E6%9C%A8 | https://ja.wikipedia.org/wiki/%E6%83%85%E5%A0%B1%E9%87%8F | ftp://ftp.boulder.ibm.com/software/analytics/spss/support/Stats/Docs/Statistics/Algorithms/14.0/TREE-CART.pdf | Bishop Pattern Recognition And Machine Learning 14.4 Tree-based Models p665 | .",
            "url": "https://vintea01.github.io/tpt-medical-it/%E5%AE%9F%E8%B7%B5%E6%A9%9F%E6%A2%B0%E5%AD%A6%E7%BF%92/2020/06/09/ML_part5.html",
            "relUrl": "/%E5%AE%9F%E8%B7%B5%E6%A9%9F%E6%A2%B0%E5%AD%A6%E7%BF%92/2020/06/09/ML_part5.html",
            "date": " • Jun 9, 2020"
        }
        
    
  
    
        ,"post1": {
            "title": "ベイズ勉強会 Part 8 ポアソン混合モデル",
            "content": "ベイズ勉強会資料は『ベイズ推論による機械学習入門』1を元に、途中式計算をできるだけ省略せずに行ったものです。 . 今回は4.1~4.3の内容を扱います。 . ※2020/06/03追記: 趣旨とは外れますが、Distributions.jlのより高度な機能を用いた効率的な実装をご紹介いただきました。ありがとうございました。 . #Julia言語 理解するためにコードを書くときにはライブラリの機能をあえて使わないようにすることが基本なのですが、Distributions.jl で混合分布をMixtureModelで作れることを知っているとforループの部分を1行に短縮できます。https://t.co/M0W6xf5lzzhttps://t.co/cNt6lkYGNm pic.twitter.com/yG7tQIjpSF . &mdash; 黒木玄 Gen Kuroki (@genkuroki) June 3, 2020 . # 使うパッケージ using Distributions using StatsBase using LinearAlgebra using SpecialFunctions ENV[&quot;GKS_ENCODING&quot;]=&quot;utf8&quot; # Plot内でunicode使うためのおまじない using Plots using StatsPlots using Flux: onehot . &#30331;&#22580;&#12377;&#12427;&#30906;&#29575;&#20998;&#24067;(&#20877;&#25522;) . &#12459;&#12486;&#12468;&#12522;&#20998;&#24067; . カテゴリ分布は次のような確率質量関数を分布関数にもつ確率分布である。 . $$ Cat({ bf s}|{ bf pi}) = Pi_{k=1}^{K} pi_k^{s_k} $$${ bf s}$はK次元ベクトルで、該当カテゴリのみを1,それ以外を0で表したものである(1 of K 表現)。例えば、サイコロの目を確率変数とすれば$s = 5$と書く代わりに、${ bf s} = (0,0,0,0,1,0)^ mathrm{T}$と書く。パラメータ${ bf pi} = ( pi_1, dots, pi_K)^ mathrm{T}$は各カテゴリに配される確率を表したものであり、$ pi_k in (0,1)$かつ$ Sigma_{k=1}^{K} pi_k = 1$を満たす。 . 対数をとると . $$ ln Cat({ bf s}|{ bf pi}) = Sigma_{k=1}^{K} s_k ln pi_k $$となる。 . &#12487;&#12451;&#12522;&#12463;&#12524;&#20998;&#24067; . 尤度関数にカテゴリ分布をとった場合、パラメータ${ bf pi}$の事前分布は、$ pi_k in (0,1)$かつ$ Sigma_{k=1}^{K} pi_k = 1$を満たすK次元ベクトルを出力する必要がある。このような分布として、ディリクレ分布がある。ディリクレ分布の分布関数は次のようになる。 . $$ Dir({ bf pi}|{ bf alpha}) = C_D ({ bf alpha}) Pi_{k=1}^{K} pi_k^{ alpha_k - 1} $$ディリクレ分布のパラメータ${ bf alpha} = ( alpha_1, dots, alpha_K)^ mathrm{T}$の要素$ alpha_k$は正の実数である。正規化係数は . $$ C_D ({ bf alpha}) = frac{ Gamma ( Sigma_{k=1}^{K} alpha_k)}{ Pi_{k=1}^{K} Gamma ( alpha_k)} $$である。 . 対数をとると . $$ ln Dir({ bf pi}|{ bf alpha}) = Sigma_{k=1}^{K} ( alpha_k - 1) ln pi_k + ln C_D ({ bf alpha}) $$となる。 . &#12509;&#12450;&#12477;&#12531;&#20998;&#24067; . ポアソン分布は次のような確率密度関数を分布関数にもつ確率分布である。 . $$ mathrm{Poi} (x| lambda) = frac{ lambda^x}{x!} mathrm{e}^{- lambda} $$xは非負の整数、パラメータ$ lambda$は正の実数である。 . 対数をとると . $$ ln mathrm{Poi} (x| lambda) = x ln lambda - ln x! - lambda $$である。 . &#12460;&#12531;&#12510;&#20998;&#24067; . ポアソン分布のパラメータ$ lambda$は正の実数であるので、事前分布$p( lambda)$はガンマ分布で表すと都合が良い。ガンマ分布は次のような確率密度関数を分布関数にもつ確率分布である。 . $$ mathrm{Gam}( lambda|a,b) = C_G(a,b) lambda^{a-1} mathrm{e}^{-b lambda} $$正規化係数$C_G(a,b)$は次のような関数である。 . $$ C_G(a,b) = frac{b^a}{ Gamma(a)} $$ガンマ分布の対数をとると . $$ ln mathrm{Gam}( lambda|a,b) = (a-1) ln lambda - b lambda + ln C_G(a,b) $$である。 . &#12514;&#12487;&#12523;&#27083;&#31689; . これまでは次のような1峰性の分布の密度推定をするモデルを扱ってきた。 . $$ begin{eqnarray} p({ bf X}, lambda) &amp;=&amp; p({ bf X}| lambda)p( lambda) ただし　p({ bf X}) &amp;=&amp; Pi_{n=1}^{N} mathrm{Poi}(x_n| lambda) p( lambda) &amp;=&amp; mathrm{Gam}( lambda|a,b) end{eqnarray} $$ # ポアソン分布による密度推定用のモデル mutable struct PoisModel a::Float64 b::Float64 end . # 事前予測分布を計算する関数 function predict(model::PoisModel) r = model.a p = 1 / (model.b + 1) predict_dist = NegativeBinomial(r, p) return predict_dist end . predict (generic function with 1 method) . # ハイパーパラメータの値を変えても、1峰性であることは変わらない p1 = bar(predict(PoisModel(1,1))) p2 = bar(predict(PoisModel(5,4))) p3 = bar(predict(PoisModel(10,10))) plot(p1,p2,p3,layout=(1,3)) . このモデルには次のような多峰性の分布を持つデータを表現することができないという欠点がある。 . # λ=5とλ=20のポアソン分布から半々の確率で生成したデータ点 Ys = [] for i in 1:10000 K = rand(Categorical([0.5,0.5])) λ = ifelse(K==1,5,20) Y = rand(Poisson(λ)) push!(Ys,Y) end histogram(Ys) . そこで、「データを複数のクラスタ(集団)に分けることができ、クラスタごとに異なるポアソン分布から生成されている」という仮定をおいてみることにする。これはカテゴリ分布とポアソン分布を組み合わせることで実現できる。 . モデルにおけるN個のデータ点${ bf X} = { x_1, dots,x_N }$の生成過程を記述すると次(参考資料より引用1)のようになる。クラスタ数Kは既知とする。 . それぞれのクラスタの混合比率${ bf pi} = ( pi_1, dots, pi_K)^ mathrm{T}$が事前分布$p({ bf pi})$から生成される（ただし$ pi_k in (0,1)$かつ$ Sigma_{k=1}^{K} pi_k=1$）。 | それぞれのクラスタ$k=1, dots,K$に対する観測モデルのパラメータ$ theta_k$（平均や分散）が事前分布$p( theta_k)$から生成される。 | $n=1, dots,N$に関して、$x_n$に対するクラスタの割当$s_n$が比率${ bf pi}$によって選ばれる。 | $n=1, dots,N$に関して、$s_n$によって選択されたk番目の確率分布$p(x_n| theta_k)$からデータ点$x_n$が生成される。 | この生成過程を同時分布の形で書くと次のようになる。$s_n$を1 of K表現で表し、${ bf S} = { s_1, dots,s_N }$とする。 . $$ begin{eqnarray} p({ bf X},{ bf S},{ bf lambda},{ bf pi}) &amp;=&amp; p({ bf X}|{ bf S},{ bf lambda})p({ bf S}|{ bf pi})p({ bf lambda})p({ bf pi}) &amp;=&amp; { Pi_{n=1}^{N} p(x_n|s_n,{ bf lambda})p(s_n|{ bf pi}) } { Pi_{k=1}^{K} p( lambda_k) } p({ bf pi}) ただし　p({ bf pi}) &amp;=&amp; mathrm{Dir}({ bf pi}|{ bf alpha}) p( lambda_k) &amp;=&amp; mathrm{Gam}( lambda_k|a,b) p(x_n|s_n,{ bf lambda}) &amp;=&amp; Pi_{k=1}^{K} mathrm{Poi}(x_n| lambda_k)^{s_{n,k} } end{eqnarray} $$このようにモデルの生成過程に対する仮定を元に記述したモデルを生成モデルと呼ぶ。また、直接観測されることのないカテゴリ変数$s_n$を隠れ変数または潜在変数と呼ぶ。 . 以下ではこのモデルの出力がどのようになるかをハイパーパラメータを変えてシミュレーションしている。 . # カテゴリ数を3とする λs = rand.([Gamma(1,1), Gamma(5,5), Gamma(10,10)]) pi = rand(Dirichlet([0.01,0.19,0.80])) Ys = [] for i in 1:10000 s = rand(Categorical(pi)) λ = λs[s] Y = rand(Poisson(λ)) push!(Ys,Y) end density(Ys) . # カテゴリ数を3とする λs = rand.([Gamma(1,1), Gamma(2,3), Gamma(10,10)]) pi = rand(Dirichlet([0.25,0.20,0.55])) Ys = [] for i in 1:10000 s = rand(Categorical(pi)) λ = λs[s] Y = rand(Poisson(λ)) push!(Ys,Y) end density(Ys) . # カテゴリ数を3とする λs = rand.([Gamma(1,1), Gamma(5,1), Gamma(10,1)]) pi = rand(Dirichlet([0.33,0.34,0.33])) Ys = [] for i in 1:10000 s = rand(Categorical(pi)) λ = λs[s] Y = rand(Poisson(λ)) push!(Ys,Y) end density(Ys) . ハイパーパラメータの値を適当に変えることで、多彩な表現ができることがわかる。 . &#20107;&#24460;&#20998;&#24067;&#12398;&#25512;&#35542;&#12395;&#36817;&#20284;&#25512;&#35542;&#12364;&#24517;&#35201;&#12394;&#29702;&#30001; . 同時分布の形で書いているので、事後分布は観測された変数${ bf X}$の分布で割れば求まる。 . $$ p({ bf S},{ bf lambda},{ bf pi}|{ bf X}) = frac{p({ bf X},{ bf S},{ bf lambda},{ bf pi})}{p({ bf X})} $$しかしこれを計算することは現実的には困難であることが知られている。分母の$p({ bf X})$を計算しようとすると、 . $$ begin{eqnarray} p({ bf X}) &amp;=&amp; Sigma_{S} int int p({ bf X},{ bf S},{ bf lambda},{ bf pi}) d { bf lambda} d { bf pi} &amp;=&amp; Sigma_{S} p({ bf X},{ bf S}) end{eqnarray} $$を解くことになるが、共役事前分布を使うことによりパラメータ${ bf lambda},{ bf pi}$については解析的に積分除去可能になるが、$p({ bf X},{ bf S})$を${ bf S}$のとりうる全ての組み合わせについて計算する必要がある。N個の要素がK個のクラスタに分類されるので$K^N$回計算する必要があり、現実的に不可能な計算量になってしまう。そこでMCMC,変分推論といった近似推論手法を用いる必要がある。 . &#12462;&#12502;&#12473;&#12469;&#12531;&#12503;&#12522;&#12531;&#12464; . 上でも行っているように、確率分布の特徴は実際にサンプルすることでわかってくる。MCMC法の1種であるギブスサンプリングでは、モデルが複雑なため同時にサンプルすることが難しい各確率変数を、順番にサンプルしていく。 . 例えば、確率分布$p(z_1,z_2,z_3)$があったときに、一度に$z_1^{(i)},z_2^{(i)},z_3^{(i)} sim p$とするのは困難であるとする。そのとき、i個目の各変数を次のように順番にサンプルしていくことを考える。 . $$ begin{eqnarray} z_1^{(i)} &amp; sim&amp; p(z_1|z_2^{(i-1)},z_3^{(i-1)}) z_2^{(i)} &amp; sim&amp; p(z_2|z_1^{(i)}, z_3^{(i-1)}) z_3^{(i)} &amp; sim&amp; p(z_3|z_1^{(i)}, z_2^{(i)}) end{eqnarray} $$1個前の値を使うことで分布を条件づけし簡単な確率分布を得るというアイデアである。$z_1^{1}$をサンプルするために$z_2^{0}, z_3^{0}$は何らかのランダムな初期値を与えてやるのが一般的である。 . &#12509;&#12450;&#12477;&#12531;&#28151;&#21512;&#12514;&#12487;&#12523;&#12398;&#12462;&#12502;&#12473;&#12469;&#12531;&#12503;&#12522;&#12531;&#12464; . データ${ bf X}$が観測された後の条件つき分布は . $$ p({ bf S},{ bf lambda},{ bf pi}|{ bf X}) $$となる。この分布は複雑であるため直接${ bf S},{ bf lambda},{ bf pi}$をサンプルすることは難しい。混合分布の場合は潜在変数とパラメータを分けてサンプルすると十分に簡単な確率分布が得られることが知られているので、以下の戦略で各確率変数をサンプルしていく。 . $$ begin{eqnarray} { bf S} &amp; sim&amp; p({ bf S}|{ bf X},{ bf lambda},{ bf pi}) { bf lambda}, { bf pi} &amp; sim&amp; p({ bf lambda},{ bf pi}|{ bf X},{ bf S}) end{eqnarray} $$&#28508;&#22312;&#22793;&#25968;${ bf S}$&#12434;&#12469;&#12531;&#12503;&#12523;&#12377;&#12427;&#20998;&#24067; . まず潜在変数${ bf S}$をサンプルするための条件付き分布を求める。ここでは、パラメータ${ bf lambda}, { bf pi}$も与えられていると考える。 . $$ begin{eqnarray} p({ bf S}|{ bf X},{ bf lambda},{ bf pi}) &amp; propto&amp; p({ bf S},{ bf lambda},{ bf pi}|{ bf X})　(分母は{ bf S}に関わらない) &amp; propto&amp; p({ bf X}|{ bf S},{ bf lambda})p({ bf S}|{ bf pi})　(p({ bf lambda}),p({ bf pi})は{ bf S}に関わらない) &amp;=&amp; Pi_{n=1}^{N} p(x_n|s_n,{ bf lambda})p(s_n|{ bf pi}) end{eqnarray} $$結果、$p({ bf S}|{ bf X},{ bf lambda},{ bf pi})$は各$s_1, dots,s_N$の分布の積に比例する、つまり条件付き独立な分布に分解できることがわかる。 . 具体的に、$s_n$をサンプルするための確率分布を計算してみる。指数部分の計算になるので対数をとる。 . $$ begin{eqnarray} ln p(x_n|s_n,{ bf lambda}) &amp;=&amp; Sigma_{k=1}^{K} s_{n,k} ln mathrm{Poi}(x_n| lambda_k) &amp;=&amp; Sigma_{k=1}^{K} s_{n,k} (x_n ln lambda_k - lambda_k) + const. end{eqnarray} $$また、 . $$ begin{eqnarray} ln p(s_n|{ bf pi}) &amp;=&amp; ln mathrm{Cat}(s_n|{ bf pi}) &amp;=&amp; Sigma_{k=1}^{K} s_{n,k} ln pi_k end{eqnarray} $$ゆえ . $$ ln p(x_n|s_n,{ bf lambda})p(s_n|{ bf pi}) = Sigma_{k=1}^{K} s_{n,k} (x_n ln lambda_k - lambda_k + ln pi_k) + const. $$ここで、$ Sigma_{k=1}^{K} s_{n,k} = 1$という制約があるのでこれはカテゴリ分布に対数をとった形として見ることができる。よって簡略化のため新しいパラメータ変数$ eta_{n}$を用意すると次のようにまとめられる。 . $$ begin{eqnarray} s_n &amp; sim&amp; mathrm{Cat}(s_n| eta_n) ただし　 eta_{n,k} &amp; propto&amp; mathrm{exp} { x_n ln lambda_k - lambda_k + ln pi_k }　( s.t. Sigma_{k=1}^{K} eta_{n,k} = 1 ) end{eqnarray} $$このように各nで$ eta_{n,k}$を計算することにより$s_n$をカテゴリ分布からサンプルできる。 . &#12497;&#12521;&#12513;&#12540;&#12479;${ bf lambda},{ bf pi}$&#12434;&#12469;&#12531;&#12503;&#12523;&#12377;&#12427;&#20998;&#24067; . 今度は潜在変数${ bf S}$を観測された値のように扱う。 . $$ begin{eqnarray} p({ bf lambda},{ bf pi}|{ bf X},{ bf S}) &amp; propto&amp; p({ bf S},{ bf lambda},{ bf pi}|{ bf X}) &amp;=&amp; p({ bf X}|{ bf S},{ bf lambda})p({ bf S}|{ bf pi})p({ lambda})p({ bf pi}) end{eqnarray} $$このとき、${ bf lambda},{ bf pi}$に関する項は別々に分解できている。${ bf X}, { bf S}$が与えられた条件下では独立となっているということである。 . まず${ bf lambda}$の分布を計算する。対数をとって . $$ begin{eqnarray} ln p({ bf X}|{ bf S},{ bf lambda}) &amp;=&amp; Sigma_{n=1}^{N} Sigma_{k=1}^{K} s_{n,k} ln mathrm{Poi}(x_n| lambda_k) + Sigma_{k=1}^{K} ln mathrm{Gam} ( lambda_k|a,b) &amp;=&amp; Sigma_{k=1}^{K} left { ( Sigma_{n=1}^{N} s_{n,k} x_n + a - 1) ln lambda_k - ( Sigma_{n=1}^{N} s_{n,k} + b) lambda_k right } + const. end{eqnarray} $$これは独立したK個のガンマ分布の積に対数をとった形であり、$ lambda_k$は次のガンマ分布からサンプルされる。 . $$ begin{eqnarray} lambda_k &amp; sim&amp; mathrm{Gam}( lambda_k| hat{a}_k, hat{b}_k) ただし　 hat{a}_k &amp;=&amp; Sigma_{n=1}^{N} s_{n,k} x_n + a hat{b}_k &amp;=&amp; Sigma_{n=1}^{N} s_{n,k} + b end{eqnarray} $$次に、${ bf pi}$の分布を計算する。対数をとって . $$ begin{eqnarray} ln p({ bf S}|{ bf pi})p({ bf pi}) &amp;=&amp; Sigma_{n=1}^{N} ln mathrm{Cat}(s_n|{ bf pi}) &amp;=&amp; Sigma_{k=1}^{K} ( Sigma_{n=1}^{N} s_{n,k} + alpha_k - 1) ln pi_k + const. end{eqnarray} $$となり、${ bf pi}$は次のディリクレ分布からサンプルできる。 . $$ begin{eqnarray} { bf pi} &amp; sim&amp; mathrm{Dir}({ bf pi}| hat{ bf alpha}) ただし　 hat{ alpha}_k &amp;=&amp; Sigma_{n=1}^{N} s_{n,k} + alpha_k end{eqnarray} $$&#12414;&#12392;&#12417; . 結局、ポアソン混合モデルのためのギブスサンプリングのアルゴリズムは次のようになる。 . . Important: ポアソン混合モデルのためのギブスサンプリングアルゴリズム . パラメータのサンプル${ bf lambda},{ bf pi}$に初期値を設定 . for $i = 1, dots, mathrm{MAXITER}$ do . 　for n = $1, dots,N$ do 　　$s_n$をサンプル . 　end for . 　for k = $1, dots,K$ do . 　　$ lambda_k$をサンプル . 　end for 　${ bf pi}$をサンプル . end for . なおサンプルするごとに学習が進んでいくが、初期値によって異なる値にたどり着くことがあるので、複数の初期値からサンプルして結果の収束を見る必要がある。 . Julia&#12395;&#12424;&#12427;&#23455;&#35013; . 以上をJuliaにより実装する。 . # データ点作成 # λ=5とλ=20のポアソン分布から7:3の確率で生成したデータ点 X = [] for i in 1:100 K = rand(Categorical([0.7,0.3])) λ = ifelse(K==1,5,20) x = rand(Poisson(λ)) push!(X,x) end p_ans = density(X, title=&quot;answer&quot;) plot(p_ans) . # ギブスサンプリングを実行 # chain数は4とする N = length(X) K = 2 n_chain = 4 S_mcmc = [] lambda_mcmc = [] pi_mcmc = [] for i in 1:n_chain a = [1.,1.] b = [1.,1.] alpha = [1/2,1/2] # 初期値をチェインごとにランダムに作る lambda = abs.(rand(MultivariateNormal([1.,1.],I(2)))) pi = rand(Dirichlet([1/2,1/2])) S_chain = [] lambda_chain = [] pi_chain = [] @time for i in 1:2000 S = [] for n in 1:N eta_n = exp.(X[n] .* log.(lambda) .- lambda .+ log.(pi)) eta_n = eta_n ./ sum(eta_n) # 合計が1になるように合計値で割る s_n = rand(Categorical(eta_n)) s_n = onehot(s_n, [1,2]) push!(S, s_n) end a = sum(S.*X) .+ a b = sum(S) .+ b lambda = rand.(Gamma.(a,1 ./ b)) alpha = sum(S) .+ alpha pi = rand(Dirichlet(alpha)) push!(S_chain, S) push!(lambda_chain, lambda) push!(pi_chain, pi) end push!(S_mcmc, S_chain) push!(lambda_mcmc, lambda_chain) push!(pi_mcmc, pi_chain) end . 3.091110 seconds (7.41 M allocations: 333.948 MiB, 5.10% gc time) 1.767400 seconds (5.26 M allocations: 227.237 MiB, 5.01% gc time) 1.825786 seconds (5.26 M allocations: 227.237 MiB, 11.16% gc time) 1.546258 seconds (5.26 M allocations: 227.237 MiB, 11.65% gc time) . # クラスタ1に対するlambda plot(1:2000,[l[1] for l in lambda_mcmc[1]]) plot!(1:2000,[l[1] for l in lambda_mcmc[2]]) plot!(1:2000,[l[1] for l in lambda_mcmc[3]]) plot!(1:2000,[l[1] for l in lambda_mcmc[4]]) . # クラスタ2に対するlambda plot(1:2000,[l[2] for l in lambda_mcmc[1]]) plot!(1:2000,[l[2] for l in lambda_mcmc[2]]) plot!(1:2000,[l[2] for l in lambda_mcmc[3]]) plot!(1:2000,[l[2] for l in lambda_mcmc[4]]) . # クラスタ1に割り振られる確率 plot(1:2000,[p[1] for p in pi_mcmc[1]]) plot!(1:2000,[p[1] for p in pi_mcmc[2]]) plot!(1:2000,[p[1] for p in pi_mcmc[3]]) plot!(1:2000,[p[1] for p in pi_mcmc[4]]) . クラスタの順番が逆になっているだけで、収束はしている。 . チェイン1のサンプルを使って予測分布を書いてみる。収束する前のサンプルは使えないので1001以降のものを使う。 . xs = [] for i in 1001:2000 pi = pi_mcmc[1][i] lambda = ifelse(rand(Categorical(pi))==1,lambda_mcmc[1][i][1],lambda_mcmc[1][i][2]) x = rand(Poisson(lambda)) push!(xs, x) end p_pred = density(xs, title=&quot;pred&quot;) plot(p_pred, p_ans, layout=(1,2)) . &#22793;&#20998;&#25512;&#35542; . MCMCとならぶベイズ推論の近似手法が変分推論である。これは「モデルの確率分布が複雑ならより簡単な近似分布で表そう」という考え方によるものである。もちろん元の分布に近い方が良く、元の分布と近似分布の「似ている度」をKLダイバージェンスで評価することで、良い近似分布を導出する作業は次のように定式化できる。 . $$ q_ mathrm{opt.} (z_1,z_2,z_3) = mathrm{argmin}_{q} mathrm{KL} [q(z1,z2,z3)||p(z1,z2,z3)] $$ . Important: 確率分布$p(x)$に対する関数$f(x)$の期待値 $$ langle f(x) rangle_{p(x)} = int f(x)p(x) dx$$ . . Important: KLダイバージェンス $$ begin{eqnarray} mathrm{KL}[q(x)||p(x)] &amp;=&amp; - int q(x) ln frac{p(x)}{q(x)} dx &amp;=&amp; langle ln q(x) rangle_{q(x)} - langle ln p(x) rangle_{q(x)} end{eqnarray}$$ . . Tip: STEINS;GATEで世界線同士の相対的な近さをダイバージェンス(世界線変動率)って呼んでましたね。変分推論も世界線の旅と考えたらオカリンの気分を味わえて面白いかも。 . この最適化問題を制約なしに解いても元の分布$p(z_1,z_2,z_3)$が最適ということになり何も解決しないのでいくつかの制約を置くことになる。典型的なものが平均場近似と呼ばれる、各変数を独立とみなす仮定をおいた変分推論である。 . $$ p(z_1,z_2,z_3) approx q(z_1)q(z_2)q(z_3) $$平均場近似の場合の最適化問題を解いていく。平均場近似でもMCMCと似たように、変数の分布を1つずつ最適化していく。そこで、$q(z_2),q(z_3)$を固定して$q(z_1)$を最適化する。以下の式では期待値計算を$ langle dot rangle_{q(z_1),q(z_2),q(z_3)} = langle dot rangle_{1,2,3}$と簡略化して書く。 . $$ begin{eqnarray} mathrm{KL}[q(z_1)q(z_2)q(z_3)||p(z_1,z_2,z_3)] &amp;=&amp; - langle ln frac{p(z_1,z_2,z_3)}{q(z_1)q(z_2)q(z_3)} rangle_{1,2,3} &amp;=&amp; - langle langle ln frac{p(z_1,z_2,z_3}{q(z_1)q(z_2)q(z_3)} rangle_{2,3} rangle_{1} &amp;=&amp; - langle langle ln p(z_1,z_2,z_3) rangle_{2,3} - langle q(z_1) rangle_{2,3} - langle q(z_2) rangle_{2,3} - langle q(z_3) rangle_{2,3} rangle_{1}　(期待値の線形性) &amp;=&amp; - langle langle ln p(z_1,z_2,z_3) rangle_{2,3} - q(z_1) rangle_{1} + const. &amp;=&amp; - langle ln frac{ exp { langle ln p(z_1,z_2,z_3) rangle_{2,3} } }{q(z_1)} rangle_{1} + const.　( expでくくり lnでまとめる) &amp;=&amp; mathrm{KL} [q(z_1)|| exp { { langle ln p(z_1,z_2,z_3) rangle_{2,3} } ] + const. end{eqnarray} $$これで$q(z_1)$だけをくくり出せたので、最適な$q(z_1)$は . $$ ln q(z_1) = langle ln p(z_1,z_2,z_3) rangle_{2,3} + const. $$という等式で得られる。$q(z_2),q(z_3)$でも全く同じ議論ができ、平均場近似による変分推論のアルゴリズムは次のようになる。 . . Important: 平均場近似による変分推論のアルゴリズム(3変数) . $q(z_2),q(z_3)$を初期化 . for $i=1, dots, mathrm{MAXITER}$ do . 　$ ln q(z_1) = langle ln p(z_1,z_2,z_3) rangle_{2,3} + const.$ . 　$ ln q(z_2) = langle ln p(z_1,z_2,z_3) rangle_{1,3} + const.$ . 　$ ln q(z_3) = langle ln p(z_1,z_2,z_3) rangle_{1,2} + const.$ . end for . 現実的な想定として、観測データ$ mathcal{D}$が与えられた確率モデル$p( mathcal{D},z_1, dots,z_M)$の事後分布に対する近似公式を作ると次のようになる。なお未観測変数$z_1, dots,z_M$から$z_i$を除いた集合を${ bf Z}_{ verb| | i}$と表す . . Important: 事後分布に対する近似公式 $$ begin{eqnarray} ln q(z_i) &amp;=&amp; langle ln p(z_1, dots,z_M| mathcal{D}) rangle_{q({ bf Z}_{ verb| | i} ) }+const. &amp;=&amp; langle ln p( mathcal{D},z_1, dots,z_M) rangle_{q({ bf Z}_{ verb| | i} ) } + const. end{eqnarray}$$ . &#12509;&#12450;&#12477;&#12531;&#28151;&#21512;&#12514;&#12487;&#12523;&#12398;&#22793;&#20998;&#25512;&#35542; . ギブスサンプリングと同じように、変分推論でも潜在変数とパラメータを分けることでうまくいくことが知られている。次のように事後分布を近似する。 . $$ p({ bf S},{ bf lambda},{ bf pi}|{ bf X}) approx q({ bf S})q({ bf lambda},{ bf pi}) $$このように潜在変数とパラメータを分けて近似する変分推論手法を変分ベイズEMアルゴリズムと呼ぶ場合がある。最尤推定におけるEMアルゴリズムと似ているためである。 . &#28508;&#22312;&#22793;&#25968;${ bf S}$&#12398;&#36817;&#20284;&#20107;&#24460;&#20998;&#24067; . 事後分布に対する近似公式に当てはめると$q({ bf S})$は . $$ begin{eqnarray} ln q({ bf S}) &amp;=&amp; langle ln p({ bf X},{ bf S},{ bf lambda},{ bf pi}) rangle_{q({ bf lambda},{ bf pi})} + const. &amp;=&amp; langle p({ bf X}|{ bf S},{ bf lambda}) rangle_{q({ bf lambda})} + langle ln p({ bf S}|{ bf pi}) rangle_{q({ bf pi})} + const. &amp;=&amp; Sigma_{n=1}^{N} left { langle ln p(x_n|s_n,{ bf lambda}) rangle_{q({ bf lambda})} + langle ln p(s_n|{ bf pi}) rangle_{q({ bf pi})} right } + const. end{eqnarray} $$と、N個の独立な分布$q(s_n)$に分解されることがわかる。それぞれの期待値の項は . $$ begin{eqnarray} langle ln p(x_n|s_n,{ bf lambda}) rangle_{q({ bf lambda})} &amp;=&amp; Sigma_{k=1}^{K} langle s_{n,k} ln mathrm{Poi}(x_n| lambda_k) rangle_{q( lambda_k)} &amp;=&amp; Sigma_{k=1}^{K} s_{n,k} (x_n langle ln lambda_k rangle - langle lambda_k rangle) + const. end{eqnarray} $$および . $$ begin{eqnarray} langle ln p(s_n|{ bf pi}) rangle_{q({ bf pi})} &amp;=&amp; langle ln mathrm{Cat}(s_n|{ bf pi}) rangle_{q({ bf pi})} &amp;=&amp; Sigma_{k=1}^{K} s_{n,k} langle ln pi_k rangle end{eqnarray} $$であり、ギブスサンプリングの時と同様の議論により近似分布$q(s_n)$は次のようなカテゴリ分布となることがわかる。 . $$ begin{eqnarray} q(s_n) &amp;=&amp; mathrm{Cat} (s_n| eta_n) ただし　 eta_{n,k} &amp; propto&amp; exp { x_n langle ln lambda_k rangle - langle lambda_k rangle + langle ln pi_k rangle }　( s.t. Sigma_{k=1}^{K} eta_{n,k} = 1 ) end{eqnarray} $$${ bf lambda},{ bf pi}$に関する期待値計算は、$q({ bf lambda}),q({ bf pi})$の形式が明らかにならないとできないので後回しとする。 . &#12497;&#12521;&#12513;&#12540;&#12479;${ bf lambda},{ bf pi}$&#12398;&#36817;&#20284;&#20107;&#24460;&#20998;&#24067; . ここでも公式を用いると . $$ begin{eqnarray} ln q({ bf lambda},{ bf pi}) &amp;=&amp; langle ln p({ bf X},{ bf S},{ bf lambda},{ bf pi}) rangle_{q({ bf S})} + const. &amp;=&amp; langle ln p({ bf X}|{ bf S},{ bf lambda}) rangle_{q({ bf S})} + ln p({ bf lambda}) + langle ln p({ bf S}|{ bf pi}) rangle_{q({ bf S})} + ln p({ bf pi}) + const. end{eqnarray} $$と、$q({ bf lambda},{ bf pi}) = q({ bf lambda})q({ bf pi})$と分解できることがわかる。 . はじめに${ bf lambda}$に関係する項のみを取り出して計算すると . $$ begin{eqnarray} ln q({ bf lambda}) &amp;=&amp; Sigma_{n=1}^{N} langle Sigma_{k=1}^{K} s_{n,k} ln mathrm{Poi}(x_n| lambda_k) rangle_{q(s_n)} + Sigma_{k=1}^{K} ln mathrm{Gam} ( lambda_k|a,b) + const. &amp;=&amp; Sigma_{k=1}^{K} left { ( Sigma_{n=1}^{N} langle s_{n,k} rangle x_n + a - 1) ln lambda_k - ( Sigma_{n=1}^{N} langle s_{n,k} rangle + b) lambda_k right } + const. end{eqnarray} $$となり、$q({ bf lambda})$はK個の独立なガンマ分布に分けられる。 . $$ begin{eqnarray} q( lambda_k) &amp;=&amp; mathrm{Gam}( lambda_k| hat{ alpha}_k, hat{b}_k) ただし　 hat{a}_k &amp;=&amp; Sigma_{n=1}^{N} langle s_{n,k} rangle x_n + a hat{b}_k &amp;=&amp; Sigma_{n=1}^{N} langle s_{n,k} rangle + b end{eqnarray} $$次に、${ bf pi}$に関係する項のみで計算すると . $$ begin{eqnarray} ln q({ bf pi}) &amp;=&amp; Sigma_{n=1}^{N} langle ln mathrm{Cat}(s_n|{ bf pi}) rangle_{q(s_n)} + ln mathrm{Dir}({ bf pi}|{ bf alpha}) + const. &amp;=&amp; Sigma_{k=1}^{K}( Sigma_{n=1}^{N} langle s_{n,k} rangle + alpha_k - 1) ln pi_k + const. end{eqnarray} $$となり、次のようなディリクレ分布が得られる。 . $$ begin{eqnarray} q({ bf pi}) &amp;=&amp; mathrm{Dir}({ bf pi}| hat{ bf alpha}) ただし　 hat{ alpha}_k &amp;=&amp; Sigma_{k=1}^{N} langle s_{n,k} rangle + alpha_k end{eqnarray} $$結局潜在変数もパラメータも事前分布と近似事後分布が同じ種類になる。 . &#24517;&#35201;&#12394;&#26399;&#24453;&#20516;&#12398;&#35336;&#31639; . $ psi( dot)$をディガンマ関数とする。 . $s_{n}$はカテゴリ分布$q(s_n)$に従うので、そのk番目の期待値は . $$ langle s_{n,k} rangle = eta_{n,k}$$ . となる。 . ${ bf lambda}$はガンマ分布の積$ Pi_{k=1}^{K} q( lambda_k)$に従い、${ bf pi}$はディリクレ分布$q( hat{ bf alpha})$に従うので . $$ begin{eqnarray} langle lambda_k rangle &amp;=&amp; frac{ hat{a}_k}{ hat{b}_k} langle ln lambda_k rangle &amp;=&amp; psi ( hat{a}_k) - ln hat{b}_k langle ln pi_k rangle &amp;=&amp; psi ( hat{ alpha}_k) - psi( Sigma_{i=1}^{K} hat{ alpha}_k) end{eqnarray} $$以上の値を用いれば、変分ベイズEMアルゴリズムが分布のパラメータを更新していくことだけで実装できる。 . Julia&#12395;&#12424;&#12427;&#23455;&#35013; . ポアソン混合モデルに対する変分ベイズEMアルゴリズムをJuliaで実装する。 . # ハイパーパラメータを所持する型 mutable struct variationalBayesPoisson K::Int eta::Array a::Array{Float64,1} b::Array{Float64,1} alpha::Array{Float64,1} end . # 初期化関数 function init(model::variationalBayesPoisson, K) model.K = K model.eta = [] model.a = ones(K) model.b = ones(K) model.alpha = rand(Dirichlet([1/k for k in 1:K])) return model end . init (generic function with 1 method) . # 学習関数 function fit(model::variationalBayesPoisson, X) N = length(X) K = model.K for i in 1:2000 model.eta = [] for n in 1:N eta_n = [] for k in 1:K eta_nk = exp(X[n] * (digamma(model.a[k]) - log(model.b[k])) - (model.a[k]/model.b[k]) + digamma(model.alpha[k]) - digamma(sum(model.alpha))) push!(eta_n,eta_nk) end eta_n = eta_n ./ sum(eta_n) push!(model.eta, eta_n) end for k in 1:K model.a[k] = sum([model.eta[n][k] * X[n] for n in 1:N]) + model.a[k] model.b[k] = sum([model.eta[n][k] for n in 1:N]) + model.b[k] model.alpha[k] = sum([model.eta[n][k] for n in 1:N]) + model.alpha[k] end end return model end . fit (generic function with 1 method) . # 予測関数 function predict(model::variationalBayesPoisson) pi = rand(Dirichlet(model.alpha)) s = rand(Categorical(pi)) lambda = rand(Gamma(model.a[s],1/model.b[s])) x = rand(Poisson(lambda)) return x end . predict (generic function with 2 methods) . # クラスタリング関数 function cluster(model::variationalBayesPoisson, x) eta_new = [] for k in 1:model.K eta_k = exp(x * (digamma(model.a[k]) - log(model.b[k])) - (model.a[k]/model.b[k]) + (digamma(model.alpha[k]) - digamma(sum(model.alpha)))) push!(eta_new,eta_k) end eta_new = eta_new ./ sum(eta_new) return eta_new[1] end . cluster (generic function with 1 method) . # データ点作成 # λ=5とλ=20のポアソン分布から7:3の確率で生成したデータ点 X = [] for i in 1:100 K = rand(Categorical([0.7,0.3])) λ = ifelse(K==1,5,20) x = rand(Poisson(λ)) push!(X,x) end p_ans = density(X, title=&quot;answer&quot;) plot(p_ans) . model = variationalBayesPoisson(1,[],[1],[1],[1]) model = init(model, 2) . variationalBayesPoisson(2, Any[], [1.0, 1.0], [1.0, 1.0], [0.2585926034694314, 0.7414073965305685]) . # 学習前にプロット xs = [predict(model) for i in 1:1000] density(xs) . # 学習前にクラスタリング bar(X,[cluster(model, X[n]) for n in 1:length(X)]) . @time model = fit(model, X) . 1.414560 seconds (8.37 M allocations: 198.056 MiB, 7.92% gc time) . variationalBayesPoisson(2, Any[[0.9999885201496728, 1.1479850327202337e-5], [0.9998493669281563, 0.00015063307184371146], [0.9994545297488561, 0.0005454702511439849], [0.004685216875871678, 0.9953147831241284], [0.9999885201496728, 1.1479850327202337e-5], [2.082738302914923e-6, 0.9999979172616971], [0.9140823403565977, 0.08591765964340221], [0.9994545297488561, 0.0005454702511439849], [0.9747099182871993, 0.025290081712800738], [0.9998493669281563, 0.00015063307184371146] … [0.9994545297488561, 0.0005454702511439849], [0.9999885201496728, 1.1479850327202337e-5], [0.9999968310341244, 3.16896587556309e-6], [0.9998493669281563, 0.00015063307184371146], [0.004685216875871678, 0.9953147831241284], [0.9928886326538802, 0.007111367346119797], [0.7459893089600897, 0.25401069103991036], [0.9998493669281563, 0.00015063307184371146], [0.9999991252251544, 8.747748456785259e-7], [0.7459893089600897, 0.25401069103991036]], [700181.8135939713, 1.0818201864060282e6], [140204.69022420832, 59797.309775791844], [140203.94881681178, 59797.05118318838]) . # 学習後の予測 xs = [predict(model) for i in 1:1000] p_pred = density(xs, title=&quot;pred&quot;) plot(p_pred,p_ans, layout=(1,2)) . # 学習後のクラスタリング bar(X, [cluster(model, X[n]) for n in 1:length(X)]) . &#23849;&#22730;&#22411;&#12462;&#12502;&#12473;&#12469;&#12531;&#12503;&#12522;&#12531;&#12464; . 崩壊型ギブスサンプリングは一旦飛ばします。 . 1. 須山敦志. 杉山将. ベイズ推論による機械学習入門. 講談社, 2017.↩ .",
            "url": "https://vintea01.github.io/tpt-medical-it/bayes/2020/05/31/bayes_part8.html",
            "relUrl": "/bayes/2020/05/31/bayes_part8.html",
            "date": " • May 31, 2020"
        }
        
    
  
    
        ,"post2": {
            "title": "ベイズ勉強会 Part 7 ポアソン分布",
            "content": "ベイズ勉強会資料は『ベイズ推論による機械学習入門』1を元に、途中式計算をできるだけ省略せずに行ったものです。 . &#12509;&#12450;&#12477;&#12531;&#20998;&#24067; . ポアソン分布は次のような確率密度関数を分布関数にもつ確率分布である。 . $$ mathrm{Poi} (x| lambda) = frac{ lambda^x}{x!} mathrm{e}^{- lambda} $$xは非負の整数、パラメータ$ lambda$は正の実数である。 . 対数をとると . $$ ln mathrm{Poi} (x| lambda) = x ln lambda - ln x! - lambda $$である。 . &#12460;&#12531;&#12510;&#20998;&#24067; . ポアソン分布のパラメータ$ lambda$は正の実数であるので、事前分布$p( lambda)$はガンマ分布で表すと都合が良い。ガンマ分布は次のような確率密度関数を分布関数にもつ確率分布である。 . $$ mathrm{Gam}( lambda|a,b) = C_G(a,b) lambda^{a-1} mathrm{e}^{-b lambda} $$正規化係数$C_G(a,b)$は次のような関数である。 . $$ C_G(a,b) = frac{b^a}{ Gamma(a)} $$ガンマ分布の対数をとると . $$ ln mathrm{Gam}( lambda|a,b) = (a-1) ln lambda - b lambda + ln C_G(a,b) $$である。 . &#12514;&#12487;&#12523;&#27083;&#31689; . ある池で1時間釣りをした時に釣れる魚の数をベイズ推論で予測してみる。1時間の釣りをN回試した時の釣れた魚の数を${ bf X} = {x_1, dots,x_N}$とすると、予測のためのモデルは次のように書ける。 . $$ begin{eqnarray} p({ bf X}, lambda) &amp;=&amp; p({ bf X}| lambda)p( lambda) p({ bf X}| lambda) &amp;=&amp; Pi_{n=1}^N mathrm{Poi}(x_n| lambda) p( lambda) &amp;=&amp; mathrm{Gam}( lambda|a,b) end{eqnarray} $$事前分布のパラメータ$a,b$はハイパーパラメータとなる。 . &#20107;&#24460;&#20998;&#24067;&#12398;&#25512;&#35542; . 事後分布$p( lambda|{ bf X})$は同時分布を観測されたデータ${ bf X}$の確率分布で割れば求まる。ただし${ bf X}$は$ lambda$を含んでおらず対数をとることにより定数項として扱える。 . $$ begin{eqnarray} ln p( lambda|{ bf X}) &amp;=&amp; ln p({ bf X}| lambda)p( lambda) + const. &amp;=&amp; ln Pi_{n=1}^N mathrm{Poi}(x_n| lambda) + ln mathrm{Gam}( lambda|a,b) + const. &amp;=&amp; Sigma_{n=1}^N { x_n ln lambda - ln x_n ! - lambda } + (a-1) ln lambda - b lambda + ln C_G(a,b) + cosnt. &amp;=&amp; ( Sigma_{n=1}^N x_n + a - 1) ln lambda - (N + b) lambda + const. end{eqnarray} $$これはガンマ分布の対数をとった形である。よって事後分布は次のように表せる。 . $$ begin{eqnarray} p( lambda|{ bf X}) &amp;=&amp; mathrm{Gam}( hat{a}, hat{b}) ただし　 hat{a} &amp;=&amp; Sigma_{n=1}^N x_n + a hat{b} &amp;=&amp; N + b end{eqnarray} $$ &#20104;&#28204;&#20998;&#24067;&#12398;&#23566;&#20986; . パラメータ$ lambda$の事前分布と事後分布の形状が同じポアソン分布となるので、事前分布を用いて事前予測分布を求めた後、学習済みのハイパーパラメータを代入して学習済み予測分布を求める。未観測の変数$x_*$は観測${ bf X}$と同じ分布から独立に生成されるとして、予測分布$p(x_*)$は次のように求まる。 . $$ begin{eqnarray} p(x_*) &amp;=&amp; int p(x_*| lambda)p( lambda)d lambda &amp;=&amp; int mathrm{Poi}(x_*| lambda) mathrm{Gam}( lambda|a,b)d lambda &amp;=&amp; int frac{ lambda^{x_*} }{x_* !} mathrm{e}^{- lambda} C_G(a,b) lambda^{a-1} mathrm{e}^{-b lambda} d lambda &amp;=&amp; frac{C_G(a,b)}{x_* !} int lambda^{x_* + a - 1} mathrm{e}^{-(1+b) lambda} d lambda &amp;=&amp; frac{C_G(a,b)}{x_* ! C_G(x_* + a, 1+b)}　(ガンマ分布の定義式より積分部分はガンマ分布の正規化係数の形で表せる) &amp;=&amp; frac{b^a Gamma(x_* + a)}{x_* ! Gamma(a) (1+b)^{x_* + a} } &amp;=&amp; frac{ Gamma(x_* + a)}{x_* ! Gamma(a)} ( frac{b}{1+b})^{a} ( frac{1}{1+b})^{x_*} end{eqnarray} $$$r = a, p = frac{1}{b+1}$とおくと、 . $$ p(x_*) = frac{ Gamma(x_* + r)}{x_* ! Gamma(r)} (1-p)^r p^{x_*} $$となり、これは負の二項分布(negative binomial distribution)の形である。よって$p(x_*)$は次のように表せる。 . $$ begin{eqnarray} p(x_*) &amp;=&amp; mathrm{NB}(x_*|r,p) &amp;=&amp; frac{ Gamma(x_* + r)}{x_* ! Gamma(r)} (1-p)^r p^{x_*} ただし　r &amp;=&amp; a p &amp;=&amp; frac{1}{b+1} end{eqnarray} $$$a,b$を$ hat{a}, hat{b}$に置き換えれば学習後の予測分布が求まる。 . 1. 須山敦志. 杉山将. ベイズ推論による機械学習入門. 講談社, 2017.↩ .",
            "url": "https://vintea01.github.io/tpt-medical-it/bayes/2020/05/24/bayes_part7.html",
            "relUrl": "/bayes/2020/05/24/bayes_part7.html",
            "date": " • May 24, 2020"
        }
        
    
  
    
        ,"post3": {
            "title": "ベイズ勉強会 Part 6 カテゴリ分布",
            "content": "ベイズ勉強会資料は『ベイズ推論による機械学習入門』1を元に、途中式計算をできるだけ省略せずに行ったものです。 . &#12459;&#12486;&#12468;&#12522;&#20998;&#24067; . カテゴリ分布は次のような確率質量関数を分布関数にもつ確率分布である。 . $$ Cat({ bf s}|{ bf pi}) = Pi_{k=1}^{K} pi_k^{s_k} $$${ bf s}$はK次元ベクトルで、該当カテゴリのみを1,それ以外を0で表したものである(1 of K 表現)。例えば、サイコロの目を確率変数とすれば$s = 5$と書く代わりに、${ bf s} = (0,0,0,0,1,0)^ mathrm{T}$と書く。パラメータ${ bf pi} = ( pi_1, dots, pi_K)^ mathrm{T}$は各カテゴリに配される確率を表したものであり、$ pi_k in (0,1)$かつ$ Sigma_{k=1}^{K} pi_k = 1$を満たす。 . 対数をとると . $$ ln Cat({ bf s}|{ bf pi}) = Sigma_{k=1}^{K} s_k ln pi_k $$となる。 . &#12487;&#12451;&#12522;&#12463;&#12524;&#20998;&#24067; . 尤度関数にカテゴリ分布をとった場合、パラメータ${ bf pi}$の事前分布は、$ pi_k in (0,1)$かつ$ Sigma_{k=1}^{K} pi_k = 1$を満たすK次元ベクトルを出力する必要がある。このような分布として、ディリクレ分布がある。ディリクレ分布の分布関数は次のようになる。 . $$ Dir({ bf pi}|{ bf alpha}) = C_D ({ bf alpha}) Pi_{k=1}^{K} pi_k^{ alpha_k - 1} $$ディリクレ分布のパラメータ${ bf alpha} = ( alpha_1, dots, alpha_K)^ mathrm{T}$の要素$ alpha_k$は正の実数である。正規化係数は . $$ C_D ({ bf alpha}) = frac{ Gamma ( Sigma_{k=1}^{K} alpha_k)}{ Pi_{k=1}^{K} Gamma ( alpha_k)} $$である。 . 対数をとると . $$ ln Dir({ bf pi}|{ bf alpha}) = Sigma_{k=1}^{K} ( alpha_k - 1) ln pi_k + ln C_D ({ bf alpha}) $$となる。 . &#12514;&#12487;&#12523;&#27083;&#31689; . サイコロの各目が出る確率をベイズ推論で求めてみる。そのためのモデルは次のように書ける。 . $$ begin{eqnarray} p({ bf S}, { bf pi}) &amp;=&amp; p({ bf S}|{ bf pi})p({ bf pi}) ただし　p({ bf S}|{ bf pi}) &amp;=&amp; Pi_{n=1}^{N} Cat({ bf s}_n|{ bf pi}) p({ bf pi}) &amp;=&amp; Dir({ bf pi}|{ bf alpha}) end{eqnarray} $$観測されたデータを${ bf S} = { { bf s}_1, dots, { bf s}_N }$とする。事前分布のパラメータ${ bf alpha}$はハイパーパラメータとなる。 . &#20107;&#24460;&#20998;&#24067;&#12398;&#25512;&#35542; . 事後分布$p({ bf pi}|{ bf S})$は同時分布を観測されたデータ${ bf S}$の確率分布で割れば求まる。ただし${ bf S}$は${ bf pi}$を含んでおらず対数をとることにより定数項として扱える。 . $$ begin{eqnarray} ln p({ bf pi}|{ bf S}) &amp;=&amp; Sigma_{n=1}^{N} ln Cat({ bf s}_n | { bf pi}) + ln Dir({ bf pi}|{ bf alpha}) + const. &amp;=&amp; Sigma_{n=1}^{N} Sigma_{k=1}^{K} s_{n,k} ln pi_k + Sigma_{k=1}^{K} ( alpha_k - 1) ln pi_k + ln C_D ({ bf alpha}) + const. &amp;=&amp; Sigma_{k=1}^{K} ( Sigma_{n=1}^{N} s_{n,k} + alpha_k - 1) ln pi_k + const. end{eqnarray} $$これはディリクレ分布の対数をとった形である。よって事後分布は次のように表せる。 . $$ begin{eqnarray} p({ bf pi}|{ bf S}) &amp;=&amp; Dir({ bf pi} | hat{ bf alpha}) ただし　 hat{ bf alpha}_k &amp;=&amp; Sigma_{n=1}^{N} s_{n,k} + alpha_k　 mathrm{for}　k = 1, dots,K end{eqnarray} $$ &#20104;&#28204;&#20998;&#24067;&#12398;&#23566;&#20986; . パラメータ${ bf pi}$の事前分布と事後分布の形状が同じディリクレ分布となるので、事前分布を用いて事前予測分布を求めた後、学習済みのハイパーパラメータを代入して学習済み予測分布を求める。未観測のカテゴリ変数${ bf s}_*$(1 of K表現)は観測${ bf S}$と同じ分布から独立に生成されるとして、予測分布$p({ bf s}_*)$は次のように求まる。 . $$ begin{eqnarray} p({ bf s}_*) &amp;=&amp; int p({ bf s}_*|{ bf pi}) p({ bf pi}) d { bf pi} &amp;=&amp; int Cat({ bf s}_* | { bf pi}) Dir({ bf pi} | { bf alpha}) d { bf pi} &amp;=&amp; C_D ({ bf alpha}) int Pi_{k=1}^{K} pi_k^{s_{*,k} } pi_k^{ alpha_k -1} d { bf pi} &amp;=&amp; C_D ({ bf alpha}) int Pi_{k=1}^{K} pi_k^{s_{*,k} + alpha_k - 1 } d { bf pi} &amp;=&amp; frac{C_D ({ bf alpha}) }{C_D ((s_{*,k} + alpha_k)_{k=1}^{K})}　(ディリクレ分布の正規化係数を省いた形を積分すれば、正規化係数の逆数になるはず) &amp;=&amp; frac{ Gamma( Sigma_{k=1}^{K} alpha_k) Pi_{k=1}^{K} Gamma (s_{*,k} + alpha_k)}{ Pi_{k=1}^{K} Gamma ( alpha_k) Gamma( Sigma_{k=1}^{K} (s_{*,k}+ alpha_k))} end{eqnarray} $$${ bf s}_*$の実現値を代入することで簡単にできる。ある$k&#39;$に対して$s_{*,k&#39;}=1$となる場合を考えると、 . $$ begin{eqnarray} p(s_{*,k&#39;} = 1) &amp;=&amp; frac{ Gamma( Sigma_{k=1}^{K} alpha_k) Gamma (1 + alpha_{k&#39;})}{ Gamma ( alpha_{k&#39;}) Gamma(1 + Sigma_{k=1}^{K} alpha_k)} &amp;=&amp; frac{ alpha_{k&#39;} }{ Sigma_{k=1}^{K} alpha_k}　(ガンマ関数と階乗の関係を利用) end{eqnarray} $$これはカテゴリ分布にまとめることができて、 . $$ begin{eqnarray} p({ bf s}_*) = Cat({ bf s}_* | left( frac{ alpha_k}{ Sigma_{i=1}^{K} alpha_i} right)_{k=1}^{K} ) end{eqnarray} $$何をしているかというと、ハイパーパラメータ${ bf alpha}$の各成分を正規化しただけである。 . これを$ hat{ bf alpha}$に置き換えれば学習後の予測分布が求まる。 . 1. 須山敦志. 杉山将. ベイズ推論による機械学習入門. 講談社, 2017.↩ .",
            "url": "https://vintea01.github.io/tpt-medical-it/bayes/2020/05/17/bayes_part6.html",
            "relUrl": "/bayes/2020/05/17/bayes_part6.html",
            "date": " • May 17, 2020"
        }
        
    
  
    
        ,"post4": {
            "title": "ベイズ勉強会 Part 5 線形モデル",
            "content": "ベイズ勉強会資料は『ベイズ推論による機械学習入門』1を元に、途中式計算をできるだけ省略せずに行ったものです。 . 実数の出力値$y_n$を、入力値${ bf x}_n$の関数で表す。 . &#12514;&#12487;&#12523;&#12398;&#27083;&#31689; . &#12514;&#12487;&#12523;&#12398;&#20363; . 出力値$y_n in mathbb{R}$を、入力値${ bf x}_n in mathbb{R}^M$, パラメータ${ bf w} in mathbb{R}^M$, ノイズ成分$ epsilon_n in mathbb{R}$を使って次のモデル式で表してみる。 . $$ y_n = { bf w}^ mathrm{T} { bf x}_n + epsilon_n $$ノイズ成分$ epsilon_n$が平均ゼロのガウス分布に従っていると仮定し、次のように表す。 . $$ epsilon_n sim mathcal{N}( epsilon_n | 0, lambda^{-1}) $$ここで$ lambda in mathbb{R}$は1次元ガウス分布の既知の精度パラメータとする。以上の2式はまとめて書くこともできて、 . $$ p(y_n | { bf x}_n, { bf w}) = mathcal{N}(y_n | { bf w}^ mathrm{T} { bf x}_n, lambda^{-1}) $$となる。 . さらに学習のためにパラメータ${ bf w}$の事前分布を設定する。ベクトルを出力したいので多次元ガウス分布とすると、 . $$ p({ bf w}) = mathcal{N}({ bf w}|{ bf m}, { bf Lambda}^{-1}) $$と書ける。${ bf m}$は平均パラメータ、${ bf Lambda}$は精度行列パラメータである。 . 複数のデータ点をまとめたものを${ bf Y}= { y_1, dots,y_N }, { bf X= { { bf x}_1, dots, { bf x}_N }}$とすれば . $$ p({ bf Y}|{ bf w}, { bf X}) = Pi_{n=1}^{N} p (y_n | { bf x}_n, { bf w}) $$と書ける。 . モデルを同時分布で書くと . $$ p({ bf Y}, { bf X}, { bf w}) = p({ bf w}) Pi_{n=1}^{N} p (y_n | { bf x}_n, { bf w})p({ bf x}_n) $$${ bf X}$に条件づけられた${ bf Y},{ bf w}$の同時分布で表してもよい。 . $$ p({ bf Y}, { bf w}|{ bf X}) = p({ bf w}) Pi_{n=1}^{N} p (y_n | { bf x}_n, { bf w}) $$&#12514;&#12487;&#12523;&#12398;&#24615;&#36074;&#12398;&#30906;&#35469; . 事前分布の値を適当に設定すれば、パラメータ${ bf w}$をサンプリングできる。今回は${ bf x}_n$を$ {1, x, x^2, x^3 }$の多項式ベクトルとし、平均ベクトル${ bf m}$をゼロベクトル、精度行列${ bf Lambda}$を単位行列とする。 . using LinearAlgebra using Distributions ENV[&quot;GKS_ENCODING&quot;]=&quot;utf8&quot; # Plot内でunicode使うためのおまじない using Plots using StatsPlots . w_dist = MultivariateNormal(zeros(4), I) # 指定するのはΣだが単位行列は逆をとっても同じ。 function model_sample(w,x) X = [1,x,x^2,x^3] return w&#39; * X end . model_sample (generic function with 1 method) . # wをいくつかサンプリングし、xの3次関数を図示する。 w1 = rand(w_dist) w2 = rand(w_dist) w3 = rand(w_dist) plot(x -&gt; model_sample(w1,x), xlim= (-10, 10)) plot!(x -&gt; model_sample(w2,x), xlim=(-10, 10)) plot!(x -&gt; model_sample(w3,x),xlim=(-10,10)) . このように学習前にモデルの性質を確かめるのも重要な作業である。 . # 誤差を加え、実現値の範囲をみる。 plot(x -&gt; rand(Normal(model_sample(w1,x),1)), xlim=(-2.,2.), ylim=(-10.,10.)) . &#23398;&#32722; . モデルの事後分布は観測された変数の確率分布で割ることで求まる。観測された変数の確率分布は$p({ bf Y}|{ bf X})$であるから、 . $$ begin{eqnarray} p({ bf w}|{ bf Y},{ bf X}) &amp;=&amp; frac{p({ bf w}) Pi_{n=1}^{N} p (y_n | { bf x}_n, { bf w})}{p({ bf Y}|{ bf X})} &amp; propto&amp; p({ bf w}) Pi_{n=1}^{N} p (y_n | { bf x}_n, { bf w}) end{eqnarray} $$これを${ bf w}$について整理していく。対数をとって . $$ begin{eqnarray} ln p({ bf w}|{ bf Y},{ bf X}) &amp;=&amp; - frac{1}{2} { ({ bf w} - { bf m})^ mathrm{T} { bf Lambda} ({ bf w} - { bf m}) } - frac{ lambda}{2} Sigma_{n=1}^{N} (y_n - { bf w}^ mathrm{T} { bf x}_n )^2 + const. &amp;=&amp; - frac{1}{2} { { bf w}^ mathrm{T} { bf Lambda} { bf w} - { bf w}^ mathrm{T} { bf Lambda} { bf m} - { bf m}^ mathrm{T} { bf Lambda} { bf w} - 2 lambda Sigma_{n=1}^{N} y_n { bf w}^ mathrm{T} { bf x}_n + lambda Sigma_{n=1}^{N} { bf w}^ mathrm{T} { bf x}_n { bf w}^ mathrm{T} { bf x}_n } + const. &amp;=&amp; - frac{1}{2} { { bf w}^ mathrm{T} { bf Lambda} { bf w} - 2 { bf w}^ mathrm{T} { bf Lambda} { bf m} - 2 lambda Sigma_{n=1}^{N} y_n { bf w}^ mathrm{T} { bf x}_n + lambda Sigma_{n=1}^{N} { bf w}^ mathrm{T} { bf x}_n { bf x}_n^ mathrm{T} { bf w} } + const.　(スカラーを転置してまとめた) &amp;=&amp; - frac{1}{2} { { bf w}^ mathrm{T} ( lambda Sigma_{n=1}^{N} { bf x}_n { bf x}_n^ mathrm{T} + { bf Lambda}) { bf w} - 2 { bf w}^ mathrm{T} ( lambda Sigma_{n=1}^{N} y_n { bf x}_n + { bf Lambda} { bf m}) } + const. end{eqnarray} $$これはM次元のガウス分布の対数をとった形になっているので、パラメータ${ bf w}$の事後分布もM次元ガウス分布であり、 . $$ begin{eqnarray} p({ bf w}|{ bf Y},{ bf X}) &amp;=&amp; mathcal{N}({ bf w}| hat{ bf m}, hat{ bf Lambda}^{-1}) ただし　 hat{ bf Lambda} &amp;=&amp; lambda Sigma_{n=1}^{N} { bf x}_n { bf x}_n^ mathrm{T} + { bf Lambda} hat{ bf m} &amp;=&amp; hat{ bf Lambda}^{-1} ( lambda Sigma_{n=1}^{N} y_n { bf x}_n + { bf Lambda} { bf m}) end{eqnarray} $$ &#20104;&#28204; . 新規入力値${ bf x}_*$が与えられた時の出力$y_*$の予測分布$p(y_*|{ bf x}_*, { bf Y}, { bf X}$を求める。事前分布と事後分布は共にM次元ガウス分布であるので、事前分布のパラメータを使用した事前予測分布を求めてから事後分布のパラメータを代入し事後予測分布を求める。ベイズの定理から、 . $$ p({ bf w} | y_*, { bf x}_*) = frac{p({ bf w})p(y_* | { bf x}_*, { bf w})}{p(y_*|{ bf x}_*)} $$よって . $$ ln p(y_*|{ bf x}_*) = ln p(y_* | { bf x}_*, { bf w}) - ln p({ bf w} | y_*, { bf x}_*) + const. $$と表せる。$p({ bf w} | y_*, { bf x}_*)$は事後分布の計算結果を流用して . $$ begin{eqnarray} p({ bf w} | y_*, { bf x}_*) &amp;=&amp; mathcal{N}({ bf w}|{ bf m}(y_*), ( lambda { bf x}_n { bf x}_n^ mathrm{T} + { bf Lambda})^{-1}) ただし　{ bf m}(y_*) &amp;=&amp; ( lambda { bf x}_n { bf x}_n^ mathrm{T} + { bf Lambda})^{-1} ( lambda y_* { bf x}_* + { bf Lambda} { bf m}) end{eqnarray} $$であり、これを代入して、 . $$ begin{eqnarray} ln p(y_*|{ bf x}_*) &amp;=&amp; ln p(y_* | { bf x}_*, { bf w}) - ln p({ bf w} | y_*, { bf x}_*) + const. &amp;=&amp; - frac{1}{2} (y_* - { bf w}^ mathrm{T} { bf x}_*)^2 lambda + frac{1}{2} ({ bf w} - { bf m}(y_*))^ mathrm{T} ( lambda { bf x}_n { bf x}_n^ mathrm{T} + { bf Lambda}) ({ bf w} - { bf m}(y_*)) + const. &amp;=&amp; - frac{1}{2} { lambda y_*^2 - 2 lambda { bf w}^ mathrm{T} { bf x}_* y_* + 2{ bf w}^ mathrm{T} ( lambda { bf x}_n { bf x}_n^ mathrm{T} + { bf Lambda}) { bf m}(y_*) - { bf m}(y_*)^ mathrm{T} ( lambda { bf x}_n { bf x}_n^ mathrm{T} + { bf Lambda}) { bf m}(y_*) } + const. &amp;=&amp; - frac{1}{2} left[ lambda y_*^2 - 2 lambda { bf w}^ mathrm{T} { bf x}_* y_* + 2 { bf w}^ mathrm{T} ( lambda y_* { bf x}_* + { bf Lambda} { bf m}) - {( lambda { bf x}_* { bf x}_*^ mathrm{T} + { bf Lambda})^{-1} ( lambda y_* { bf x}_* + { bf Lambda} { bf m}) }^ mathrm{T} ( lambda y_* { bf x}_* + { bf Lambda} { bf m}) right] + const. &amp;=&amp; - frac{1}{2} { lambda y_*^2 - ( lambda y_* { bf x}_* + { bf Lambda} { bf m})^ mathrm{T} ( lambda { bf x}_* { bf x}_*^ mathrm{T} + { bf Lambda})^{-1} ( lambda y_* { bf x}_* + { bf Lambda} { bf m}) } + const. &amp;=&amp; - frac{1}{2} { lambda y_*^2 - lambda^2 { bf x}_*^ mathrm{T} ( lambda { bf x}_* { bf x}_*^ mathrm{T} + { bf Lambda})^{-1} { bf x}_* y_*^2 - 2 { bf x}_*^ mathrm{T} lambda ( lambda { bf x}_* { bf x}_*^ mathrm{T} + { bf Lambda})^{-1} { bf Lambda} { bf m} y_* } + const. &amp;=&amp; - frac{1}{2} { ( lambda - lambda^2 { bf x}_*^ mathrm{T} ( lambda { bf x}_* { bf x}_*^ mathrm{T} + { bf Lambda})^{-1} { bf x}_*) y_*^2 - 2 { bf x}_*^ mathrm{T} lambda ( lambda { bf x}_* { bf x}_*^ mathrm{T} + { bf Lambda})^{-1} { bf Lambda} { bf m} y_* } + const. end{eqnarray} $$と$y_*$の2次関数に変形できる。これは次のような1次元ガウス分布の対数をとったものである。 . $$ begin{eqnarray} p(y_*|{ bf x}_*) &amp;=&amp; mathcal{N}(y_* | mu_*, lambda_*^{-1}) ただし　 mu_* &amp;=&amp; { bf m}^ mathrm{T} { bf x}_* lambda_*^{-1} &amp;=&amp; lambda^{-1} + { bf x}_*^ mathrm{T} { bf Lambda}^{-1} { bf x}_* end{eqnarray} $$$ mu_*, lambda_*$はウッドベリーの公式$({ bf A}+{ bf UBV})^{-1} = { bf A}^{-1} - { bf A}^{-1} { bf U} ({ bf B}^{-1} + { bf VA}^{-1} { bf U})^{-1} { bf VA}^{-1}$を使って導ける。導出を次に示す。 . $$ begin{eqnarray} ln mathcal{N}(y_* | mu_*, lambda_*^{-1}) &amp;=&amp; - frac{1}{2} (y_* - mu_*)^2 lambda_* + const. &amp;=&amp; - frac{1}{2} { lambda_* y_*^2 - 2 lambda_* mu_* y_* } + const. 対応から　 lambda_* &amp;=&amp; lambda - lambda^2 { bf x}_*^ mathrm{T} ( lambda { bf x}_* { bf x}_*^ mathrm{T} + { bf Lambda})^{-1} { bf x}_* end{eqnarray} $$${ bf A} = lambda^{-1}, { bf B} = { bf Lambda}^{-1}, { bf U} = { bf x}_*^ mathrm{T}, { bf V} = { bf x}_*$とおくと、ウッドベリーの公式から . $$ lambda_* = ( lambda^{-1} + { bf x}_*^ mathrm{T} { bf Lambda}^{-1} { bf x}_*)^{-1} $$また$ mu_*$については対応とウッドベリーの公式から . $$ begin{eqnarray} mu_* lambda_* &amp;=&amp; { bf x}_*^ mathrm{T} lambda ( lambda { bf x}_* { bf x}_*^ mathrm{T} + { bf Lambda})^{-1} { bf Lambda} { bf m} &amp;=&amp; { bf x}_*^ mathrm{T} lambda ({ bf Lambda}^{-1} - { bf Lambda}^{-1} { bf x}_* ( lambda^{-1} + { bf x}_*^ mathrm{T} { bf Lambda}^{-1} { bf x}_*)^{-1} { bf x}_*^ mathrm{T} { bf Lambda}^{-1}) { bf Lambda} { bf m} &amp;=&amp; { bf x}_*^ mathrm{T} lambda { bf m} - { bf x}_*^ mathrm{T} lambda { bf Lambda}^{-1} { bf x}_* ( lambda^{-1} + { bf x}_*^ mathrm{T} { bf Lambda}^{-1} { bf x}_*)^{-1} { bf x}_*^ mathrm{T} { bf m} end{eqnarray} $$$ lambda_*{-1}$をかけて . $$ begin{eqnarray} mu_* &amp;=&amp; { bf x}_*^ mathrm{T} { bf m} + { bf x}_*^ mathrm{T} lambda { bf m} { bf x}_*^ mathrm{T} { bf Lambda}^{-1} { bf x}_* - { bf x}_*^ mathrm{T} lambda { bf Lambda}^{-1} { bf x}_* { bf x}_*^ mathrm{T} { bf m}　({ bf x}_*^ mathrm{T} { bf m}がスカラーであることを利用) &amp;=&amp; { bf m}^ mathrm{T} { bf x}_* end{eqnarray} $$となり導出完了。 . &#12514;&#12487;&#12523;&#27604;&#36611; . モデルの性能を比較するための定量的な方法として、周辺尤度(marginal likelihood)あるいはモデルエビデンス(model evidence)というものがある。これは観測変数$ mathcal{D}$がモデルから生成される確率$p( mathcal{D})$に当たる。今回の線形モデルの例で言えば$p({ bf Y}|{ bf X})$を求めることになる。 . $$ p({ bf Y}|{ bf X}) = frac{p({ bf w}) Pi_{n=1}^{N} p (y_n | { bf x}_n, { bf w})}{p({ bf w}|{ bf Y},{ bf X})} $$対数をとり、具体的な分布を代入していく。 . $$ begin{eqnarray} ln p({ bf Y}|{ bf X}) &amp;=&amp; ln p({ bf w}) + ln Sigma_{n=1}^{N} p (y_n | { bf x}_n, { bf w}) - ln p({ bf w}|{ bf Y},{ bf X}) &amp;=&amp; - frac{1}{2} { ({ bf w} - { bf m})^ mathrm{T} { bf Lambda} ({ bf w} - { bf m}) - ln |{ bf Lambda}| + M ln 2 pi } - frac{1}{2} Sigma_{n=1}^{N} { ln 2 pi - ln lambda + (y_n - { bf w}^ mathrm{T} { bf x}_n)^2 lambda } + frac{1}{2} { ({ bf w} - hat{ bf m})^ mathrm{T} hat{ bf Lambda} ({ bf w} - hat{ bf m}) - ln | hat{ bf Lambda} | + M ln 2 pi } &amp;=&amp; - frac{1}{2} { Sigma_{n=1}^{N}( lambda y_n^2 - ln lambda + ln 2 pi) + { bf m}^ mathrm{T} { bf Lambda} { bf m} - ln |{ bf Lambda}| - hat{ bf m}^ mathrm{T} hat{ bf Lambda} hat{ bf m} + ln | hat{ bf Lambda}| + { bf w}^ mathrm{T} { bf Lambda} { bf w} - 2 { bf w}^ mathrm{T} { bf Lambda} { bf m} - { bf w}^ mathrm{T} hat{ bf Lambda} { bf w} + 2 { bf w}^ mathrm{T} hat{ bf Lambda} hat{ bf m} - 2 lambda { bf w}^ mathrm{T} Sigma_{n=1}^{N} y_n { bf x}_n + lambda Sigma_{n=1}^{N} { bf w}^ mathrm{T} { bf x}_n { bf x}_n^ mathrm{T} { bf w} } &amp;=&amp; - frac{1}{2} { Sigma_{n=1}^{N}( lambda y_n^2 - ln lambda + ln 2 pi) + { bf m}^ mathrm{T} { bf Lambda} { bf m} - ln |{ bf Lambda}| - hat{ bf m}^ mathrm{T} hat{ bf Lambda} hat{ bf m} + ln | hat{ bf Lambda}| - { bf w}^ mathrm{T} lambda Sigma_{n=1}^{N} { bf x}_n { bf x}_n^ mathrm{T} { bf w} + 2 { bf w}^ mathrm{T} lambda Sigma_{n=1}^{N} y_n { bf x}_n - 2 lambda { bf w}^ mathrm{T} Sigma_{n=1}^{N} y_n { bf x}_n + lambda Sigma_{n=1}^{N} { bf w}^ mathrm{T} { bf x}_n { bf x}_n^ mathrm{T} { bf w} } &amp;=&amp; - frac{1}{2} { Sigma_{n=1}^{N}( lambda y_n^2 - ln lambda + ln 2 pi) + { bf m}^ mathrm{T} { bf Lambda} { bf m} - ln |{ bf Lambda}| - hat{ bf m}^ mathrm{T} hat{ bf Lambda} hat{ bf m} + ln | hat{ bf Lambda}| } end{eqnarray} $$と、整理できる。 . Julia&#12391;&#23455;&#35013; . mutable struct LinearModel M::Int m::Vector Λ::Matrix end function init(model::LinearModel) model.m = zeros(model.M) model.Λ = I(model.M) return model end function predict(model::LinearModel, x_new::Float64) x_vec = [x_new^m for m in 0:model.M-1] μ_pred = model.m&#39; * x_vec σ_new = sqrt(1/λ + x_vec&#39; * inv(model.Λ) * x_vec) pred_dist = Normal(μ_pred, σ_new) return pred_dist end . predict (generic function with 1 method) . λ = 10 model = LinearModel(4, zeros(4), I(4)) model = init(model) plot(x -&gt; mean(predict(model, x)), xlim=(-1,1), ylim=(-10,10)) plot!(x -&gt; quantile(predict(model, x), 0.025)) plot!(x -&gt; quantile(predict(model, x), 0.975)) . function fit(model, xs, ys) N = length(xs) x_ns = [[x^m for m in 0:model.M-1] for x in xs] Λ̂ = λ * sum(x_ns .* transpose.(x_ns)) + model.Λ m̂ = inv(Λ̂)*(λ * sum(ys .* x_ns) + model.Λ * model.m) evidence = - 0.5 * (λ*sum(ys.^2) - N*log(λ) + N*log(2*π) + model.m&#39;*model.Λ*model.m - log(det(model.Λ)) - m̂&#39;*Λ̂*m̂ + log(det(Λ̂))) model.m = m̂ model.Λ = Λ̂ return model, evidence end . fit (generic function with 1 method) . # sinカーブ上の点を生成 xs = collect(0:π/10:2π) ys = sin.(xs) λ = 10 . 10 . scatter(xs, ys) . function simulation(M) model = LinearModel(M, zeros(1), I(1)) model = init(model) model, evidence = fit(model, xs, ys) p = scatter(xs, ys, xlim=(-π,3π), ylim=(-3,3)) plot!(p, x -&gt; mean(predict(model, x)), xlim=(-π,3π)) plot!(p, x -&gt; quantile(predict(model, x), 0.025), xlim=(-π,3π)) plot!(p, x -&gt; quantile(predict(model, x), 0.975), xlim=(-π,3π)) return p, evidence end . simulation (generic function with 1 method) . # M=1,4,10の場合でプロット p1, evi1 = simulation(1) p4, evi4 = simulation(4) p10, evi10 = simulation(10) plot(p1, p4, p10, layout=(1,3)) . # モデルエビデンスをプロット plot(collect(1:10), [simulation(M)[2] for M in 1:10]) . #hide_output # animation anim = @animate for M in 1:10 p, evi = simulation(M) plot(p, title=&quot;M = $(M)&quot;) end gif(anim, &quot;animations/linear_reg.gif&quot;, fps = 2) . . &#12362;&#12414;&#12369;:MAP&#25512;&#23450;&#12392;L2&#27491;&#21063;&#21270; . MAP推定は事後確率を最大にするような値をパラメータの値にする推定である。 . 線形モデルでは$p({ bf w}|{ bf Y},{ bf X})$を最大化する${ bf w}$を求めることになる。対数事後確率を最大にするパラメータも同じなので$ ln p({ bf w}|{ bf Y},{ bf X})$を最大化すればいい。 . ただし、${ bf m} = { bf 0}, lambda = sigma_y^{-2}, Lambda = sigma_w^{-2} I$とする。 . $$ begin{eqnarray} ln p({ bf w}|{ bf Y},{ bf X}) &amp;=&amp; ln p({ bf Y}|{ bf X},{ bf w}) + ln p({ bf w}) + const. &amp;=&amp; Sigma_{n=1}^{N} ln mathcal{N}(y_n | { bf w}^ mathrm{T} { bf x}_n, lambda) + ln mathcal{N}({ bf w}|{ bf m},{ bf Lambda}^{-1}) + const. &amp;=&amp; - frac{ lambda}{2} Sigma_{n=1}^{N} (y_n - { bf w}^ mathrm{T} { bf x}_n)^2 - frac{1}{2} ({ bf w}-{ bf m})^ mathrm{T} { bf Lambda} ({ bf w}-{ bf m}) + const. &amp;=&amp; - sigma_y^{-2} { frac{1}{2} Sigma_{n=1}^{N} (y_n - { bf w}^ mathrm{T} { bf x}_n)^2 + frac{ sigma_w^{-2}}{ sigma_y^{-2}} frac{1}{2} { bf w}^ mathrm{T} { bf w} } + const. end{eqnarray} $$と式変形でき、$ frac{1}{2} Sigma_{n=1}^{N} (y_n - { bf w}^ mathrm{T} { bf x}_n)^2 + frac{ sigma_w^{-2}}{ sigma_y^{-2}} frac{1}{2} { bf w}^ mathrm{T} { bf w}$の部分はL2正則化で最小化する損失関数と等価である。 . したがって、L2正則化はMAP推定の特別な場合であり、その正則化項の係数はMAP推定における事前分布のパラメータ(ハイパーパラメータ)として解釈できる。 . 1. 須山敦志. 杉山将. ベイズ推論による機械学習入門. 講談社, 2017.↩ .",
            "url": "https://vintea01.github.io/tpt-medical-it/bayes/2020/05/15/bayes_part5.html",
            "relUrl": "/bayes/2020/05/15/bayes_part5.html",
            "date": " • May 15, 2020"
        }
        
    
  
    
        ,"post5": {
            "title": "Circular Binary Segmentation",
            "content": "&#24517;&#35201;&#12394;&#12497;&#12483;&#12465;&#12540;&#12472;&#12398;&#12452;&#12531;&#12509;&#12540;&#12488; . library(DNAcopy) library(tidyverse) . Registered S3 methods overwritten by &#39;ggplot2&#39;: method from [.quosures rlang c.quosures rlang print.quosures rlang Registered S3 method overwritten by &#39;rvest&#39;: method from read_xml.response xml2 ── Attaching packages ─────────────────────────────────────── tidyverse 1.2.1 ── ✔ ggplot2 3.1.1 ✔ purrr 0.3.2 ✔ tibble 2.1.1 ✔ dplyr 0.8.0.1 ✔ tidyr 0.8.3 ✔ stringr 1.4.0 ✔ readr 1.3.1 ✔ forcats 0.4.0 ── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ── ✖ dplyr::filter() masks stats::filter() ✖ dplyr::lag() masks stats::lag() . &#12469;&#12531;&#12503;&#12523;&#12487;&#12540;&#12479;&#12398;&#12452;&#12531;&#12509;&#12540;&#12488; . data(coriell) head(coriell) . CloneChromosomePositionCoriell.05296Coriell.13330 . GS1-232B23 | 1 | 0 | NA | 0.207470 | . RP11-82d16 | 1 | 468 | 0.008824 | 0.063076 | . RP11-62m23 | 1 | 2241 | -0.000890 | 0.123881 | . RP11-60j11 | 1 | 4504 | 0.075875 | 0.154343 | . RP11-111O05 | 1 | 5440 | 0.017303 | -0.043890 | . RP11-51b04 | 1 | 7000 | -0.006770 | 0.094144 | . &#12392;&#12426;&#12354;&#12360;&#12378;&#21487;&#35222;&#21270; . coriell.rmna &lt;- drop_na(coriell) chrom_pos &lt;- coriell.rmna %&gt;% mutate(id = 1:nrow(coriell.rmna)) %&gt;% group_by(Chromosome) %&gt;% summarise(min = min(id), pos = median(id), max=max(id)) y.pos &lt;- replace(rep(-1.6, 23), seq(0,23,2), -1.5) coriell.rmna %&gt;% mutate(id = 1:nrow(coriell.rmna), class = coriell.rmna$Chromosome %% 2) %&gt;% ggplot2::ggplot() + geom_point(mapping = aes(x = interaction(Chromosome, id, lex.order=T), y = Coriell.05296, color=class)) + annotate(geom = &quot;text&quot;, x = chrom_pos$pos, y = y.pos, size=3, label = unique(coriell.rmna$Chromosome)) + theme(axis.title.x=element_blank(), axis.text.x=element_blank(), axis.ticks.x=element_blank(), legend.position=&quot;none&quot;) . Circular Binary Segmentation&#12399;&#12497;&#12483;&#12465;&#12540;&#12472;&#21270;&#12373;&#12428;&#12390;&#12356;&#12427; . #1 DNAcopyオブジェクトの作成 | #2 外れ値の除去（後述） | #3 Circular Binary Segmentationの実行 | . ※実装に関してはパッケージの中身をみるか、またはpythonが読める人ならこちらが役に立つ。 . CNA.object &lt;- CNA(cbind(coriell$Coriell.05296), coriell$Chromosome, coriell$Position, data.type=&quot;logratio&quot;, sampleid=&quot;c05296&quot;) #1 smoothed.CNA.object &lt;- smooth.CNA(CNA.object) #2 segment.smoothed.CNA.object &lt;- segment(smoothed.CNA.object, verbose=1) #3 . Warning message in CNA(cbind(coriell$Coriell.05296), coriell$Chromosome, coriell$Position, : “array has repeated maploc positions ” . Analyzing: c05296 . . オブジェクトの中身をみれば、具体的なブレイクポイントがわかる。 . segment.smoothed.CNA.object . Call: segment(x = smoothed.CNA.object, verbose = 1) ID chrom loc.start loc.end num.mark seg.mean 1 c05296 1 468 240000 132 0.0212 2 c05296 2 0 245000 64 0.0095 3 c05296 3 0 218000 86 0.0025 4 c05296 4 0 171809 143 -0.0087 5 c05296 4 172856 179118 9 0.1752 6 c05296 4 179200 184000 13 -0.0350 7 c05296 5 0 198500 108 -0.0107 8 c05296 6 0 188000 85 -0.0048 9 c05296 7 0 161500 172 -0.0042 10 c05296 8 0 147000 151 -0.0026 11 c05296 9 0 115000 111 -0.0236 12 c05296 10 0 64187 53 -0.0165 13 c05296 10 65000 69549 4 0.3509 14 c05296 10 70547 110000 37 0.5164 15 c05296 10 110412 142000 32 -0.0076 16 c05296 11 0 34420 51 0.0121 17 c05296 11 35416 39623 15 -0.6511 18 c05296 11 43357 145000 119 0.0171 19 c05296 12 0 142000 94 0.0204 20 c05296 13 3426 100500 57 -0.0337 21 c05296 14 770 97000 76 0.0191 22 c05296 15 0 79000 66 0.0138 23 c05296 16 0 84000 66 0.0270 24 c05296 17 0 86000 91 0.0538 25 c05296 18 0 86000 53 0.0018 26 c05296 19 0 70000 37 -0.0274 27 c05296 20 0 73000 87 0.0129 28 c05296 21 3131 17703 18 0.0763 29 c05296 21 17704 30000 15 -0.0231 30 c05296 22 1100 33000 16 0.0183 31 c05296 23 0 155000 51 0.7184 . DataFrameも取得可能 . segment.smoothed.CNA.object[[&#39;output&#39;]] . IDchromloc.startloc.endnum.markseg.mean . c05296 | 1 | 468 | 240000 | 132 | 0.0212 | . c05296 | 2 | 0 | 245000 | 64 | 0.0095 | . c05296 | 3 | 0 | 218000 | 86 | 0.0025 | . c05296 | 4 | 0 | 171809 | 143 | -0.0087 | . c05296 | 4 | 172856 | 179118 | 9 | 0.1752 | . c05296 | 4 | 179200 | 184000 | 13 | -0.0350 | . c05296 | 5 | 0 | 198500 | 108 | -0.0107 | . c05296 | 6 | 0 | 188000 | 85 | -0.0048 | . c05296 | 7 | 0 | 161500 | 172 | -0.0042 | . c05296 | 8 | 0 | 147000 | 151 | -0.0026 | . c05296 | 9 | 0 | 115000 | 111 | -0.0236 | . c05296 | 10 | 0 | 64187 | 53 | -0.0165 | . c05296 | 10 | 65000 | 69549 | 4 | 0.3509 | . c05296 | 10 | 70547 | 110000 | 37 | 0.5164 | . c05296 | 10 | 110412 | 142000 | 32 | -0.0076 | . c05296 | 11 | 0 | 34420 | 51 | 0.0121 | . c05296 | 11 | 35416 | 39623 | 15 | -0.6511 | . c05296 | 11 | 43357 | 145000 | 119 | 0.0171 | . c05296 | 12 | 0 | 142000 | 94 | 0.0204 | . c05296 | 13 | 3426 | 100500 | 57 | -0.0337 | . c05296 | 14 | 770 | 97000 | 76 | 0.0191 | . c05296 | 15 | 0 | 79000 | 66 | 0.0138 | . c05296 | 16 | 0 | 84000 | 66 | 0.0270 | . c05296 | 17 | 0 | 86000 | 91 | 0.0538 | . c05296 | 18 | 0 | 86000 | 53 | 0.0018 | . c05296 | 19 | 0 | 70000 | 37 | -0.0274 | . c05296 | 20 | 0 | 73000 | 87 | 0.0129 | . c05296 | 21 | 3131 | 17703 | 18 | 0.0763 | . c05296 | 21 | 17704 | 30000 | 15 | -0.0231 | . c05296 | 22 | 1100 | 33000 | 16 | 0.0183 | . c05296 | 23 | 0 | 155000 | 51 | 0.7184 | . 可視化も一瞬 . plot(segment.smoothed.CNA.object, plot.type=&quot;whole&quot;) . &#22806;&#12428;&#20516;&#12398;&#38500;&#21435;&#12395;&#38306;&#12375;&#12390; . 各添字 $i (i = 1, 2, ..., n)$ に対して、$i - R, ..., i, ..., i + R (2≤R≤5)$ のウィンドウを定義する。 . $m_i$ をウィンドウ領域の中央値とし、$ hat sigma$ を標準偏差とする。 . 観測値 $X_i$ がウィンドウ領域の最大値または最小値だった場合、その値に最も近い値を持つ $X_j$ を探す。 . $|X_j - X_i|&gt;L hat sigma (default: L=4)$ だった場合、$X_i$ を $m_{i}+sign(X_i-X_j)M hat sigma$ に置き換える。 .",
            "url": "https://vintea01.github.io/tpt-medical-it/bioinformatics/2020/04/07/circular-binary-segmentation.html",
            "relUrl": "/bioinformatics/2020/04/07/circular-binary-segmentation.html",
            "date": " • Apr 7, 2020"
        }
        
    
  
    
        ,"post6": {
            "title": "ベイズ勉強会 Part 4 多次元ガウス分布のベイズ推論",
            "content": "ベイズ勉強会資料は『ベイズ推論による機械学習入門』1を元に、途中式計算をできるだけ省略せずに行ったものです。 . &#22810;&#27425;&#20803;&#12460;&#12454;&#12473;&#20998;&#24067; . 多次元ガウス分布はD次元ベクトル${ bf x} in mathbb{R}^D$を生成するための確率分布であり、以下の確率密度関数で表される。 . . Important: 多次元ガウス分布の確率密度関数 $$ frac{1}{ sqrt{(2 pi)^D |{ bf Sigma} }|} exp{ {- frac{1}{2}({ bf x}-{ bf mu})^ mathrm{T} { bf Sigma}^{-1} ({ bf x}-{ bf mu}) } }$$ . ${ bf mu} in mathbb{R}^D$は平均パラメータ、${ bf Sigma}$は共分散行列パラメータで$D times D$の正定値行列である必要がある。 . . Important: 正定値行列 . 固有値が全て正の実正方行列を正定値行列と呼ぶ。実正方行列${ bf A}$が正定値行列である必要十分条件は任意の非ゼロベクトル${ bf x}$に関して、 . $${ bf x}^ mathrm{T} { bf A}{ bf x} &gt; 0$$が成り立つこと。正定値行列の逆行列も正定値行列である。また全ての固有値が正であることから、 . $$|{ bf A}| &gt; 0$$が成り立つ。 . また、対称行列であるので . $${ bf A}^{ mathrm{T} } = { bf A}$$が成り立つ。 . 多次元ガウス分布を対数で表示すると、 . . Important: 多次元ガウス分布の対数表示 $$ ln mathcal{N}({ bf x}|{ bf mu},{ bf Sigma})=- frac{1}{2} {({ bf x}-{ bf mu})^ mathrm{T} { bf Sigma}^{-1}({ bf x}-{ bf mu}) + ln |{ bf Sigma}| + D ln 2 pi }$$ . 1次元ガウス分布と同様に分散の逆元として精度を定義できる。共分散行列$ bf{ Sigma}$の逆行列として精度行列$ bf{ Lambda}$を定義する。すなわち$ bf{ Lambda}= bf{ Sigma}^{-1}$である。 . . Important: 多次元ガウス分布を精度行列で表した場合 $$ frac{1}{ sqrt{(2 pi)^D} }|{ bf Lambda}|^{ frac{1}{2} } exp{ {- frac{1}{2}({ bf x}-{ bf mu})^ mathrm{T} { bf Lambda} ({ bf x}-{ bf mu}) } }$$ . . Important: 多次元ガウス分布の対数表示(精度行列で表した場合) $$ ln mathcal{N}({ bf x}|{ bf mu},{ bf Lambda}^{-1})=- frac{1}{2} {({ bf x}-{ bf mu})^ mathrm{T} { bf Lambda}({ bf x}-{ bf mu}) - ln |{ bf Lambda}| + D ln 2 pi }$$ . この多次元ガウス分布のベイズ推論を行っていく。1次元ガウス分布と同様、平均パラメータ未知、精度パラメータ未知、両方未知の場合の順に行う。なお本稿では特に断り無い限り多次元ガウス分布のことをガウス分布と呼ぶ。 . &#24179;&#22343;&#26410;&#30693; . D次元の確率変数${ bf x} in mathbb{R}^D$の平均パラメータ${ bf mu} in mathbb{R}^D$のみが未知で、精度行列${ bf Lambda} in mathbb{R}^{D times D}$は既に与えられている、またはハイパーパラメータとして、ベイズ推論を行ってみる。N個のデータ${ bf X} = { { bf x}_1, dots,{ bf x}_N }$が観測されていて、予測する未知の観測を${ bf x}_*$とおく。 . &#12514;&#12487;&#12523;&#12398;&#27083;&#31689; . 平均のみが未知の時は、ガウス分布を事前分布とすることで共役性が満たされることがわかっている。${ bf m} in mathbb{R}^D, { bf Lambda}_{ mu} in mathbb{R}^{D times D}$をハイパーパラメータとして同時分布は次のようになる。 . $$ begin{eqnarray} p({ bf X},{ bf x}_*,{ bf mu}) &amp;=&amp; p({ bf X}|{ bf mu})p({ bf x}_*|{ bf mu})p({ bf mu}) p({ bf X}|{ bf mu}) &amp;=&amp; Pi_{n=1}^{N} mathcal{N}({ bf x}_n|{ bf mu},{ bf Lambda}^{-1}) p({ bf x}_*|{ bf mu}) &amp;=&amp; mathcal{N}({ bf x}_*|{ bf mu},{ bf Lambda}^{-1}) p({ bf mu}) &amp;=&amp; mathcal{N}({ bf mu}|{ bf m},{ bf Lambda}_{ mu}^{-1}) end{eqnarray} $$&#20107;&#24460;&#20998;&#24067;&#12398;&#25512;&#35542; . ベイズの定理を用いて事後分布$p({ bf mu}|{ bf X})$は次のようになる。 . $$ begin{eqnarray} p({ bf mu}|{ bf X}) &amp; propto&amp; p({ bf X}|{ bf mu})p({ bf mu}) &amp;=&amp; { Pi_{n=1}^{N} p({ bf x}_n|{ bf mu}) }p({ bf mu}) &amp;=&amp; Pi_{n=1}^{N} { mathcal{N}({ bf x}_n|{ bf mu},{ bf Lambda}^{-1}) } mathcal{N}({ bf mu}|{ bf m},{ bf Lambda}_{ mu}^{-1}) end{eqnarray} $$対数をとると . $$ begin{eqnarray} ln p({ bf mu}|{ bf X}) &amp;=&amp; Sigma_{n=1}^{N} ln mathcal{N}({ bf x}_n|{ bf mu},{ bf Lambda}^{-1}) + ln mathcal{N}({ bf mu}|{ bf m},{ bf Lambda}_{ mu}^{-1}) + const. &amp;=&amp; - frac{1}{2} Sigma_{n=1}^{N} ({ bf x}_n-{ bf mu})^ mathrm{T} { bf Lambda}({ bf x}_n-{ bf mu}) - frac{1}{2}({ bf mu}-{ bf m})^ mathrm{T}{ bf Lambda}_{ mu}({ bf mu}-{ bf m}) + const. &amp;=&amp; - frac{1}{2} Sigma_{n=1}^{N} ({ bf x}_n^{ mathrm{T} }-{ bf mu}^{ mathrm{T} }){ bf Lambda}({ bf x}_n-{ bf mu}) - frac{1}{2}({ bf mu}^{ mathrm{T} }-{ bf m}^{ mathrm{T} }) { bf Lambda}_{ mu}({ bf mu}-{ bf m}) + const. &amp;=&amp; frac{1}{2} Sigma_{n=1}^{N} { { bf x}_n^{ mathrm{T} }{ bf Lambda}{ bf mu} } + frac{1}{2} { bf mu}^{ mathrm{T} } { bf Lambda} Sigma_{n=1}^{N} { bf x}_n - frac{N}{2} { bf mu}^{ mathrm{T} }{ bf Lambda}{ bf mu} - frac{1}{2} { bf mu}^{ mathrm{T} }{ bf Lambda}_{ mu}{ bf mu} + frac{1}{2}{ bf mu}^{ mathrm{T} }{ bf Lambda}_{ mu}{ bf m} + frac{1}{2}{ bf m}^{ mathrm{T} }{ bf Lambda}_{ mu}{ bf mu} + const. end{eqnarray} $$ ここで、${ bf x}_n^{ mathrm{T} }{ bf Lambda}{ bf mu}$は行数と列数について(1×D)×(D×D)×(D×1)=(1×1)よりスカラーなので次が成り立つ。 . $$ begin{eqnarray} { bf x}_n^{ mathrm{T} }{ bf Lambda}{ bf mu} &amp;=&amp; ({ bf x}_n^{ mathrm{T} }{ bf Lambda}{ bf mu})^{ mathrm{T} }　(スカラーを転置しても同じ) &amp;=&amp; { bf mu}^{ mathrm{T} } { bf Lambda}^{ mathrm{T} } { bf x}_n　(これは公式通り) &amp;=&amp; { bf mu}^{ mathrm{T} } { bf Lambda} { bf x}_n　({ bf Lambda}は対称行列) end{eqnarray} $$${ bf m}^{ mathrm{T} }{ bf Lambda}_{ mu} { bf mu}$についても同様であり、 . $$ begin{eqnarray} ln p({ bf mu}|{ bf X}) &amp;=&amp; frac{1}{2} Sigma_{n=1}^{N} { { bf x}_n^{ mathrm{T} }{ bf Lambda}{ bf mu} } + frac{1}{2} { bf mu}^{ mathrm{T} } { bf Lambda} Sigma_{n=1}^{N} { bf x}_n - frac{N}{2} { bf mu}^{ mathrm{T} }{ bf Lambda}{ bf mu} - frac{1}{2} { bf mu}^{ mathrm{T} }{ bf Lambda}_{ mu}{ bf mu} + frac{1}{2}{ bf mu}^{ mathrm{T} }{ bf Lambda}_{ mu}{ bf m} + frac{1}{2}{ bf m}^{ mathrm{T} }{ bf Lambda}_{ mu}{ bf mu} + const. &amp;=&amp; frac{1}{2}{ bf mu}^{ mathrm{T} } { bf Lambda} Sigma_{n=1}^{N} { bf x}_n + frac{1}{2}{ bf mu}^{ mathrm{T} } { bf Lambda} Sigma_{n=1}^{N} { bf x}_n - frac{N}{2} { bf mu}^{ mathrm{T} }{ bf Lambda}{ bf mu} - frac{1}{2} { bf mu}^{ mathrm{T} }{ bf Lambda}_{ mu}{ bf mu} + frac{1}{2}{ bf mu}^{ mathrm{T} }{ bf Lambda}_{ mu}{ bf m} + + frac{1}{2}{ bf mu}^{ mathrm{T} }{ bf Lambda}_{ mu}{ bf m} + const. &amp;=&amp; - frac{1}{2} { { bf mu}^{ mathrm{T} } (N { bf Lambda}+{ bf Lambda}_{ mu}){ bf mu} - 2 { bf mu}^{ mathrm{T} }({ bf Lambda} Sigma_{n=1}^{N} { bf x}_n + { bf Lambda}_{ mu} { bf m}) } + const. end{eqnarray} $$${ bf mu}$に関する上に凸の二次関数となり、ガウス分布であることがわかる。1次元と同様に逆算的に計算していく。 . $$p({ bf mu}|{ bf X}) = mathcal{N}({ bf mu}| hat{ bf m}, hat{ bf Lambda}_{ bf mu}^{-1})$$ . とおき、対数をとって${ bf mu}$について整理すると . $$ begin{eqnarray} ln p({ bf mu}|{ bf X}) &amp;=&amp; - frac{1}{2} {({ bf mu}- hat{ bf m})^ mathrm{T} hat{ bf Lambda}_{ bf mu} ({ bf mu}- hat{ bf m}) } + const. &amp;=&amp; - frac{1}{2} { { bf mu}^{ mathrm{T} } hat{ bf Lambda}_{ bf mu} { bf mu} - hat{ bf m}^{ mathrm{T} } hat{ bf Lambda}_{ bf mu} { bf mu} - { bf mu}^{ mathrm{T} } hat{ bf Lambda}_{ bf mu} hat{ bf m} } + const. &amp;=&amp; - frac{1}{2} { { bf mu}^{ mathrm{T} } hat{ bf Lambda}_{ bf mu} { bf mu}-2{ bf mu}^{ mathrm{T} } hat{ bf Lambda}_{ bf mu} hat{ bf m} } + const. end{eqnarray} $$対応関係を見れば . $$ begin{eqnarray} hat{ bf Lambda}_{ bf mu} = N{ bf Lambda}+{ bf Lambda}_{ bf mu} hat{ bf m} = hat{ bf Lambda}_{ bf mu}^{-1}({ bf Lambda} Sigma_{n=1}^{N} { bf x}_n + { bf Lambda}_{ mu} { bf m}) end{eqnarray} $$と事後分布のハイパーパラメータが求まる。 . &#20104;&#28204;&#20998;&#24067;&#12398;&#23566;&#20986; . 簡単のために学習前の事前分布を用いて予測分布を導出し、更新されたハイパーパラメータを代入することで学習後の予測分布を計算する。1次元の時と同様、ベイズの定理と対数化を利用し積分計算を避ける。 . $$ ln p({ bf x}_*) = ln p({ bf x}_*|{ bf mu}) - ln p({ bf mu}|{ bf x}_*) + const.$$ . $ ln p({ bf mu}|{ bf x}_*)$は${ bf x}_*$を学習した後の事後分布と見なせるので、 . $$ begin{eqnarray} p({ bf mu}|{ bf x}_*) &amp;=&amp; mathcal{N}({ bf mu}|{ bf m}({ bf x}_*), ({ bf Lambda}+{ bf Lambda}_{ bf mu})^{-1}) ただし　{ bf m}({ bf x}_*) &amp;=&amp; ({ bf Lambda}+{ bf Lambda}_{ bf mu})^{-1} ({ bf Lambda}{ bf x}_* + { bf Lambda}_{ bf mu} { bf m}) end{eqnarray} $$したがって、 . $$ begin{eqnarray} ln p({ bf x}_*) &amp;=&amp; ln p({ bf x}_*|{ bf mu}) - ln p({ bf mu}|{ bf x}_*) + const. &amp;=&amp; - frac{({ bf x}_*-{ bf mu})^ mathrm{T}{ bf Lambda}({ bf x}_*-{ bf mu})}{2} + frac{({ bf mu}-{ bf m}({ bf x}_*))^ mathrm{T}({ bf Lambda}+{ bf Lambda}_{ mu})({ bf mu}-{ bf m}({ bf x}_*))}{2} + const. &amp;=&amp; - frac{1}{2} { { bf x}_*^{ mathrm{T} }{ bf Lambda}{ bf x}_* - { bf x}_*^{ mathrm{T} }{ bf Lambda}{ bf mu} - { bf mu}^ mathrm{T}{ bf Lambda}{ bf x}_* - { bf m}({ bf x}_*)^ mathrm{T} ({ bf Lambda}+{ bf Lambda}_{ bf mu}) { bf m}({ bf x}_*) + { bf m}({ bf x}_*)^ mathrm{T}({ bf Lambda}+{ bf Lambda}_{ bf mu}){ bf mu} + { bf mu}^ mathrm{T}({ bf Lambda}+{ bf Lambda}_{ bf mu}){ bf m}({ bf x}_*) } + const. &amp;=&amp; - frac{1}{2} { { bf x}_*^{ mathrm{T} }{ bf Lambda}{ bf x}_* - 2 { bf x}_*^{ mathrm{T} }{ bf Lambda}{ bf mu} - { bf m}({ bf x}_*)^ mathrm{T} ({ bf Lambda}+{ bf Lambda}_{ bf mu}) { bf m}({ bf x}_*) + 2 { bf mu}^ mathrm{T}({ bf Lambda}+{ bf Lambda}_{ bf mu}){ bf m}({ bf x}_*) } + const. &amp;=&amp; - frac{1}{2} { { bf x}_*^{ mathrm{T} }{ bf Lambda}{ bf x}_* - 2 { bf x}_*^{ mathrm{T} }{ bf Lambda}{ bf mu} - { bf m}({ bf x}_*)^ mathrm{T} ({ bf Lambda}{ bf x}_* + { bf Lambda}_{ bf mu}{ bf m}) + 2{ bf mu}^ mathrm{T}{ bf Lambda}{ bf x}_* } + const. &amp;=&amp; - frac{1}{2} { { bf x}_*^{ mathrm{T} }{ bf Lambda}{ bf x}_* - ({ bf Lambda}{ bf x}_* + { bf Lambda}_{ bf mu}{ bf m})^ mathrm{T} { bf m}({ bf x}_*) } + const.　({ bf m}({ bf x}_*)^ mathrm{T} ({ bf Lambda}{ bf x}_* + { bf Lambda}_{ bf mu}{ bf m})はスカラーなので転置しても変わらない) &amp;=&amp; - frac{1}{2} { { bf x}_*^{ mathrm{T} }{ bf Lambda}{ bf x}_* - ({ bf Lambda}{ bf x}_* + { bf Lambda}_{ bf mu}{ bf m})^ mathrm{T} ({ bf Lambda}+{ bf Lambda}_{ bf mu})^{-1} ({ bf Lambda}{ bf x}_* + { bf Lambda}_{ bf mu}{ bf m}) } + const. &amp;=&amp; - frac{1}{2} { { bf x}_*^{ mathrm{T} }{ bf Lambda}{ bf x}_* - ({ bf Lambda}{ bf x}_*)^ mathrm{T}({ bf Lambda}+{ bf Lambda}_{ bf mu})^{-1}{ bf Lambda}{ bf x}_* - ({ bf Lambda}{ bf x}_*)^ mathrm{T}({ bf Lambda}+{ bf Lambda}_{ bf mu})^{-1}{ bf Lambda}_{ bf mu}{ bf m} - ({ bf Lambda}_{ bf mu}{ bf m})^ mathrm{T}({ bf Lambda}+{ bf Lambda}_{ bf mu})^{-1}{ bf Lambda}{ bf x}_* } + const. &amp;=&amp; - frac{1}{2} { { bf x}_*^{ mathrm{T} }{ bf Lambda}{ bf x}_* - { bf x}_*^ mathrm{T}{ bf Lambda}({ bf Lambda}+{ bf Lambda}_{ bf mu})^{-1}{ bf Lambda}{ bf x}_* - 2{ bf x}_*^ mathrm{T}{ bf Lambda}({ bf Lambda}+{ bf Lambda}_{ bf mu})^{-1}{ bf Lambda}_{ bf mu}{ bf m} } + const. &amp;=&amp; - frac{1}{2} { { bf x}_*^{ mathrm{T} } ({ bf Lambda}-{ bf Lambda}({ bf Lambda}+{ bf Lambda}_{ bf mu})^{-1}{ bf Lambda}) { bf x}_* - 2{ bf x}_*^ mathrm{T}{ bf Lambda}({ bf Lambda}+{ bf Lambda}_{ bf mu})^{-1}{ bf Lambda}_{ bf mu}{ bf m} } + const. end{eqnarray} $$ここで . $$ p({ bf x}_*) = mathcal{N}({ bf x}_*|{ bf mu}_*,{ bf Lambda}_*^{-1}) $$と書けるとすると . $$ ln p({ bf x}_*) = - frac{1}{2} { { bf x}_*^{ mathrm{T} } { bf Lambda}_{*} { bf x}_* -2{ bf x}_*^{ mathrm{T} } { bf Lambda}_{*} { bf mu}_* } + const. $$であるから、対応関係から . $$ begin{eqnarray} { bf Lambda}_* &amp;=&amp; { bf Lambda}-{ bf Lambda}({ bf Lambda}+{ bf Lambda}_{ bf mu})^{-1}{ bf Lambda} { bf mu}_* &amp;=&amp; { bf Lambda}_*^{-1} { bf Lambda}({ bf Lambda}+{ bf Lambda}_{ bf mu})^{-1}{ bf Lambda}_{ bf mu}{ bf m} end{eqnarray} $$ウッドベリーの公式を使うことで更に簡潔な形にできる。 . . Tip: ウッドベリーの公式 $$({ bf A}+{ bf U}{ bf B}{ bf V})^{-1} = { bf A}^{-1} - { bf A}^{-1}{ bf U}({ bf B}^{-1}+{ bf V}{ bf A}^{-1}{ bf U})^{-1}{ bf V}{ bf A}^{-1}$$ . . Tip: ウッドベリーの公式(${ bf A},{ bf B}$の次元が等しく, ${ bf U},{ bf V}$が単位行列の場合) $$({ bf A}+{ bf B})^{-1} = { bf A}^{-1} - { bf A}^{-1}({ bf A}^{-1} + { bf B}^{-1})^{-1} { bf A}^{-1}$$ . ${ bf Lambda}_*$について、${ bf A}={ bf Lambda}^{-1},{ bf B}={ bf Lambda}_{ bf mu}^{-1}$とおくと、 . $$ begin{eqnarray} { bf Lambda}_* &amp;=&amp; { bf Lambda}-{ bf Lambda}({ bf Lambda}+{ bf Lambda}_{ bf mu})^{-1}{ bf Lambda} &amp;=&amp; { bf A}^{-1} - { bf A}^{-1}({ bf A}^{-1} + { bf B}^{-1})^{-1} { bf A}^{-1} &amp;=&amp; ({ bf A}+{ bf B})^{-1} &amp;=&amp; ({ bf Lambda}^{-1} + { bf Lambda}_{ mu}^{-1})^{-1} end{eqnarray} $$${ bf mu}_*$は、${ bf Lambda}_* = { bf Lambda}-{ bf Lambda} ({ bf Lambda}+{ bf Lambda}_{ bf mu})^{-1} { bf Lambda}$より . $$ begin{eqnarray} { bf Lambda}({ bf Lambda}+{ bf Lambda}_{ bf mu})^{-1}{ bf Lambda} &amp;=&amp; { bf Lambda} - { bf Lambda}_* { bf Lambda}({ bf Lambda}+{ bf Lambda}_{ bf mu})^{-1} &amp;=&amp; ({ bf Lambda} - { bf Lambda}_*){ bf Lambda}^{-1} end{eqnarray} $$だから . $$ begin{eqnarray} { bf mu}_* &amp;=&amp; { bf Lambda}_*^{-1} { bf Lambda}({ bf Lambda}+{ bf Lambda}_{ bf mu})^{-1}{ bf Lambda}_{ bf mu}{ bf m} &amp;=&amp; { bf Lambda}_*^{-1} ({ bf Lambda} - { bf Lambda}_*){ bf Lambda}^{-1}{ bf Lambda}_{ bf mu}{ bf m} &amp;=&amp; { { bf Lambda}_*^{-1}{ bf Lambda}{ bf Lambda}^{-1}{ bf Lambda}_{ bf mu} - { bf Lambda}_*^{-1}{ bf Lambda}_* { bf Lambda}^{-1}{ bf Lambda}_{ bf mu} }{ bf m} &amp;=&amp; { { bf Lambda}_*^{-1}{ bf Lambda}_{ bf mu} - { bf Lambda}^{-1}{ bf Lambda}_{ bf mu} }{ bf m} &amp;=&amp; { ({ bf Lambda}^{-1} + { bf Lambda}_{ mu}^{-1}){ bf Lambda}_{ bf mu} - { bf Lambda}^{-1}{ bf Lambda}_{ bf mu} }{ bf m} &amp;=&amp; { bf I}_D { bf m} = { bf m} end{eqnarray} $$まとめると、 . $$ begin{eqnarray} { bf Lambda}_* &amp;=&amp; ({ bf Lambda}^{-1} + { bf Lambda}_{ mu}^{-1})^{-1} { bf mu}_* &amp;=&amp; { bf m} end{eqnarray} $$これらに、更新されたハイパーパラメータ$ hat{ bf m}, hat{ bf Lambda}_{ bf mu}$を代入して学習後の予測分布$p({ bf x}_*|{ bf X})$が求まる。 . &#31934;&#24230;&#34892;&#21015;&#26410;&#30693; . &#12514;&#12487;&#12523;&#12398;&#27083;&#31689; . 多次元ガウス分布の精度行列は正定値行列である必要がある。$D times D$の正定値行列を生成する確率分布にウィシャート分布がある。 . . Important: ウィシャート分布の確率密度関数 $$ mathcal{W}({ bf Lambda}| nu,{ bf W}) = C_ mathcal{W} ( nu, { bf W})|{ bf Lambda}|^{ frac{ nu-D-1}{2} } exp { - frac{1}{2} Tr({ bf W}^{-1} { bf Lambda}) }$$ . $ nu$は自由度パラメータで、$ nu &gt; D - 1$を満たす必要がある。また、パラメータ${ bf W}$は$D times D$の正定値行列である。$Tr()$はトレースといい、行列の対角成分の和をとる演算である。ウィシャート分布も対数化することで計算の見通しが良くなる。 . . Important: ウィシャート分布の対数化 $$ ln mathcal{W} ({ bf Lambda}| nu,{ bf W}) = frac{ nu-D-1}{2} ln |{ bf Lambda}| - frac{1}{2} Tr({ bf W}^{-1} { bf Lambda}) + ln C_ mathcal{W} ( nu, { bf W})$$ . . Important: 対数化された正規化項 $$ ln C_ mathcal{W} ( nu, { bf W}) = - frac{ nu}{2} ln |{ bf W}| - ln frac{ nu D}{2} ln 2 - frac{D(D-1)}{4} ln pi - Sigma_{d=1}^{D} ln Gamma( frac{ nu+1+d}{2})$$ . . Tip: トレースについて成り立つ等式 $$ begin{eqnarray} Tr({ bf A}) &amp;=&amp; Tr({ bf A}^ mathrm{T}) Tr({ bf A} + { bf B}) &amp;=&amp; Tr({ bf A}) + Tr({ bf B}) Tr({ bf AB}) &amp;=&amp; Tr({ bf BA}) end{eqnarray}$$ . さて、このウィシャート分布を用いてモデルを構築すると次のようになる。 . $$ begin{eqnarray} p({ bf X},{ bf x}_*,{ bf Lambda}) &amp;=&amp; p({ bf X}|{ bf Lambda})p({ bf x}_*|{ bf Lambda})p({ bf Lambda}) p({ bf x}_*|{ bf Lambda}) &amp;=&amp; mathcal{N}({ bf x}_* |{ bf mu}, { bf Lambda}^{-1}) p({ bf X}|{ bf Lambda}) &amp;=&amp; Pi_{n=1}^{N} mathcal{N}({ bf x}_n |{ bf mu}, { bf Lambda}^{-1}) p({ bf Lambda}) &amp;=&amp; mathcal{W}({ bf Lambda}| nu, { bf W}) end{eqnarray} $$&#20107;&#24460;&#20998;&#24067;&#12398;&#25512;&#35542; . データ${ bf X}$を観測した後の事後分布は . $$ p({ bf Lambda}|{ bf X}) propto p({ bf X}|{ bf Lambda}) p({ bf Lambda}) $$ゆえ対数化すると . $$ begin{eqnarray} ln p({ bf Lambda}|{ bf X}) &amp;=&amp; Sigma_{n=1}^{N} ln mathcal{N} ({ bf x}_n|{ bf mu}, { bf Lambda}^{-1}) + ln mathcal{W}({ bf Lambda} | nu, { bf W}) + const. &amp;=&amp; - frac{1}{2} { Sigma_{n=1}^{N} ({ bf x}_n-{ bf mu})^ mathrm{T} { bf Lambda}({ bf x}_n-{ bf mu}) - N ln |{ bf Lambda}| } + frac{ nu-D-1}{2} ln |{ bf Lambda}| - frac{1}{2} Tr({ bf W}^{-1} { bf Lambda}) + const. &amp;=&amp; frac{N+ nu-D-1}{2} ln |{ bf Lambda}| - frac{1}{2} Sigma_{n=1}^{N} Tr { ({ bf x}_n-{ bf mu})^ mathrm{T} { bf Lambda}({ bf x}_n-{ bf mu}) } - frac{1}{2} Tr({ bf W}^{-1} { bf Lambda}) + const.　(スカラーのトレースをとっても同じ) &amp;=&amp; frac{N+ nu-D-1}{2} ln |{ bf Lambda}| - frac{1}{2} Sigma_{n=1}^{N} Tr { ({ bf x}_n-{ bf mu})({ bf x}_n-{ bf mu})^ mathrm{T} { bf Lambda} } - frac{1}{2} Tr({ bf W}^{-1} { bf Lambda}) + const.　(トレース内では対角成分が同じであれば順番を入れ替えても問題ない) &amp;=&amp; frac{N+ nu-D-1}{2} ln |{ bf Lambda}| - frac{1}{2} Tr left[ { Sigma_{n=1}^{N} ({ bf x}_n-{ bf mu})({ bf x}_n-{ bf mu})^ mathrm{T} + { bf W}^{-1} } { bf Lambda} right] + const.　(トレースの和は和のトレース) end{eqnarray} $$ウィシャート分布との対応を見れば、 . $$ begin{eqnarray} p({ bf Lambda}|{ bf X}) &amp;=&amp; mathcal{W}({ bf Lambda}| hat{ nu}, hat{ bf W}) ただし　 hat{ bf W}^{-1} &amp;=&amp; Sigma_{n=1}^{N} ({ bf x}_n - { bf mu})({ bf x}_n - { bf mu})^ mathrm{T} + { bf W}^{-1} hat{ nu} &amp;=&amp; N + nu end{eqnarray} $$となる。 . &#20104;&#28204;&#20998;&#24067;&#12398;&#23566;&#20986; . 事前分布と事後分布の形が同じなので、表記がシンプルになるよう学習前のハイパーパラメータで予測分布を計算し、後で代入する。 . 積分計算を避け、ベイズの定理と対数を利用する。学習前の予測分布$p({ bf x}_*)$は、 . $$ ln p({ bf x}_*) = ln p({ bf x}_*|{ bf Lambda}) - ln p({ bf Lambda}|{ bf x}_*) + const. $$と表せる。事後分布の結果を流用して . $$ begin{eqnarray} p({ bf Lambda}|{ bf x}_*) &amp;=&amp; mathcal{W}({ bf Lambda}|1+ nu , { bf W}({ bf x}_*)) ただし　{ bf W} ({ bf x}_*)^{-1} &amp;=&amp; ({ bf x}_* - { bf mu})({ bf x}_* - { bf mu})^ mathrm{T} + { bf W}^{-1} end{eqnarray} $$よって . $$ begin{eqnarray} ln p({ bf x}_*) &amp;=&amp; ln p({ bf x}_*|{ bf Lambda}) - ln p({ bf Lambda}|{ bf x}_*) + const. &amp;=&amp; - frac{1}{2} left[ ({ bf x}_* -{ bf mu})^ mathrm{T} { bf Lambda} ({ bf x}_* -{ bf mu}) - Tr { { bf W}({ bf x}_*)^{-1}{ bf Lambda} } - ( nu + 1) ln |{ bf W} ({ bf x}_*)| right] + const. end{eqnarray} $$行列式、トレースの性質を使いながら計算を進める。 . . Tip: 行列式の性質 $$ begin{eqnarray} |c{ bf A}| &amp;=&amp; c^N |{ bf A}| |{ bf A}^ mathrm{T}| &amp;=&amp; |{ bf A}| |{ bf A}{ bf B}| &amp;=&amp; |{ bf A}| |{ bf B}| |{ bf A}^{-1}| &amp;=&amp; |{ bf A}|^{-1} |{ bf I}_N + { bf C} { bf D}^ mathrm{T} | &amp;=&amp; |{ bf I}_M + { bf C}^ mathrm{T} { bf D}|　(この{ bf C}と{ bf D}はN times M行列) end{eqnarray}$$ . $$ begin{eqnarray} ln p({ bf x}_*) &amp;=&amp; - frac{1}{2} left[ Tr { ({ bf x}_* -{ bf mu})^ mathrm{T} { bf Lambda} ({ bf x}_* -{ bf mu})) } - Tr { ({ bf x}_* - { bf mu})({ bf x}_* - { bf mu})^ mathrm{T} { bf Lambda}) } + ( nu + 1) ln |{ bf W} ({ bf x}_*)^{-1}| right] + const. &amp;=&amp; - frac{1+ nu}{2} ln |({ bf x}_* - { bf mu})({ bf x}_* - { bf mu})^ mathrm{T} + { bf W}^{-1}| + const. &amp;=&amp; - frac{1+ nu}{2} ln |{ bf W}^{-1} { { bf W} ({ bf x}_* - { bf mu})({ bf x}_* - { bf mu})^ mathrm{T} + { bf I}_D }| + const. &amp;=&amp; - frac{1+ nu}{2} ln |{ bf W}^{-1}| |{ bf I}_D + { bf W} ({ bf x}_* - { bf mu})({ bf x}_* - { bf mu})^ mathrm{T}| + const. &amp;=&amp; - frac{1+ nu}{2} ln |{ bf I}_D + { bf W} ({ bf x}_* - { bf mu})({ bf x}_* - { bf mu})^ mathrm{T} | + const. &amp;=&amp; - frac{1+ nu}{2} ln |{ bf I}_1 + { { bf W} ({ bf x}_* - { bf mu}) }^ mathrm{T} ({ bf x}_* - { bf mu}) | + const.　(D times 1行列になっている) &amp;=&amp; - frac{1+ nu}{2} ln { 1 + ({ bf x}_* - { bf mu})^ mathrm{T} { bf W} ({ bf x}_* - { bf mu}) } + const. end{eqnarray} $$これは多次元のStudentのt分布になっている。 . . Important: 多次元のStudentのt分布: $$St({ bf x} | { bf mu}_s , { bf Lambda}_s , nu_s) = frac{ Gamma( frac{ nu_s + D}{2})}{ Gamma( frac{ nu_s}{2})} frac{|{ bf Lambda}_s|^{ frac{1}{2} } } {( pi nu_s)^{ frac{D}{2} }} left { 1 + frac{1}{ nu_s} ({ bf x} - { bf mu}_s)^ mathrm{T} { bf Lambda}_s ({ bf x} - { bf mu}_s) right }^{- frac{ nu_s + D}{2} }$$ . これを対数化して${ bf x}$に関わる項だけ抜き出すと、 . $$ ln St({ bf x} | { bf mu}_s , { bf Lambda}_s , nu_s) = - frac{ nu_s + D}{2} ln left { 1 + frac{1}{ nu_s} ({ bf x} - { bf mu}_s)^ mathrm{T} { bf Lambda}_s ({ bf x} - { bf mu}_s) right } + const. $$対応を見ると学習前の予測分布$p({ bf x}_*)$は次のように表せる。 . $$ begin{eqnarray} p({ bf x}_*) &amp;=&amp; St({ bf x} | { bf mu}_s , { bf Lambda}_s , nu_s) ただし　{ bf mu}_s &amp;=&amp; { bf mu} { bf Lambda}_s &amp;=&amp; (1-D+ nu){ bf W} nu_s &amp;=&amp; 1-D+ nu end{eqnarray} $$学習後の予測分布$p({ bf x}_* | { bf X})$はこれに更新されたハイパーパラメータを代入することで求まる。 . &#24179;&#22343;&#12539;&#31934;&#24230;&#34892;&#21015;&#26410;&#30693; . &#12514;&#12487;&#12523;&#27083;&#31689; . 平均パラメータの事前分布をガウス分布、精度パラメータの事前分布をウィシャート分布と別々に決めてもいいが、ガウス・ウィシャート分布が尤度関数がガウス分布の場合の共役事前分布として知られている。 . . Important: ガウス・ウィシャート分布 $$NW({ bf mu}, { bf Lambda}|{ bf m}, beta, nu,{ bf W}) = mathcal{N}({ bf mu}|{ bf m}, ( beta { bf Lambda})^{-1}) mathcal{W} ({ bf Lambda}| nu, { bf W})$$ . ガウス・ウィシャート分布を事前分布とした場合のモデルは次のようになる。 . $$ begin{eqnarray} p({ bf X},{ bf x}_*,{ bf mu}, { bf Lambda}) &amp;=&amp; p({ bf X}|{ bf mu}, { bf Lambda})p({ bf x}_*|{ bf mu}, { bf Lambda}) p({ bf mu}) p({ bf Lambda}) p({ bf mu}, { bf Lambda}) &amp;=&amp; NW({ bf mu}, { bf Lambda}|{ bf m}, beta, nu,{ bf W}) end{eqnarray} $$ &#20107;&#24460;&#20998;&#24067;&#12398;&#25512;&#35542; . データ${ bf X}$を観測した後の事後分布を求める。 . $$ begin{eqnarray} p({ bf mu}, { bf Lambda}| { bf X}) &amp;=&amp; frac{p({ bf X}, { bf mu}, { bf Lambda})}{p({ bf X})} &amp;=&amp; frac{p({ bf mu}|{ bf Lambda}, { bf X}) p({ bf Lambda}|{ bf X}) p({ bf X}) }{p({ bf X})} &amp;=&amp; p({ bf mu}|{ bf Lambda}, { bf X}) p({ bf Lambda}|{ bf X}) end{eqnarray} $$1次元の場合と同様に、平均と精度の事後分布を別々に求めてみる。 . &#24179;&#22343;&#12398;&#20107;&#24460;&#20998;&#24067; . 平均未知の場合の事後分布で精度行列を$ beta { bf Lambda}$とおくことにより求まる。 . $$ begin{eqnarray} p({ bf mu}|{ bf Lambda}, { bf X}) &amp;=&amp; mathcal{N}({ bf mu}| hat{ bf m}, ( hat{ beta} { bf Lambda})^{-1}) ただし　 hat{ beta} &amp;=&amp; N + beta hat{ bf m} &amp;=&amp; frac{1}{ hat{ beta}}( Sigma_{n=1}^{N} { bf x}_n + beta { bf m}) end{eqnarray} $$ . Note: この部分の式変形 $$ begin{eqnarray} { bf Lambda}_{ bf mu} &amp;=&amp; beta { bf Lambda},　 hat{ bf Lambda}_{ bf mu} = hat{ beta} { bf Lambda}　とおいて平均未知の式を見れば、 hat{ beta} { bf Lambda} &amp;=&amp; N { bf Lambda} + beta { bf Lambda}　ゆえ hat{ beta} &amp;=&amp; N + beta hat{ bf m} &amp;=&amp; frac{1}{ hat{ beta} } hat{ bf Lambda}^{-1} ({ bf Lambda} Sigma_{n=1}^{N} { bf x}_n + beta { bf Lambda} { bf m}) &amp;=&amp; frac{1}{ hat{ beta} }( Sigma_{n=1}^{N} { bf x}_n + beta { bf m}) end{eqnarray}$$ . &#31934;&#24230;&#12398;&#20107;&#24460;&#20998;&#24067; . ベイズの定理より、 . $$ p({ bf mu}, { bf Lambda}| { bf X}) = frac{p({ bf X}|{ bf mu}, { bf Lambda})p({ bf mu},{ bf Lambda})}{p({ bf X})} $$が成り立つので、 . $$ begin{eqnarray} p({ bf mu}|{ bf Lambda}, { bf X}) p({ bf Lambda}|{ bf X}) &amp;=&amp; frac{p({ bf X}|{ bf mu}, { bf Lambda})p({ bf mu},{ bf Lambda})}{p({ bf X})} p({ bf Lambda}|{ bf X}) &amp;=&amp; frac{p({ bf X}|{ bf mu}, { bf Lambda})p({ bf mu},{ bf Lambda})}{p({ bf X})p({ bf mu}|{ bf Lambda}, { bf X})} ln p({ bf Lambda}|{ bf X}) &amp;=&amp; ln p({ bf X}|{ bf mu}, { bf Lambda}) + ln p({ bf mu},{ bf Lambda}) - ln p({ bf mu}|{ bf Lambda}, { bf X}) + const. &amp;=&amp; Sigma_{n=1}^{N} ln mathcal{N}({ bf x}_n|{ bf mu}, { bf Lambda}^{-1}) + ln NW({ bf mu}, { bf Lambda}|{ bf m}, beta, nu,{ bf W}) - ln mathcal{N}({ bf mu}| hat{ bf m}, ( hat{ beta} { bf Lambda})^{-1}) + const. &amp;=&amp; Sigma_{n=1}^{N} ln mathcal{N}({ bf x}_n|{ bf mu}, { bf Lambda}^{-1}) + ln mathcal{N}({ bf mu}|{ bf m}, ( beta { bf Lambda})^{-1}) + ln mathcal{W} ({ bf Lambda}| nu, { bf W}) - ln mathcal{N}({ bf mu}| hat{ bf m}, ( hat{ beta} { bf Lambda})^{-1}) + const. &amp;=&amp; - frac{1}{2} { Sigma_{n=1}^{N} ({ bf x}_n - { bf mu})^ mathrm{T} { bf Lambda} ({ bf x}_n - { bf mu}) - N ln |{ bf Lambda}| } - frac{ beta}{2} ({ bf mu} - { bf m})^ mathrm{T} { bf Lambda} ({ bf mu} - { bf m}) + frac{1}{2} ln | beta { bf Lambda}| + frac{ nu-D-1}{2} ln |{ bf Lambda}| - frac{1}{2} Tr({ bf W}^ mathrm{T} { bf Lambda}) + frac{ hat{ beta}}{2} ({ bf mu} - hat{ bf m})^ mathrm{T} { bf Lambda} ({ bf mu} - hat{ bf m}) - frac{1}{2} ln | hat{ beta} { bf Lambda}| + const. &amp;=&amp; - frac{1}{2} { Sigma_{n=1}^{N} ({ bf x}_n - { bf mu})^ mathrm{T} { bf Lambda} ({ bf x}_n - { bf mu}) - N ln |{ bf Lambda}| } - frac{ beta}{2} ({ bf mu} - { bf m})^ mathrm{T} { bf Lambda} ({ bf mu} - { bf m}) + frac{1}{2} ln |{ bf Lambda}| + frac{ nu-D-1}{2} ln |{ bf Lambda}| - frac{1}{2} Tr({ bf W}^{-1} { bf Lambda}) + frac{ hat{ beta}}{2} ({ bf mu} - hat{ bf m})^ mathrm{T} { bf Lambda} ({ bf mu} - hat{ bf m}) - frac{1}{2} ln |{ bf Lambda}| + const.　(| beta { bf Lambda}|= beta^{D} |{ bf Lambda}|だが対数を取っているのでconst.に吸収させている。) &amp;=&amp; frac{N+ nu-D-1}{2} ln |{ bf Lambda}| - frac{1}{2} Tr left[ { Sigma_{n=1}^{N} { bf x}_n { bf x}_n^ mathrm{T} + beta { bf m} { bf m}^ mathrm{T} - hat{ beta} hat{ bf m} hat{ bf m}^ mathrm{T} + { bf W}^{-1} } { bf Lambda} right] + const.　(スカラーはトレースを取ってまとめた) end{eqnarray} $$と整理できる。これをウィシャート分布の定義式と対応関係を取って . $$ begin{eqnarray} p({ bf Lambda}|{ bf X}) &amp;=&amp; mathcal{W}({ bf Lambda}| hat{ nu}, hat{ bf W}) ただし　 hat{ bf W}^{-1} &amp;=&amp; Sigma_{n=1}^{N} { bf x}_n { bf x}_n^ mathrm{T} + beta { bf m} { bf m}^ mathrm{T} - hat{ beta} hat{ bf m} hat{ bf m}^ mathrm{T} + { bf W}^{-1} hat{ nu} &amp;=&amp; N + nu end{eqnarray} $$&#20107;&#24460;&#20998;&#24067;&#12434;&#12414;&#12392;&#12417;&#12427; . 以上をまとめて事後分布は次のようになる。 . $$ begin{eqnarray} p({ bf mu}, { bf Lambda}|{ bf X}) &amp;=&amp; NW({ bf mu}, { bf Lambda}| hat{ bf m}, hat{ beta}, hat{ nu}, hat{ bf W}) ただし　 hat{ beta} &amp;=&amp; N + beta hat{ bf m} &amp;=&amp; frac{1}{ hat{ beta}}( Sigma_{n=1}^{N} { bf x}_n + beta { bf m}) ただし　 hat{ bf W}^{-1} &amp;=&amp; Sigma_{n=1}^{N} { bf x}_n { bf x}_n^ mathrm{T} + beta { bf m} { bf m}^ mathrm{T} - hat{ beta} hat{ bf m} hat{ bf m}^ mathrm{T} + { bf W}^{-1} hat{ nu} &amp;=&amp; N + nu end{eqnarray} $$ &#20104;&#28204;&#20998;&#24067;&#12398;&#23566;&#20986; . 今回も積分による導出を避けベイズの定理と対数で予測分布を導出する。また、記述がシンプルになるので事前分布を用いた予測分布を導出し後で更新されたハイパーパラメータを代入する。 . ベイズの定理により、予測分布$p({ bf x}_*)$は次のように表せる。 . $$ ln p({ bf x}_*) = ln p({ bf x}_*|{ bf mu}, { bf Lambda}) - ln p({ bf mu}, { bf Lambda}|{ bf x}_*) + const. $$$ ln p({ bf mu}, { bf Lambda}|{ bf x}_*)$は事後分布の計算結果を流用して . $$ begin{eqnarray} p({ bf mu}, { bf Lambda}|{ bf x}_*) &amp;=&amp; mathcal{N}({ bf mu}|{ bf m}({ bf x}_*), ((1+ beta){ bf Lambda})^{-1}) mathcal{W} ({ bf Lambda}|1+ nu,{ bf W}({ bf x}_*)) ただし　{ bf m}({ bf x}_*) &amp;=&amp; frac{ { bf x}_* + beta { bf m} }{1+ beta} { bf W}({ bf x}_*)^{-1} &amp;=&amp; frac{ beta}{1+ beta} ({ bf x}_* - { bf m})({ bf x}_* - { bf m})^ mathrm{T} + { bf W}^{-1} end{eqnarray} $$ . Note: ${ bf W}({ bf x}_*)$の導出。 $$ begin{eqnarray} { bf W}({ bf x}_*)^{-1} &amp;=&amp; { bf x}_* { bf x}_*^ mathrm{T} + beta { bf m}{ bf m}^ mathrm{T} - (1+ beta) { bf m}({ bf x}_*) { bf m}({ bf x}_*)^ mathrm{T} + { bf W}^{-1} &amp;=&amp; { bf x}_* { bf x}_*^ mathrm{T} + beta { bf m}{ bf m}^ mathrm{T} - frac{1}{1+ beta} ({ bf x}_* + beta { bf m}) ({ bf x}_* + beta { bf m})^ mathrm{T} + { bf W}^{-1} &amp;=&amp; (1- frac{1}{1+ beta}){ bf x}_* { bf x}_*^ mathrm{T} - frac{ beta}{1+ beta} { bf x}_* { bf m}^ mathrm{T} - frac{ beta}{1+ beta} { bf x}_*^ mathrm{T} { bf m} + ( beta - frac{ beta^2}{1+ beta}) { bf m} { bf m}^ mathrm{T} + { bf W}^{-1} &amp;=&amp; frac{ beta}{1+ beta} ({ bf x}_* - { bf m})({ bf x}_* - { bf m})^ mathrm{T} + { bf W}^{-1} end{eqnarray}$$ . これを使って計算する。 . $$ begin{eqnarray} ln p({ bf x}_*) &amp;=&amp; ln p({ bf x}_*|{ bf mu}, { bf Lambda}) - ln p({ bf mu}, { bf Lambda}|{ bf x}_*) + const. &amp;=&amp; ln mathcal{N} ({ bf x}_*|{ bf mu}, { bf Lambda}^{-1}) - ln mathcal{N}({ bf mu}|{ bf m}({ bf x}_*), ((1+ beta){ bf Lambda})^{-1}) - ln mathcal{W} ({ bf Lambda}|1+ nu,{ bf W}({ bf x}_*)) + const. &amp;=&amp; - frac{1}{2} ({ bf x}_* - { bf mu})^ mathrm{T} { bf Lambda} ({ bf x}_* - { bf mu}) + frac{1+ beta}{2} ({ bf mu}-{ bf m}({ bf x}_*))^ mathrm{T} { bf Lambda} ({ bf mu}-{ bf m}({ bf x}_*)) + frac{1}{2} Tr({ bf W}({ bf x}_*)^{-1} { bf Lambda}) + frac{1+ nu}{2} ln |{ bf W}({ bf x}_*)| + cosnt. &amp;=&amp; - frac{1}{2} Tr left[ { ({ bf x}_* - { bf mu})({ bf x}_* - { bf mu})^ mathrm{T} - (1+ beta) ({ bf mu}-{ bf m}({ bf x}_*)) ({ bf mu}-{ bf m}({ bf x}_*))^ mathrm{T} - { bf W}({ bf x}_*)^{-1} } { bf Lambda} right] - frac{1+ nu}{2} ln |{ bf W}({ bf x}_*)^{-1}| end{eqnarray} $$トレースの計算。和のトレースはトレースの和であることを利用し、${ bf x}_*$に関わらない部分はconst.にまとめる。 . $$ begin{eqnarray} トレース部分 &amp;=&amp; Tr left[ { ({ bf x}_* - { bf mu})({ bf x}_* - { bf mu})^ mathrm{T} - (1+ beta) ({ bf mu}-{ bf m}({ bf x}_*)) ({ bf mu}-{ bf m}({ bf x}_*))^ mathrm{T} - { bf W}({ bf x}_*)^{-1} } { bf Lambda} right] &amp;=&amp; Tr left[ { { bf x}_* { bf x}_*^ mathrm{T} - { bf mu} { bf x}_*^ mathrm{T} - { bf x}_* { bf mu}^ mathrm{T} + (1+ beta) { bf mu} { bf m}({ bf x}_*)^ mathrm{T} + (1+ beta) { bf m}({ bf x}_*) { bf mu}^ mathrm{T} - (1+ beta) { bf m}({ bf x}_*) { bf m}({ bf x}_*)^ mathrm{T} - frac{ beta}{1+ beta} { bf x}_* { bf x}_*^ mathrm{T} + frac{ beta}{1+ beta} { bf m} { bf x}_*^ mathrm{T} + frac{ beta}{1+ beta} { bf x}_* { bf m}^ mathrm{T} } { bf Lambda} right] + cosnt. &amp;=&amp; Tr left[ { { bf x}_* { bf x}_*^ mathrm{T} - { bf mu} { bf x}_*^ mathrm{T} - { bf x}_* { bf mu}^ mathrm{T} + { bf mu} { bf x}_*^ mathrm{T} + { bf x}_* { bf mu}^ mathrm{T} - frac{1}{1+ beta}({ bf x}_* + beta { bf m})({ bf x}_*^ mathrm{T} + beta { bf m}^ mathrm{T}) - frac{ beta}{1+ beta} { bf x}_* { bf x}_*^ mathrm{T} + frac{ beta}{1+ beta} { bf m} { bf x}_*^ mathrm{T} + frac{ beta}{1+ beta} { bf x}_* { bf m}^ mathrm{T} } { bf Lambda} right] + cosnt. &amp;=&amp; const. end{eqnarray} $$結局${ bf x}_*$に関わる部分は消えてしまう。 . $$ begin{eqnarray} ln p({ bf x}_*) &amp;=&amp; - frac{1+ nu}{2} ln |{ bf W}({ bf x}_*)^{-1}| + const. &amp;=&amp; - frac{1+ nu}{2} ln | frac{ beta}{1+ beta} ({ bf x}_* - { bf m})({ bf x}_* - { bf m})^ mathrm{T} + { bf W}^{-1}| + const. &amp;=&amp; - frac{1+ nu}{2} ln { 1 + frac{ beta}{1+ beta} ({ bf x}_* - { bf m})^ mathrm{T} { bf W} ({ bf x}_* - { bf m}) } + const.　(精度未知の時と同様に式変形を行った。) end{eqnarray} $$これは多次元のStudentのt分布の対数表現である。対応をとって . $$ begin{eqnarray} p({ bf x}_*) &amp;=&amp; St({ bf x}_* | { bf mu}_s, { bf Lambda}_s, nu_s) ただし　{ bf mu}_s &amp;=&amp; { bf m} { bf Lambda}_s &amp;=&amp; frac{(1-D+ nu) beta}{1+ beta} { bf W} nu_s &amp;=&amp; 1 - D + nu end{eqnarray} $$となる。学習後の予測分布は更新されたハイパーパラメータを代入することで求まる。 . Julia&#12395;&#12424;&#12427;&#23455;&#35013; . 平均未知・精度行列未知の場合のみ実装します。 . D=2, N=100とします。 . # 乱数生成のためのパッケージ using Random # 行列計算用のパッケージ using LinearAlgebra # グラフ描画用のパッケージ ENV[&quot;GKS_ENCODING&quot;]=&quot;utf8&quot; # Plot内でunicode使うためのおまじない using Plots using Plots.PlotMeasures using StatsPlots # 確率分布の関数を呼び出すパッケージ using Distributions . # 真の分布のパラメータ mu_true = [5., 10.] Sigma_true = [5. 0.5;0.5 5.] Lambda_true = inv(Sigma_true) # 0~100までの数列 Ns = 0:100; . # 100個のデータ Random.seed!(12) data = rand(MvNormal(mu_true, Sigma_true), last(Ns)) # 最初の5個 data[:, 1:5] . 2×5 Array{Float64,2}: 4.51187 6.34995 9.50191 4.78056 -1.47009 6.12032 9.66378 12.1489 10.295 9.9565 . data[:,1:100] * data[:,1:100]&#39; . 2×2 Array{Float64,2}: 3182.96 5309.36 5309.36 11050.5 . #hide_output D=2 # 事前分布のハイパーパラメータ m = [1., 1.] beta = 1. nu = 2. # &gt;D-1である W = [1. 0. ;0. 1.] # ベイズ推論の進行過程をアニメーションに animation = @animate for i = 1:100 # ハイパーパラメータを更新 beta_hat = i + beta m_hat = vec((sum(data[:, 1:i], dims=2) .+ beta .* m) ./ beta_hat) nu_hat = i + nu Sigma_xn_xn = sum([data[:,j]*data[:,j]&#39; for j = 1:i]) W_hat = Matrix(Hermitian(inv(Sigma_xn_xn .+ beta .* (m * m&#39;) .- beta_hat .* (m_hat * m_hat&#39;) .+ inv(W)))) # 事後確率分布 updated_Wishart = Wishart(nu_hat, W_hat) updated_Normal = MvNormal(m_hat,　beta_hat .* Matrix(Hermitian(inv(rand(updated_Wishart))))) # 予測分布のパラメータ mu_s = m_hat Lambda_s = ((1-D+nu_hat)*beta_hat/(1+beta_hat)) .* W_hat nu_s = 1 - D + nu_hat # 予測分布 predict = MvTDist(nu_s, mu_s, inv(Lambda_s)) # 描画用の関数 x1 = 0. :0.1: 10. x2 = 5. :0.1: 15. # 平均の事後分布 コードだけ # pdf_post(x, y) = pdf(updated_Normal, [x, y]) # pdf_post.(x1,x2&#39;) == [pdf_post(x, y) for x in x1, y in x2 ] # p1 = contour(x1,x2,pdf_post.(x1,x2&#39;)) # 予測分布 pdf_predict(x, y) = pdf(predict, [x, y]) pdf_predict.(x1,x2&#39;) == [pdf_predict(x, y) for x in x1, y in x2] p2 = contour(x1,x2,pdf_predict.(x1,x2&#39;)) # 真の分布 pdf_true(x, y) = pdf(MvNormal(mu_true, Sigma_true), [x, y]) pdf_true.(x1,x2&#39;) == [pdf_true(x, y) for x in x1, y in x2] contour!(p2, x1,x2,pdf_true.(x1,x2&#39;)) plot(p2, title=&quot;iter=$i&quot;) end; gif(animation, &quot;animations/mgauss_ml.gif&quot;, fps = 15) . . 1. 須山敦志. 杉山将. ベイズ推論による機械学習入門. 講談社, 2017.↩ .",
            "url": "https://vintea01.github.io/tpt-medical-it/bayes/2020/04/06/bayes-part4.ipynb.html",
            "relUrl": "/bayes/2020/04/06/bayes-part4.ipynb.html",
            "date": " • Apr 6, 2020"
        }
        
    
  
    
        ,"post7": {
            "title": "ベイズ勉強会 Part 3 1次元ガウス分布のベイズ推論",
            "content": "ベイズ勉強会資料は『ベイズ推論による機械学習入門』1を元に、途中式計算をできるだけ省略せずに行ったものです。 . 1&#27425;&#20803;&#12460;&#12454;&#12473;&#20998;&#24067; . 1次元のガウス分布(以下本ページでは単に「ガウス分布」と呼ぶ)は、次の確率密度関数で表される$x in mathbb{R}$を生成する確率分布である。 . . Important: 1次元ガウス分布の確率密度関数$$ mathcal{N}(x| mu, sigma^2) = frac{1}{ sqrt{2 pi sigma^2}} exp {- frac{(x- mu)^2}{2 sigma^2} }$$ . パラメータは$ mu in mathbb{R}, sigma^2 in mathbb{R^+}$の2つで、それぞれ平均と分散である。精度パラメータ$ lambda = sigma^{-2}$を用いて書くこともある。精度で書くと以下のようになる。 . . Important: 精度で表した1次元ガウス分布の確率密度関数$$ mathcal{N}(x| mu, lambda^{-1}) = frac{1}{ sqrt{2 pi}} lambda^{ frac{1}{2}}exp {- frac{1}{2}(x- mu)^2 lambda }$$ . 以下、観測されたデータ$ mathcal{D}= {x_1, dots,x_N }$の各点$x_n$と未知の観測$x_*$は同じ1次元ガウス分布から独立に生成されたと仮定してベイズ推論を行う。 . &#24179;&#22343;&#12364;&#26410;&#30693;&#12289;&#31934;&#24230;&#12364;&#26082;&#30693;&#12398;&#22580;&#21512; . ガウス分布の2つのパラメータのうち、精度パラメータ$ lambda$が既知である状況でベイズ推論を行う。 . &#12514;&#12487;&#12523;&#12398;&#27083;&#31689; . 平均$ mu$だけが未知という条件で、尤度関数をガウス分布にした場合、そのパラメータ$ mu$の事前分布はどうすればよいだろうか。$ mu$の条件は$ mu in mathbb{R}$であることのみであり、実数を1つ出力する分布を事前分布とすればベイズ推論ができそうだ。このような分布は様々だが、1次元ガウス分布を用いることで事後分布も1次元ガウス分布となることが知られている。つまり尤度関数が1次元ガウス分布の場合の共役事前分布は1次元ガウス分布である。これを用いて同時分布を構築すると以下のようになる。 . $$ begin{eqnarray} p( mathcal{D},x_*, mu) &amp;=&amp; p( mathcal{D}| mu)p(x_*| mu)p( mu) p( mathcal{D}| mu) &amp;=&amp; Pi_{n=1}^{N} mathcal{N}(x_n| mu, lambda^{-1}) p(x_*| mu) &amp;=&amp; mathcal{N}(x_*| mu, lambda^{-1}) p( mu) &amp;=&amp; mathcal{N}( mu|m, lambda_{ mu}^{-1}) end{eqnarray} $$$p( mu)$の$m in mathbb{R}, lambda_{ mu} in mathbb{R^+}$は固定されたハイパーパラメータである。 . &#20107;&#24460;&#20998;&#24067;&#12398;&#25512;&#35542; . 事後分布$p( mu| mathcal{D})$を求める。ベイズの定理から次のように書ける。分母は形状には関わらないので省く。 . $$ begin{eqnarray} p( mu| mathcal{D}) &amp; propto&amp; p( mathcal{D}| mu) p( mu) &amp;=&amp; { Pi_{n=1}^{N} p(x_n| mu) }p( mu) &amp;=&amp; { Pi_{n=1}^{N} mathcal{N}(x_n| mu, lambda^{-1}) } mathcal{N}( mu|m, lambda_{ mu}^{-1}) end{eqnarray} $$対数をとると、 . $$ begin{eqnarray} ln p( mu| mathcal{D}) &amp;=&amp; Sigma_{n=1}^{N} ln mathcal{N}(x_n| mu, lambda^{-1}) + ln mathcal{N}( mu|m, lambda_{ mu}^{-1}) + const. &amp;=&amp; Sigma_{n=1}^{N} {- frac{1}{2}(x_n- mu)^2 lambda } + {- frac{1}{2}( mu-m)^2 lambda_{ mu} } + const. &amp;=&amp; - frac{1}{2} left[ Sigma_{n=1}^{N} {(x_n^2 -2x_n mu + mu^2) lambda } + ( mu^2 - 2 mu m + m^2) lambda_{ mu} right] + const. &amp;=&amp; - frac{1}{2} {(N lambda + lambda_{ mu}) mu^2 - 2( Sigma_{n=1}^{N} x_n lambda + m lambda_{ mu}) mu } + const. end{eqnarray} $$最後の変形では$ mu$に関わらない値は$const.$に吸収させている。これを平方完成するとガウス分布の形になっていることがわかるがここでは結果から逆算的に求める。事後分布が次のようなガウス分布で書けるとする。 . $$ p( mu| mathcal{D}) = mathcal{N}( mu| hat{m}, hat{ lambda_{ mu}}^{-1}) $$対数をとると . $$ begin{eqnarray} ln p( mu| mathcal{D}) &amp;=&amp; - frac{1}{2}( mu- hat{m})^2 hat{ lambda_{ mu}} &amp;=&amp; - frac{1}{2} { hat{ lambda_{ mu}} mu^2 - 2 hat{m} hat{ lambda_{ mu}} mu } + const. end{eqnarray} $$となるので、事後分布のパラメータ$ hat{m}, hat{ lambda_{ mu}}$は次のように求まる。 . $$ begin{eqnarray} hat{ lambda_{ mu}} &amp;=&amp; N lambda + lambda_{ mu} hat{m} &amp;=&amp; frac{ lambda Sigma_{n=1}^{N} x_n + lambda_{ mu}m}{ hat{ lambda_{ mu}}} end{eqnarray} $$以上で事後分布の推論が完了した。 . . Note: 更新された精度パラメータは、ハイパーパラメータに$N lambda$だけ加えたものでありデータ数$N$が大きくなる程精度が上がる、すなわち事後分布のばらつきが小さくなりかつハイパーパラメータの影響が小さくなることを示している。平均パラメータはハイパーパラメータ$m$と$ Sigma{n=1}^{N}x_n$の重み付き和の形になっておりこれもデータ数が増えるほどハイパーパラメータの影響を受けにくくなることがわかる。 . &#20104;&#28204;&#20998;&#24067;&#12398;&#31639;&#20986; . モデル全体の事後分布をパラメータ$ mu$で周辺化することで未知の観測$x_*$に対する予測分布が得られる。ハット記号を付けるのが面倒なので、学習していない事前分布から予測分布を算出し、後で更新されたパラメータを代入してみることにする。 . $$ begin{eqnarray} p(x_*) &amp;=&amp; int p(x_*| mu) p( mu) d mu &amp;=&amp; int mathcal{N}(x_*| mu, lambda^{-1}) mathcal{N}( mu|m, lambda_{ mu}^{-1}) d mu end{eqnarray} $$これを直接計算するのは大変なので、ベイズの定理と対数をうまく使ってみる。ベイズの定理から、 . $$ p( mu|x_*) = frac{p(x_*| mu)p( mu)}{p(x_*)} $$$p(x_*)$を左辺に置いて対数をとると、 . $$ ln p(x_*) = ln p(x_*| mu) - ln p( mu|x_*) + const. $$$ ln p( mu)$は$x_*$には関係ないので$const.$とした。$p( mu|x_*)$は$p( mu| mathcal{D})$に$ mathcal{D}=x_*$とすれば求まる。 . $$ begin{eqnarray} p( mu|x_*) &amp;=&amp; mathcal{N}( mu|m(x_*), ( lambda + lambda_{ mu})^{-1}) ただし　m(x_*) &amp;=&amp; frac{ lambda x_* + lambda_{ mu}m}{ lambda + lambda_{ mu}} end{eqnarray} $$これと$p(x_*| mu) = mathcal{N}( mu, lambda^{-1})$を代入すると . $$ begin{eqnarray} ln p(x_*) &amp;=&amp; ln p(x_*| mu) - ln p( mu|x_*) + const. &amp;=&amp; - frac{1}{2} { lambda (x_* - mu)^2 - ( lambda + lambda_{ mu})( mu - m(x_*))^2 } + const. &amp;=&amp; - frac{1}{2} { lambda x_*^2 - 2 lambda mu x_* - frac{ lambda^2 x_*^2 + 2 lambda lambda_{ mu} m x_*}{ lambda + lambda_{ mu}} + 2 lambda mu x_* } + const. &amp;=&amp; - frac{1}{2} { frac{ lambda^2 x_*^2 + lambda lambda_{ mu} x_*^2 - lambda^2 x_*^2 - 2 lambda lambda_{ mu} m x_*}{ lambda + lambda_{ mu}} } + const. &amp;=&amp; - frac{1}{2} { frac{ lambda lambda_{ mu}}{ lambda + lambda_{ mu}} x_*^2 - frac{2m lambda lambda_{ mu}}{ lambda + lambda_{ mu}} x_* } + const. end{eqnarray} $$$x_*$の2次関数の形にできたので事後分布と同じく逆算的に計算すると、予測分布$p(x_*)$は . $$ begin{eqnarray} p(x_*) &amp;=&amp; mathcal{N} (x_* | mu_*, lambda_{*}^{-1}) ただし　 lambda_* &amp;=&amp; frac{ lambda lambda_{ mu}}{ lambda + lambda_{ mu}} mu_* &amp;=&amp; m end{eqnarray} $$となる。これに$ hat{m}, hat{ lambda_{ mu}}$を代入することで学習した後の予測分布$p(x_*| mathcal{D})$は . $$ begin{eqnarray} p(x_*) &amp;=&amp; mathcal{N} (x_* | mu_*, lambda_{*}^{-1}) ただし　 lambda_* &amp;=&amp; frac{ lambda (N lambda + lambda_{ mu})}{ lambda + (N lambda + lambda_{ mu})} mu_* &amp;=&amp; frac{ lambda Sigma_{n=1}^{N} x_n + lambda_{ mu}m}{N lambda + lambda_{ mu}} end{eqnarray} $$と求まる。 . . Note: 精度から見た結果の意味 . 精度について逆数をとると意味がわかりやすい。 . $$ lambda_*^{-1} = lambda^{-1} + hat{ lambda_{ mu}}^{-1}$$精度の逆数は分散なので、この式は「予測分布の分散は観測分布の分散と事後分布の分散の和である」という意味になる。 . 今回は観測分布の分散が実際の分散に等しいことを仮定しているので、データ数が増え事後分布の分散が小さくなれば予測分布は実際の分布の分散とほぼ一致する。 . &#24179;&#22343;&#12364;&#26082;&#30693;&#12289;&#31934;&#24230;&#12364;&#26410;&#30693;&#12398;&#22580;&#21512; . 今度は、平均パラメータ$ mu$が既知で、精度パラメータ$ lambda$が未知の場合でベイズ推論を行う。 . &#12514;&#12487;&#12523;&#12398;&#27083;&#31689; . 精度パラメータ$ lambda$は正の実数である必要がある。正の実数を出力する確率分布にはガンマ分布があり、平均既知精度未知の場合の1次元ガウス分布の共役事前分布として知られている。事前分布にガンマ分布を採用すると次のようにモデル構築することになる。 . $$ begin{eqnarray} p( mathcal{D},x_*, lambda) &amp;=&amp; p( mathcal{D}| lambda)p(x_*| lambda)p( lambda) p( mathcal{D}| lambda) &amp;=&amp; Pi_{n=1}^{N} mathcal{N}(x_n| mu, lambda^{-1}) p(x_*| lambda) &amp;=&amp; mathcal{N}(x_*| mu, lambda^{-1}) p( lambda) &amp;=&amp; Gam( lambda|a, b) end{eqnarray} $$このモデルのハイパーパラメータは$a,b$である。$ mu$は既知の値という設定だが、$ mu$をハイパーパラメータとして推論していると考えることもできる。 . . Important: ガンマ分布 . ガンマ分布は$a, b in mathbb{R^+}$をパラメータに持ち、正の実数を生成する確率分布である。ガンマ分布の確率密度関数は次の通り。 . $$Gam( lambda|a,b) = C_G(a,b) lambda^{a-1}e^{-b lambda}$$$C_G(a,b)$は正規化係数であり、 . $$C_G(a,b) = frac{b^a}{ Gamma(a)}$$ &#20107;&#24460;&#20998;&#24067;&#12398;&#25512;&#35542; . 事後分布$p( lambda| mathcal{D})$を推論する。ベイズの定理から . $$ begin{eqnarray} p( lambda| mathcal{D}) &amp; propto&amp; p( mathcal{D}| lambda)p( lambda) &amp;=&amp; { Pi_{n=1}^{N} p(x_n| lambda) } p( lambda) &amp;=&amp; { Pi_{n=1}^{N} mathcal{N}(x_n| mu, lambda^{-1}) } Gam( lambda|a,b) end{eqnarray} $$対数をとる。 . $$ begin{eqnarray} ln p( lambda| mathcal{D}) &amp;=&amp; Sigma_{n=1}^{N} ln mathcal{N}(x_n| mu, lambda^{-1}) + ln Gam( lambda|a,b) + const. &amp;=&amp; Sigma_{n=1}^{N} { frac{1}{2} ln lambda - frac{(x_n- mu)^2 lambda}{2} } + (a-1) ln lambda -b lambda + const. &amp;=&amp; ( frac{N}{2}+a-1) ln lambda - { frac{1}{2} Sigma_{n=1}^{N}(x_n- mu)^2 + b } lambda + const. end{eqnarray} $$対数を戻せばこれはガンマ分布となることがわかる。 . $$ begin{eqnarray} p( lambda| mathcal{D}) &amp;=&amp; Gam( lambda| hat{a}, hat{b}) ただし　 hat{a} &amp;=&amp; frac{N}{2} + a hat{b} &amp;=&amp; frac{1}{2} Sigma_{n=1}^{N} (x_n- mu)^2 + b end{eqnarray} $$&#20104;&#28204;&#20998;&#24067;&#12398;&#31639;&#20986; . 事後分布の形状が事前分布と同じなので、学習前の予測分布$p(x_*)$を計算すれば、学習後の$ hat{a}, hat{b}$を代入するだけで$p(x_*| mathcal{D})$がわかる。 . $$ p(x_*) = int p(x_*| lambda)p( lambda) d lambda $$を直接計算せずにベイズの定理と対数計算で簡単に計算してみる。 . $$ p( lambda|x_*) = frac{p(x_*| lambda)p( lambda)}{p(x_*)} $$対数をとり、$p( lambda)$を定数にまとめれば . $$ ln p(x_*) = ln p(x_*| lambda) - ln p( lambda|x_*) + const. $$$ ln p( lambda|x_*)$は事後分布の形に合わせれば . $$ begin{eqnarray} p( lambda|x_*) &amp;=&amp; Gam( lambda| frac{1}{2}+a,b(x_*)) ただし　b(x_*) &amp;=&amp; frac{1}{2}(x_*- mu)^2 + b end{eqnarray} $$と書ける。これを代入して . $$ begin{eqnarray} ln p(x_*) &amp;=&amp; ln mathcal{N}(x_*| mu, lambda^{-1}) - ln Gam( lambda| frac{1}{2}+a,b(x_*)) + cosnt. &amp;=&amp; frac{1}{2} ln lambda - frac{(x_*- mu)^2 lambda}{2} - (a- frac{1}{2}) ln lambda + { frac{1}{2}(x_*- mu)^2 + b } lambda - ln C_G(a+ frac{1}{2}, frac{1}{2}(x_*- mu)^2 + b) + const. &amp;=&amp; - (a+ frac{1}{2}) ln { frac{1}{2}(x_*- mu)^2 + b } + Gamma(a+ frac{1}{2}) + const. &amp;=&amp; - frac{2a+1}{2} ln { 1 + frac{1}{2b}(x_*- mu)^2 } + const. end{eqnarray} $$となる。途中、$x_*$を含まない項は$const.$に吸収させている。また、$ lambda$に関わる項は消えている。この結果は1次元のStudentのt分布に対数をとったものと同じ形になっている。 . . Important: 1次元のStudentのt分布 . 1次元のStudentのt分布は次の確率密度関数で表される。 . $$St(x| mu_s, lambda_s, nu_s) = frac{ Gamma( frac{ nu_s + 1}{2})}{ Gamma( frac{ nu_s}{2})}( frac{ lambda_s}{ pi nu_s})^{ frac{1}{2}} { 1 + frac{ lambda_s}{ nu_s} (x- mu_s)^2 }^{- frac{ nu_s+1}{2}}$$対数をとり$x$に関わらない部分をconst.にまとめると . $$ ln St(x| mu_s, lambda_s, nu_s) = - frac{ nu_s+1}{2} ln { 1 + frac{ lambda_s}{ nu_s} (x- mu_s)^2 } + const.$$ 対数t分布との対応を見れば、予測分布は次のように書けることがわかる。 . $$ begin{eqnarray} p(x_*) &amp;=&amp; St(x_*| mu_s, lambda_s, nu_s) ただし　 mu_s &amp;=&amp; mu lambda_s &amp;=&amp; frac{a}{b} nu_s &amp;=&amp; 2a end{eqnarray} $$学習により更新された$ hat{a}, hat{b}$を代入すると次のようになる。 . $$ begin{eqnarray} p(x_*| mathcal{D}) &amp;=&amp; St(x_*| mu_s, lambda_s, nu_s) ただし　 mu_s &amp;=&amp; mu lambda_s &amp;=&amp; frac{N+2a}{ Sigma_{n=1}^{N} (x_n- mu)^2 + 2b} nu_s &amp;=&amp; N + 2a end{eqnarray} $$ &#24179;&#22343;&#12392;&#31934;&#24230;&#12364;&#12392;&#12418;&#12395;&#26410;&#30693;&#12398;&#22580;&#21512; . 次に、平均と精度がともに未知の場合のベイズ推論を実践してみる。モデルのパラメータが2個になっても、やることは変わらない。 . &#12514;&#12487;&#12523;&#12398;&#27083;&#31689; . 平均についてガウス事前分布を、精度についてガンマ事前分布をそれぞれ設定し次のような同時分布を作ることも可能である(尤度関数は前と同じなので省略)。 . $$ begin{eqnarray} p( mathcal{D},x_*, mu, lambda) &amp;=&amp; p( mathcal{D}| mu, lambda^{-1})p(x_*| mu, lambda^{-1})p( mu)p( lambda) p( mu) &amp;=&amp; mathcal{N}( mu|m, lambda_{ mu}^{-1}) p( lambda) &amp;=&amp; Gam( lambda|a,b) end{eqnarray} $$が、実はガウス・ガンマ分布という事前分布を用いると事後分布もガウス・ガンマ分布となることが知られている。ここではガウス・ガンマ分布を用いる。 . . Important: ガウス・ガンマ分布 . ガウス・ガンマ分布は$m, beta, a, b$をパラメータに持ち、$ mu, lambda$という2つの確率変数を生成する確率分布である。確率密度関数は次のように書ける。 . $$ begin{eqnarray} p( mu, lambda) &amp;=&amp; NG( mu, lambda|m, beta,a,b) &amp;=&amp; mathcal{N}( mu|m,( beta lambda)^{-1})Gam( lambda|a,b) end{eqnarray} $$ . ガウス事前分布・ガンマ事前分布を別々に設定する場合との違いは$ mu$が$ lambda$に条件づけられていることである。グラフィカルモデルで示すと次のようになる。 . . . ガウス・ガンマ分布を使った場合モデルは次のようになる(尤度関数は省略)。 . $$ begin{eqnarray} p( mathcal{D},x_*, mu, lambda) &amp;=&amp; p( mathcal{D}| mu, lambda^{-1})p(x_*| mu, lambda^{-1})p( mu, lambda) p( mu, lambda) &amp;=&amp; NG( mu, lambda|m, beta,a,b) end{eqnarray} $$&#20107;&#24460;&#20998;&#24067;&#12398;&#25512;&#35542; . $ mu$が$ lambda$に条件づけられているので、同時分布$p( mathcal{D}, mu, lambda)$は次のように変形できる。 . $$ p( mathcal{D}, mu, lambda) = p( mu| lambda, mathcal{D})p( lambda| mathcal{D})p( mathcal{D}) $$未観測の変数の事後分布は同時分布を観測された変数の確率で割ることで求まるのでこの場合の事後分布は、 . $$ frac{p( mathcal{D}, mu, lambda)}{p( mathcal{D})} = p( mu| lambda, mathcal{D})p( lambda| mathcal{D}) $$より、$p( mu| lambda, mathcal{D})p( lambda| mathcal{D})$のことを指す。 . &#24179;&#22343;&#12395;&#27880;&#30446; . まず平均にのみ注目し$p( mu| lambda, mathcal{D})$について考える。平均未知精度既知の場合の事後分布の結果に対し$ lambda$を$ beta lambda$に置き換えれば、 . $$ begin{eqnarray} p( mu| lambda, mathcal{D}) &amp;=&amp; mathcal{N}( mu| hat{m},( hat{ beta} lambda)^{-1}) ただし　 hat{ beta} &amp;=&amp; N + beta hat{m} &amp;=&amp; frac{1}{ hat{ beta}}( Sigma_{n=1}^{N} x_n + beta m) end{eqnarray} $$ . Note: 置き換えによって$ lambda_{ mu}= beta lambda$となっていることを利用した。 . &#31934;&#24230;&#12395;&#27880;&#30446; . 次に精度に関わる部分$p( lambda| mathcal{D})$を求める。同時分布から、 . $$ begin{eqnarray} p( lambda| mathcal{D}) &amp;=&amp; frac{p( mathcal{D}, mu, lambda)}{p( mu| lambda, mathcal{D})p( mathcal{D})} &amp; propto&amp; frac{p( mathcal{D}, mu, lambda)}{p( mu| lambda, mathcal{D})} &amp;=&amp; frac{p( mathcal{D}| mu, lambda)p( mu, lambda)}{p( mu| lambda, mathcal{D})} &amp;=&amp; frac{ { Pi_{n=1}^{N} mathcal{N}(x_n| mu, lambda^{-1}) } mathcal{N}( mu|m,( beta lambda)^{-1})Gam( lambda|a,b)}{ mathcal{N}( mu| hat{m},( hat{ beta} lambda)^{-1})} end{eqnarray} $$対数をとって整理していく。 . $$ begin{eqnarray} ln p( lambda| mathcal{D}) &amp;=&amp; Sigma_{n=1}^{N} { ln mathcal{N}(x_n| mu, lambda^{-1}) } + ln mathcal{N}( mu|m,( beta lambda)^{-1}) + ln Gam( lambda|a,b) - ln mathcal{N}( mu| hat{m},( hat{ beta} lambda)^{-1}) + const. &amp;=&amp; Sigma_{n=1}^{N} { frac{1}{2} ln lambda - frac{(x_n- mu)^2 lambda}{2} } + frac{ ln beta + ln lambda}{2} - frac{( mu-m)^2 beta lambda}{2} + (a-1) ln lambda -b lambda - frac{ ln hat{ beta} + ln lambda}{2} + frac{( mu- hat{m})^2 hat{ beta} lambda}{2} + const. &amp;=&amp; ( frac{N}{2} + a - 1) ln lambda - frac{1}{2} { Sigma_{n=1}^{N} x_n^2 - 2 mu Sigma_{n=1}^{N} x_n + N mu^2 + beta mu^2 - 2 mu m beta + m^2 beta + 2 b - mu^2 hat{ beta} + 2 mu hat{m} hat{ beta} - hat{m}^2 hat{ beta} } lambda + const. &amp;=&amp; ( frac{N}{2} + a - 1) ln lambda - frac{1}{2} { Sigma_{n=1}^{N} x_n^2 + 2 mu( hat{m} hat{ beta}- Sigma_{n=1}^{N} x_n - m beta) + (N + beta - hat{ beta}) mu^2 + m^2 beta - hat{m}^2 hat{ beta} + 2b } lambda + const. &amp;=&amp; ( frac{N}{2} + a - 1) ln lambda - { frac{1}{2}( Sigma_{n=1}^{N} x_n^2 + beta m^2 - hat{ beta} hat{m}^2) + b } lambda + const. end{eqnarray} $$ガンマ分布の定義式と照らし合わせて . $$ begin{eqnarray} p( lambda| mathcal{D}) &amp;=&amp; Gam( lambda| hat{a}, hat{b}) ただし　 hat{a} &amp;=&amp; frac{N}{2} + a hat{b} &amp;=&amp; frac{1}{2}( Sigma_{n=1}^{N} x_n^2 + beta m^2 - hat{ beta} hat{m}^2) + b end{eqnarray} $$&#12414;&#12392;&#12417; . 結局求めたい事後分布$p( mu| lambda, mathcal{D})p( lambda| mathcal{D})$は更新されたハイパーパラメータ$ hat{m}, hat{ beta}, hat{a}, hat{b}$を持つガウス・ガンマ分布の形になる。 . $$ begin{eqnarray} p( mu| lambda, mathcal{D})p( lambda| mathcal{D}) &amp;=&amp; mathcal{N}( mu| hat{m},( hat{ beta} lambda)^{-1})Gam( lambda| hat{a}, hat{b}) &amp;=&amp; NG( mu, lambda| hat{m}, hat{ beta}, hat{a}, hat{b}) end{eqnarray} $$&#20104;&#28204;&#20998;&#24067;&#12398;&#23566;&#20986; . 事前分布と事後分布が同じ形状であるから、学習前の予測分布を導出し、更新されたハイパーパラメータを代入することで学習後の予測分布を求めることができる。 . 学習前の予測分布は以下のように2つの変数を積分除去することで求められる。 . $$p(x_*) = int int p(x_*| mu, lambda)p( mu, lambda)d mu d lambda$$ . でもできれば積分はしたくないのでベイズの定理から求めてみる。 . . Note: 積分は式変形も面倒だしコンピュータにとっても計算コストが高いのでできるだけしたくない。いかに積分を回避するかが肝。 . ベイズの定理から . $$ p( mu, lambda|x_*) = frac{p(x_*| mu, lambda)p( mu, lambda)}{p(x_*)} $$より . $$ ln p(x_*) = ln p(x_*| mu, lambda) - ln p( mu, lambda|x_*) + const. $$事後分布の結果を流用して、 . $$ begin{eqnarray} p( mu, lambda|x_*) &amp;=&amp; mathcal{N}( mu|m(x_*), {(1+ beta) lambda }^{-1})Gam( lambda| frac{1}{2}+a,b(x_*)) ただし　m(x_*) &amp;=&amp; frac{x_*+ beta m}{1+ beta} b(x_*) &amp;=&amp; frac{ beta}{2(1+ beta)}(x_*-m)^2 + b end{eqnarray} $$ . Note: $m(x_*),b(x_*)$の導出 . $ hat{m}, hat{b}$を$ mathcal{D}=x_*$として計算すると . $$ begin{eqnarray} hat{m} &amp;=&amp; frac{1}{ hat{ beta}}( Sigma_{n=1}^{N} x_n + beta m) &amp;=&amp; frac{1}{1+ beta}(x_*+ beta m) end{eqnarray} $$$$ begin{eqnarray} hat{b} &amp;=&amp; frac{1}{2}( Sigma_{n=1}^{N} x_n^2 + beta m^2 - hat{ beta} hat{m}^2) + b &amp;=&amp; frac{1}{2} {x_*^2 + beta m^2 - (1+ beta)( frac{x_*+ beta m}{1+ beta})^2 } + b &amp;=&amp; frac{1}{2(1+ beta)} {(1+ beta)(x_*^2+ beta m^2) - x_*^2 - 2x_* beta m - beta^2 m^2 } + b &amp;=&amp; frac{1}{2(1+ beta)} { beta x_*^2 - 2 beta x_* m + beta m^2 } +b &amp;=&amp; frac{ beta}{2(1+ beta)}(x_*-m)^2 + b end{eqnarray} $$ よって予測分布$p(x_*)$は . $$ begin{eqnarray} ln p(x_*) &amp;=&amp; ln mathcal{N}(x_*| mu, lambda) - ln mathcal{N}( mu|m(x_*), {(1+ beta) lambda }^{-1}) - ln Gam( lambda| frac{1}{2}+a,b(x_*)) + const. &amp;=&amp; frac{1}{2} ln lambda - frac{(x_*- mu)^2 lambda}{2} - frac{ ln(1+ beta) + ln lambda}{2} + frac{( mu-m(x_*))^2(1+ beta) lambda}{2} - (a- frac{1}{2}) ln lambda + b(x_*) lambda - ln C_G(a+ frac{1}{2}, b(x_*)) + const. &amp;=&amp; - frac{(x_*- mu)^2 lambda}{2}+ frac{( mu-m(x_*))^2(1+ beta) lambda}{2}+ b(x_*) lambda - (a+ frac{1}{2}) ln b(x_*) + const. end{eqnarray} $$ . Note: $x_*$について整理する。気合で計算する。 . $$ begin{eqnarray} ln p(x_*) &amp;=&amp; - frac{(1+ beta) lambda}{2(1+ beta)}x_*^2 + frac{2(1+ beta) mu lambda}{2(1+ beta)}x_* + frac{(1+ beta)^2 lambda}{2(1+ beta)}m(x_*)^2 - frac{2(1+ beta)^2 mu lambda}{2(1+ beta)} m(x_*) + frac{ beta lambda}{2(1+ beta)} x_*^2 - frac{2 beta m lambda}{2(1+ beta)}x_* - (a+ frac{1}{2}) ln b(x_*) + const. &amp;=&amp; frac{ beta lambda - (1+ beta) lambda}{2(1+ beta)} x_*^2 + frac{2(1+ beta) mu lambda - 2 beta m lambda}{2(1+ beta)} + frac{ lambda}{2(1+ beta)} x_*^2 + frac{2 beta m lambda}{2(1+ beta)} x_* - frac{2(1+ beta) mu lambda}{2(1+ beta)}x_* - (a+ frac{1}{2}) ln b(x_*) + const. &amp;=&amp; -(a+ frac{1}{2}) ln b(x_*) + const. &amp;=&amp; - frac{1+2a}{2} ln { frac{ beta}{2(1+ beta)}(x_*-m)^2 + b } + const. &amp;=&amp; - frac{1+2a}{2} ln {1 + frac{ beta}{2(1+ beta)b}(x_*-m)^2 } + const. end{eqnarray} $$これはStudentのt分布になる。 . $$ begin{eqnarray} p(x_*) &amp;=&amp; St(x_*| mu_s, lambda_s, nu_s) ただし　 mu_s &amp;=&amp; m lambda_s &amp;=&amp; frac{ beta a}{(1+ beta)b} nu_s &amp;=&amp; 2a end{eqnarray} $$ したがって学習後の予測分布$p(x_*| mathcal{D})$は更新されたハイパーパラメータを代入して . $$ begin{eqnarray} p(x_*| mathcal{D}) &amp;=&amp; St(x_*| mu_s, lambda_s, nu_s) ただし　 mu_s &amp;=&amp; frac{ Sigma_{n=1}^{N} x_n + beta m}{N+ beta} lambda_s &amp;=&amp; frac{N+ beta frac{N}{2}+a}{(1+N+ beta)( frac{ Sigma_{n=1}^{N} x_n^2 + beta m^2 - (N+ beta)( frac{ Sigma_{n=1}^{N} x_n + beta m}{N+ beta})^2}{2} + b)} nu_s &amp;=&amp; N + 2a end{eqnarray} $$疲れましたね。 . Julia&#12391;&#23455;&#35013; . &#35299;&#26512;&#35299; . # パッケージのimport # 乱数生成のためのパッケージ using Random # グラフ描画用のパッケージ using Plots # 確率分布の関数を呼び出すパッケージ using Distributions . # 真の分布のパラメータ mu_true = 5 sigma_true = 5 # 0~100までの数列 Ns = 0:100; . # 100個のデータ Random.seed!(12) data = rand(Normal(mu_true, sigma_true), last(Ns)) # 最初の5個 data[1:5] . 5-element Array{Float64,1}: 3.908514313490514 -3.6092237496539887 8.018578394019395 3.9410124050184745 15.066579706268774 . &#24179;&#22343;&#26410;&#30693; . #hide_output # 精度は既知 lambda = 1/sigma_true^2 # 事前分布のハイパーパラメータ m = 0 lambda_mu = 1 # アニメーションをつけるためにStatsPlotsパッケージをimport using StatsPlots # ベイズ推論の進行過程をアニメーションに animation = @gif for (i, N) in enumerate(Ns) # データ点の和を計算 sum_x = sum(data[1:i-1]) # ハイパーパラメータを更新 lambda_mu_hat = i * lambda + lambda_mu m_hat = (lambda * sum_x + lambda_mu * m)/lambda_mu_hat # 事後確率分布 updated_belief = Normal(m_hat, sqrt(1/lambda_mu_hat)) # 予測分布のパラメータ m_pred = m_hat lambda_pred = lambda * lambda_mu_hat / (lambda + lambda_mu_hat) # 予測分布 predict = Normal(m_pred, sqrt(1/lambda_pred)) # 描画用の関数 p1 = plot(updated_belief, size = (500, 250), xlabel = &quot;mu&quot;, ylabel = &quot;&quot;, legend = nothing, xlim = (mu_true-3*sigma_true,mu_true+3*sigma_true), fill=0, α=0.3, w=3) vline!(p1, [mu_true]) p2 = plot(predict, size = (500, 250), xlabel = &quot;x&quot;, ylabel = &quot;&quot;, legend = nothing, xlim = (mu_true-3*sigma_true,mu_true+3*sigma_true), fill=0, α=0.3, w=3) plot!(p2, Normal(mu_true, sigma_true),fill=0, α=0.2) plot(p1, p2, layout=(1,2), title = &quot;$N observations&quot;) end; . . &#31934;&#24230;&#26410;&#30693; . #hide_output # 平均は既知 mu = mu_true # 事前分布のハイパーパラメータ a = 1 b = 1 # ベイズ推論の進行過程をアニメーションに animation = @gif for (i, N) in enumerate(Ns) # ハイパーパラメータを更新 a_hat = i/2 + a b_hat = sum((data[1:i-1] .- mu).^2)/2 + b # 事後確率分布 updated_belief = Gamma(a_hat, 1/b_hat) # 予測分布のパラメータ mu_s = mu lambda_s = a_hat/b_hat nu_s = 2*a_hat # 予測分布 predict = LocationScale(mu_s, sqrt(1/lambda_s), TDist(nu_s)) # 描画用の関数 p1 = plot(updated_belief, size = (500, 250), xlabel = &quot;lambda&quot;, ylabel = &quot;&quot;, legend = nothing, xlim = (0, 2/sigma_true^2), fill=0, α=0.3, w=3) vline!(p1, [1/sigma_true^2]) p2 = plot(predict, size = (500, 250), xlabel = &quot;x&quot;, ylabel = &quot;&quot;, legend = nothing, xlim = (mu_true-3*sigma_true,mu_true+3*sigma_true), fill=0, α=0.3, w=3) plot!(p2, Normal(mu_true, sigma_true),fill=0, α=0.2) plot(p1, p2, layout=(1,2), title = &quot;$N observations&quot;) end; . . &#24179;&#22343;&#12539;&#31934;&#24230;&#26410;&#30693; . #hide_output # 事前分布のハイパーパラメータ m = 0 beta = 1 a = 1 b = 1 # ベイズ推論の進行過程をアニメーションに animation = @gif for (i, N) in enumerate(Ns) # ハイパーパラメータを更新 beta_hat = i + beta m_hat = (sum(data[1:i-1])+beta*m)/beta_hat a_hat = i/2 + a b_hat = (sum(data[1:i-1].^2) + beta*m^2 - beta_hat*m_hat^2)/2 + b # 事後確率分布 updated_gamma = Gamma(a_hat, 1/b_hat) updated_normal = Normal(m_hat, sqrt(1/(beta_hat*rand(updated_gamma)))) # 予測分布のパラメータ mu_s = m_hat lambda_s = beta_hat*a_hat/((1+beta_hat)*b_hat) nu_s = 2*a_hat # 予測分布 predict = LocationScale(mu_s, sqrt(1/lambda_s), TDist(nu_s)) # 描画用の関数 p1 = plot(updated_normal, size = (500, 250), xlabel = &quot;mu&quot;, ylabel = &quot;&quot;, legend = nothing, xlim = (mu_true-3*sigma_true,mu_true+3*sigma_true), fill=0, α=0.3, w=3) vline!(p1, [mu_true]) p2 = plot(updated_gamma, size = (500, 250), xlabel = &quot;lambda&quot;, ylabel = &quot;&quot;, legend = nothing, xlim = (0, 2/sigma_true^2), fill=0, α=0.3, w=3) vline!(p2, [1/sigma_true^2]) p3 = plot(predict, size = (500, 250), xlabel = &quot;x&quot;, ylabel = &quot;&quot;, legend = nothing, xlim = (mu_true-3*sigma_true,mu_true+3*sigma_true), fill=0, α=0.3, w=3) plot!(p3, Normal(mu_true, sigma_true),fill=0, α=0.2) plot(p1, p2, p3,layout=(1,3), title = &quot;$N observations&quot;) end; . . Turing.jl&#12395;&#12424;&#12427;&#12495;&#12511;&#12523;&#12488;&#12491;&#12450;&#12531;&#12514;&#12531;&#12486;&#12459;&#12523;&#12525; . # Load Turing and MCMCChains. using Turing, MCMCChains # Load the distributions library. using Distributions # Load StatsPlots for density plots. using StatsPlots . # @model gauss_model(y) = begin # # パラメータの分布 # lambda ~ Gamma(1 ,1) # mu ~ Normal(0, sqrt(1/(1*lambda))) # # Nは観測点の数 # N = length(y) # for n in 1:N # # 尤度関数 # y[n] ~ Normal(mu, sqrt(1/lambda)) # end # end; @model gauss_model(y) = begin # パラメータの分布 a = 1 b = 1 beta = 1 m = 0 lambda ~ Gamma(a ,b) mu ~ Normal(m, sqrt(1/(beta*lambda))) # Nは観測点の数 N = length(y) for n in 1:N # 尤度関数 y[n] ~ Normal(mu, sqrt(1/lambda)) end end; . # Settings of the Hamiltonian Monte Carlo (HMC) sampler. iterations = 4000 ϵ = 0.01 τ = 10 # 4チェーン作って収束をみる chains = psample(gauss_model(data), HMC(ϵ, τ), iterations, progress=false, 4) . Object of type Chains, with data of type 4000×11×4 Array{Float64,3} Iterations = 1:4000 Thinning interval = 1 Chains = 1, 2, 3, 4 Samples per chain = 4000 internals = acceptance_rate, hamiltonian_energy, hamiltonian_energy_error, is_accept, log_density, lp, n_steps, nom_step_size, step_size parameters = lambda, mu 2-element Array{ChainDataFrame,1} Summary Statistics parameters mean std naive_se mcse ess r_hat ────────── ────── ────── ──────── ────── ───────── ────── lambda 0.0345 0.0048 0.0000 0.0001 2518.4932 1.0013 mu 5.2872 0.5337 0.0042 0.0336 151.3972 1.0459 Quantiles parameters 2.5% 25.0% 50.0% 75.0% 97.5% ────────── ────── ────── ────── ────── ────── lambda 0.0258 0.0312 0.0343 0.0376 0.0445 mu 4.2179 4.9509 5.3070 5.6502 6.3011 . plot(chains) . 得られたMCMCサンプルからランダムにパラメータを選びガウス分布から乱数生成することを繰り返すと、予測分布からのMCMCサンプルが得られる2。 . # warm-upを排除してサンプルをえる chain1 = chains[1001:4000,:,1] mu_mcmc = chain1[:mu].value lambda_mcmc = chain1[:lambda].value predict_mcmc = zeros(3000) for i in 1:3000 mu_tmp = mu_mcmc[rand(1:3000)] lambda_tmp = lambda_mcmc[rand(1:3000)] x_tmp = rand(Normal(mu_tmp, sqrt(1/lambda_tmp))) predict_mcmc[i] = x_tmp end . # 厳密解を計算 N = length(data) # 事前分布のハイパーパラメータ m = 0 beta = 1 a = 1 b = 1 # ハイパーパラメータを更新 beta_hat = N + beta m_hat = (sum(data[1:N-1])+beta*m)/beta_hat a_hat = N/2 + a b_hat = (sum(data[1:N-1].^2) + beta*m^2 - beta_hat*m_hat^2)/2 + b # 事後分布 updated_gamma = Gamma(a_hat, 1/b_hat) updated_normal = Normal(m_hat, sqrt(1/(beta_hat*rand(updated_gamma)))) # 予測分布のパラメータ mu_s = m_hat lambda_s = beta_hat*a_hat/((1+beta_hat)*b_hat) nu_s = 2*a_hat # 予測分布 predict_dist = LocationScale(mu_s, sqrt(1/lambda_s), TDist(nu_s)) # 平均の事後分布のプロット p1 = plot(chains[:,:,1][:mu], seriestype = :density, xlim = (mu_true-3*sigma_true,mu_true+3*sigma_true), w = 2, c = :blue) # Visualize a green density plot of posterior distribution in closed-form. plot!(p1, updated_normal, xlabel = &quot;mu&quot;, ylabel = &quot;&quot;, title = &quot;&quot;, xlim = (mu_true-3*sigma_true,mu_true+3*sigma_true), label = &quot;Closed-form&quot;, fill=0, α=0.3, w=3, c = :lightgreen) # Visualize the true probability of heads in red. vline!(p1, [mu_true], label = &quot;True mu&quot;, c = :red) # 精度の事後分布のプロット p2 = plot(chains[:,:,1][:lambda], seriestype = :density, xlim = (0, 2/sigma_true^2), w = 2, c = :blue) # Visualize a green density plot of posterior distribution in closed-form. plot!(p2, updated_gamma, xlabel = &quot;labmda&quot;, ylabel = &quot;&quot;, title = &quot;&quot;, xlim = (0, 2/sigma_true^2), label = &quot;Closed-form&quot;, fill=0, α=0.3, w=3, c = :lightgreen) # Visualize the true probability of heads in red. vline!(p2, [(1/sigma_true)^2], label = &quot;True lambda&quot;, c = :red) plot(p1, p2, layout=(1,2)) . # 予測分布のプロット p3 = plot(predict_mcmc, seriestype=:density, xlim = (mu_true-3*sigma_true,mu_true+3*sigma_true), w = 2, c = :blue) plot!(p3, predict_dist, size = (500, 250), xlabel = &quot;x&quot;, ylabel = &quot;&quot;, legend = nothing, xlim = (mu_true-3*sigma_true,mu_true+3*sigma_true), fill=0, α=0.3, w=3, c = :lightgreen) . 1. 須山敦志. 杉山将. ベイズ推論による機械学習入門. 講談社, 2017.↩ . 2. 松浦健太郎. StanとRでベイズ統計モデリング. 共立出版, 2016.のChapter 2↩ .",
            "url": "https://vintea01.github.io/tpt-medical-it/bayes/2020/04/03/bayes_part3.html",
            "relUrl": "/bayes/2020/04/03/bayes_part3.html",
            "date": " • Apr 3, 2020"
        }
        
    
  
    
        ,"post8": {
            "title": "実践機械学習勉強会 Part 1 Metrics",
            "content": "参考図書 1 . &#22238;&#24112;&#21839;&#38988;&#65288;Regression&#65289;&#12395;&#20351;&#12431;&#12428;&#12427;&#35413;&#20385;&#25351;&#27161; . MSE, RMSE, R-squared | MAE | (R)MSPE, MAPE | (R)MSLE | . notation . $N$ : オブジェクト数 | $y in mathbb{R}^N$ : ターゲット値のN次元ベクトル | $ hat y in mathbb{R}^N$ : 予測値のN次元ベクトル | $y_i in mathbb{R}$ : オブジェクト$x_i$のターゲット値 | $ hat y_i in mathbb{R}$ : オブジェクト$x_i$の予測値 | . MSE, RMSE, R-squared . MSE: Mean Square Error . $$MSE(y, hat y)= frac{1}{N} sum^N_{i=1}(y_i- hat y_i)^2$$ . 評価指標の特性を考える際、一定の予測値$ hat y_i = alpha$がどの値をとる時に一番良い評価指標の値が得られるかを考えると良く、今回は . $$ min_{ alpha} f( alpha) = frac{1}{N} sum_{i=1}^N ( alpha - y_i)^2 $$のように$ alpha$に関して微分可能な関数$f( alpha)$の最小化問題に帰結できます。これを満たす$ alpha^*$の必要条件は . $$ frac{d f}{d alpha} bigg|_{ alpha= alpha^*} = 0 $$となります。よってこれを解くと、 $$ frac{d f}{d alpha} bigg|_{ alpha= alpha^*} = frac{2}{N} sum_{i=1}^N ( alpha^* - y_i) = 0 $$ . $$ frac{2}{N} sum_{i=1}^N alpha^* - frac{2}{N} sum_{i=1}^N y_i = 0 $$$$ alpha^* - frac{1}{N} sum_{i=1}^N y_i = 0 $$より、 $$ alpha^* = frac{1}{N} sum_{i=1}^N y_i(= bar y) $$ . $ alpha^*$における２次導関数 $ frac{d^2 f}{d alpha^2}$ は正なのでMSEにおけるbest constantは、ターゲット値の平均(target mean value)となります。 . RMSE: Root Mean Square Error . $$ RMSE= sqrt{MSE} $$$$ frac{ partial RMSE}{ partial hat y_i}= frac{1}{2 sqrt{MSE}} frac{ partial MSE}{ partial hat y_i} $$ R-squared . $$ R^2=1- frac{MSE}{ frac{1}{N} sum^N_{i=1}(y_i- bar y)^2} $$ &#26368;&#36969;&#21270;&#12398;&#20181;&#26041; . MSE・RMSE・R-squaredは基本的に同じ意味を持つ評価指標で、また最適化する際もそのまま目的関数として使用することができます。詳しくは各ライブラリのdocを読みましょう。 . MAE: Mean Absolute Error . $$ MAE(y, hat y) = frac{1}{N} sum_{i=1}^N | hat y_i - y_i| $$同様にbest constant $ alpha^*$を求めてみましょう。 $$ min_{ alpha} f( alpha) = frac{1}{N} sum_{i=1}^N | alpha - y_i| $$ . ここで $ frac{ partial |x|}{dx} = sign(x)$（$sign$ は 符号関数, signum functionを指す）であるので、 $$ frac{d f}{d alpha} bigg|_{ alpha= alpha^*} = frac{1}{N} sum_{i=1}^N sign( alpha^* - y_i) = 0 $$ . 定数項を無視すると、 $$ g( alpha^*) = sum_{i=1}^N sign( alpha^* - y_i) = 0 $$ をみたす $ alpha^*$ を求めればよいことが分かります。例えばここで、ターゲットのN次元ベクトルが$y=[-3,-1,-1.5,0,1,2,3]$とすると、$g( alpha)$のグラフは以下のようになります。 . #collapse-hide import numpy as np import matplotlib.pyplot as plt %matplotlib inline def sgn(x,y): if x &lt; y: return -1 elif x == y: return 0 else: return 1 def g(alpha,y): total = 0 for i in y: total += sgn(alpha,i) return total y = np.array([-3,-1,-1.5,0,1,2,3]) alpha = np.arange(y.min()-0.5,y.max()+0.5,0.01) median = np.median(y) gs_a = [] for a in alpha: gs_a.append(g(a,y)) gs_y = [] for yi in y: gs_y.append(g(yi,y)) plt.figure(figsize=(10,7)) plt.xlabel(&quot;α&quot;) plt.ylabel(&#39;g(α)&#39;) plt.xlim(alpha.min()-0.1,alpha.max()+0.1) plt.ylim(-len(y)-0.5,len(y)+0.5) plt.plot(alpha,gs_a,label=&#39;g(α)&#39;) plt.scatter(y,gs_y,label=&#39;g($y_i$)&#39;) plt.scatter(median,g(median,y),label=&#39;median&#39;) plt.legend(loc=&#39;upper left&#39;) plt.show() . . このように、値がN回不連続的に飛び飛びの値をとることがわかり、０になるには約$ frac{N}{2}$回飛ばなければならないことが分かります。グラフの様にその値はターゲットの中央値（target median）となることが分かります。Nが偶数奇数の場合分けが必要ですが、いずれの場合もbest constantはtarget medianとなります。 . . Note: MAEのbest constantはターゲットの中央値であることから、MAEはターゲットの外れ値（outliers）の影響を受けずらいことが分かる。一方MSEはoutliersの影響を受けやすい。よって、ターゲットにouteliersを含む場合はMAEがよりrobustな評価指標と言える。 . &#26368;&#36969;&#21270;&#12398;&#20181;&#26041; . MAEも目的関数として扱うことができますが、$ hat y_i=y_i$の時に微分可能でないのでsmoothingして0に近いエラーに関しても処理できるようにする必要があります。このsmoothingには様々な方法がありますが、有名なものにHuber lossがあります。0に近い時はMSE、エラーが大きい値ではMAEのような挙動を示す関数です。詳しくは各ライブラリのdocを読みましょう。 . (R)MSPE, MAPE: Percentage Error . 単純なMSEやMAEでは、ターゲットの値が大きい時に同じ精度の予測値に対して過小評価されてしまいます。例えば、 $$ MSE(10,9)=1 $$ $$ MSE(1000,900)=10000 $$ のように同じ90％の予測精度でもMSEの値が大きくなることが分かります。そこで、MSE・MAEそれぞれに対し、ターゲット値の逆数で重みを付けた評価指標がそれぞれMSPE・MAPEという訳です。 $$ MSPE(y, hat y)= frac{100 %}{N} sum^N_{i=1}( frac{y_i- hat y_i}{y_i})^2 $$ $$ MAPE(y, hat y)= frac{100 %}{N} sum^N_{i=1}| frac{y_i- hat y_i}{y_i}| $$ . それではそれぞれのbest constantはどの値をとるのでしょうか？ MSPE、MAPEそれぞれその値は重み付け平均値、重み付け中央値を取ります。小さい値のターゲットに重みを大きくつけた新しいターゲット値の平均、中央値という訳です。ターゲット値に$w_i= frac{1/y_i}{ sum^N_{i=1}1/y_i}$を付加した後、MSE・MAE同様の議論をすれば証明できます。 . &#26368;&#36969;&#21270;&#12398;&#20181;&#26041; . MSPE・MAPEを直接モデル最適化の目的関数として扱うことは難しく、以下のステップが必要となります。 . ターゲットの値を用いて各オブジェクト$x_i$に対してSample weights: $w_i$を対応させる | その重みに従って新たに元のデータからサンプリングを行う | サンプリングされた新たなデータセットに対して、MSE・MAEを適用する | $w_i$に関してはMSPE・MASEについてそれぞれ、 $$ MSPE: w_i= frac{1/y_i^2}{ sum^N_{i=1}1/y_i^2} $$ $$ MAPE: w_i= frac{1/y_i}{ sum^N_{i=1}1/y_i} $$ となります。 . . Note: $w_i$の合計は必ずしも１である必要はない。また、サンプル数はもとのデータセットのオブジェクト数Nを超えても良い。 . (R)MSLE: (Root) Mean Square Logarithmic Error . $$ RMSLE(y, hat y)= sqrt{ frac{1}{N} sum^N_{i=1}(log(y_i+1)-log( hat y_i+1))^2} =RMSE(log(y+1),log( hat y+1))= sqrt{MSE(log(y+1),log( hat y+1))} $$こちらもターゲットのスケールによる誤差の見積もり変化に対して、頑強な評価指標です。MSEの対数バージョンということですね。 . ではbest constantはどの値をとるかというとこの場合はlog spaceでのtarget meanです。log spaceでの平均が分かった後にその値を指数化して戻してあげる必要がありますがコンセプトはMSEと変わりません。 . &#26368;&#36969;&#21270;&#12398;&#20181;&#26041; . これも単純に目的関数としては使えないので以下のステップが必要です。 . ターゲット値をlog spaceに変換する; $z_i=log(y_i+1)$ | 変換された新しいターゲットに対して、目的関数をMSEに設定しモデルをfitする | 予測値を指数化し想定されるスケールに戻す; $ hat y_i=exp( hat z_i)-1$ | 詳しくは各ライブラリのdocを読みましょう。 . &#20998;&#39006;&#21839;&#38988;&#65288;Classification&#65289;&#12395;&#20351;&#12431;&#12428;&#12427;&#35413;&#20385;&#25351;&#27161; . Accuracy | Logarithmic Loss | Area under ROC curve | (Quadratic weighted) Kappa | . notation . $N$ : オブジェクト数 | $L$ : カテゴリ数 | $y$ : 真値 | $ hat y$ : 予測値 | $[a=b]$ : 1 if a=b else 0 | . Accuracy . $$ Accuracy= frac{1}{N} sum^N_{i=1}[ hat y_i=y_i] $$この指標はクラス予測がどのくらいの頻度で正しいか表しています。best constantは最も現れる頻度の高いカテゴリ値です。例えばターゲットに猫が10、犬が90あるとしたら、常にイッヌと予測したら0.9が得られ最大となります。 . &#26368;&#36969;&#21270;&#12398;&#20181;&#26041; . 何でもいいのである評価指標でモデルを最適化・fitする | 最適化済みのモデルの各カテゴリに対する確率予測値に対して、閾値を調節する | 閾値の最適解によってそのモデルの実力を最も発揮したAccuracyが求められます。 詳しくは各ライブラリのdocを読みましょう。 . Logarithmic Loss . Binary $$ LogLoss=- frac{1}{N} sum^N_{i=1}y_ilog( hat y_i)+(1-y_i)log(1- hat y_i) $$ Multiclass $$ LogLoss=- frac{1}{N} sum^N_{i=1} sum^L_{l=1}y_{il}log( hat y_{il}) $$ . 2値分類と多クラス分類のタスクで上のように書き分けられますが、多クラス分類の方は一般化されている形になっています。実践的には$log$の中身$x$に対して$10^{-15} leqq x leqq 1-10^{-15}$のようにクリッピングした関数 $$ LogLoss=- frac{1}{N} sum^N_{i=1} sum^L_{l=1}y_{il}log(min(max( hat y_{il},10^{-15}),1-10^{-15})) $$ . が使われます。下のグラフはターゲットが０の時の予測確率値とLogLossを示していますが、誤ったクラスの予測確率値が大きいほど、つまり間違った答えをはっきりこれだと言ってしまうほど大きいペナルティが課せられることが分かります。 . #collapse-hide y_pred = np.arange(0,1,0.01) def logloss(y_pred): return -np.log(1-y_pred) plt.figure(figsize=(10,7)) plt.xlabel(&quot;$ hat y$&quot;) plt.ylabel(&#39;Loss&#39;) plt.xlim(-0.01,1.01) plt.ylim(-0.1,6) plt.plot(y_pred,logloss(y_pred),label=&#39;LogLoss&#39;) plt.legend(loc=&#39;upper left&#39;) plt.show() . . best constantは各カテゴリの頻度値となります。猫1割、犬9割だったら猫0.1、犬0.9と常に予測するときに最小のLossが得られます。 . &#26368;&#36969;&#21270;&#12398;&#20181;&#26041; . これは目的関数として設定できます。そのまま使いましょう。詳しくは各ライブラリのdocを読みましょう。 . Area under ROC curve . 2値分類においてモデルのNegativeの予測確率値を小さい順に並び替えた時に、ある値より前の対応するターゲットが全てPositive、後は全てNegativeになる場合、閾値を適切に設定すればAccuracy100％の完全なモデルであることが分かります。つまりある閾値を境に綺麗にpositiveからnegativeを予測できていることが理想です。しかし、現実は予測確率をsortした時に対応するターゲットは綺麗に並んでくれはしません。本来positiveの所にnegativeが来てしまうことがあるのです。このようにどれくらい綺麗な並びでpositiveとnegativeを分けられているかを示すのがこの評価指標です。詳しいアルゴリズムは以下の動画が分かりやすく説明しているので参考にして下さい。 . それではbest constantはどの値をとるのでしょうか。この評価指標のアルゴリズムから分かるように、予測確率の大きさの順番しかこのスコアに影響しないので、どの値でも$AUC=0.5$と同じスコアになります。 . Note: ランダムに予測した場合予測確率の大小順はばらばらになるので$AUC=0.5$となり、最低値となる。 . &#26368;&#36969;&#21270;&#12398;&#20181;&#26041; . これを目的関数として設定できるモデルライブラリがあるのでその場合はそのまま使いましょう。そうでない場合はLogLossを最適化することで代用できます。詳しくは各ライブラリのdocを読みましょう。 . Kappa . Cohen&#39;s Kappa . お馴染みの例、猫10、犬90の場合、すべて犬と予想するだけで$Accuracy=0.9$となりますが、このようにモデルには最低限これはいけるっしょ的な精度、つまりBaseline Accuracyなるものが存在します。この値でAccuracyをscalingしたものがKappaという指標です。 . 詳しいアルゴリズムについて説明します。 例えば猫20、犬80と結果的に予測したとするとこの予測値をオブジェクトごとに適当に並び変えても最低限、$0.2*0.1+0.8*0.9=0.74$のAccuracyが得られます。このようにBaseline Accuracyは以下の様に定義できます。 $$ p_e= frac{1}{N^2} sum_kn_{k1}n_{k2} $$ ここで$k$は予測したカテゴリ値、$n_{k1}$、$n_{k2}$はそれぞれカテゴリkの予測した数、ターゲット内の数を示します。 そしてKappaは $$ Cohen&#39;s Kappa=1- frac{1-accuracy}{1-p_e} $$ または $$ Cohen&#39;s Kappa=1- frac{error}{baseline error} $$ と表されます。 . Weighted Kappa . この$error$と$baseline error$に関して与えられた重みでscalingしたものがこの指標です。例えば猫を犬と間違えたらそれは万死に値すると考える人によって、予測値犬、ターゲット猫に対応する重みは100000と設定されるとそこのペナルティが大きくなるのは明白ですね。この重み付けの種類によって以下のように名前が変わります。 . Linear weights $$ w_{ij}=|i-j| $$ Quadratic weights $$ w_{ij}=(i-j)^2 $$ ここでi、jはそれぞれターゲット、予測のクラス値です。比較的データサイエンスコンペティションで使われる指標であるQuadratic Weighted Kappaは予測値とターゲットの距離をerrorと捉えたMSEのような側面も持ち合わせていることが分かります。 . &#26368;&#36969;&#21270;&#12398;&#20181;&#26041;&#65288;Quadratic Weighted Kappa&#65289; . 目的関数そのままで扱うことは難しいため、以下のステップが必要となります。 . MSEを評価指標に設定しモデルを最適化 | Accuracyが最大となるように閾値を調節 | または、 . 微分可能な近似関数を設計 | GBDT（Gradient Boosting Decision Tree）やNeural net系のモデルに設計した関数を目的関数として設定し最適化 | 前者の方が行いやすいです。また、後者の近似関数の参考として以下の論文があります。 詳しくは各ライブラリのdocを読みましょう。 . &#26368;&#24460;&#12395; . 結構盛沢山の評価指標ですが、基本的にKaggleではコンペティションの指定した評価指標について最良のスコアを目指すだけです。しかし、現実社会の問題を考える時に、データや問題の特性に対応した最適な評価指標があります。自分で評価指標を決定しその指標に対してモデルを最適化するデータサイエンスの基本を知ることは広く役に立つと考えます。 . 1. 『How to Win a Data Science Competition: Learn from Top Kagglers』(National Research University Higher School of Economics, week3)↩ .",
            "url": "https://vintea01.github.io/tpt-medical-it/%E5%AE%9F%E8%B7%B5%E6%A9%9F%E6%A2%B0%E5%AD%A6%E7%BF%92/2020/03/31/Kaggle_Part1.html",
            "relUrl": "/%E5%AE%9F%E8%B7%B5%E6%A9%9F%E6%A2%B0%E5%AD%A6%E7%BF%92/2020/03/31/Kaggle_Part1.html",
            "date": " • Mar 31, 2020"
        }
        
    
  
    
        ,"post9": {
            "title": "ベイズ勉強会 Part 2 ベルヌーイ分布のベイズ推論",
            "content": "ベイズ勉強会資料は『ベイズ推論による機械学習入門』1を元に、途中式計算をできるだけ省略せずに行ったものです。 . &#12505;&#12523;&#12492;&#12540;&#12452;&#20998;&#24067; . ベルヌーイ分布は次の確率質量関数で表される確率分布である。 . この確率質量関数は確率$ mu$で1、$1- mu$で0を出力する。 . . Important: ベルヌーイ分布の確率質量関数$$Bern(x| mu) = mu^x (1- mu)^{1-x}　(x in {0, 1 }, mu in (0, 1))$$ . &#21839;&#38988; . 今N個のデータ点$ mathcal{D} = {x_1, x_2, dots, x_N }　(x_1, dots, x_N in {0, 1 })$が得られたとする。未知のデータ点$x_*$を予測するためにベイズ推測を行いたい。 . この問題が解ければ、コインを投げた時表が出る確率はどの程度かをベイズ推測で評価できるようになる。 . &#12514;&#12487;&#12523;&#27083;&#31689; . $ mathcal{D}, x_*, mu$で同時分布を構築する。データ点のとりうる値が2値なので、$ mathcal{D}, x_*$が$ mu$をパラメータに持つベルヌーイ分布から生成されているとする。$ mathcal{D}, x_*, mu$の関係をDAGで描くと以下のようになる。 . . よって同時分布は . $$ p( mathcal{D}, x_*, mu) = p( mathcal{D}| mu)p(x_*| mu)p( mu) $$という尤度関数×事前分布の形で書ける。 . &#23588;&#24230;&#38306;&#25968; . データ点はベルヌーイ分布から独立に生成されるとしているので . $$ p( mathcal{D}| mu) = Pi_{n=1}^{N} Bern(x_n| mu) p(x_*| mu) = Bern(x_*| mu) $$と書ける。 . &#20107;&#21069;&#20998;&#24067; . 事前分布$p( mu)$は$ mu in (0,1)$を満たすような確率分布である必要がある。これを満たす確率分布に、ベータ分布がある。 . . Important: ベータ分布の確率密度関数 . $$Beta( mu|a, b) = C_B(a,b) mu^{a-1} (1- mu)^{b-1}$$$$ただし, C_B (a,b) = frac{ Gamma(a+b)}{ Gamma(a) Gamma(b)}, mu in (0, 1), {a, b } in mathbb{R^+}を満たす.$$ $a, b$がベータ分布のパラメータである。 . . Note: ベータ分布の係数とガンマ関数 . $C_B(a,b)$は正規化されることを保証する係数である。$C_B(a,b)$中の$ Gamma(・)$はガンマ関数である。ガンマ関数は自然数に定義される階乗を一般化したものであり、正の実数$x in mathbb{R^+}$に対して、 . $$ Gamma(x) = int t^{x-1} e^{-t} dt$$と定義される。重要な性質として . $$ begin{eqnarray} Gamma(x+1) &amp;=&amp; x Gamma(x) Gamma(1) &amp;=&amp; 1 end{eqnarray}$$を満たし、自然数nに対しては . $$ Gamma(n+1) = n!$$が成り立つ。 . ベータ分布を用いることで事前分布$p( mu)$は . $$ p( mu) = Beta( mu|a, b) $$と定義できる。$a,b$も加えてDAGを描き直すと次のように描ける。 . . 更に$a,b$を出力する確率分布を考えることもできるが、モデルを複雑化すると計算も煩雑になるのでここまでにしておく。では$a,b$の値はどうするのかというと、事前に決めておくことになる。このような変数を、パラメータのためのパラメータということで、超パラメータ(ハイパーパラメータ)と呼ぶ。 . &#12414;&#12392;&#12417; . まとめると、推論のためのモデルは次のように書ける。 . $$ begin{eqnarray} p( mathcal{D}, x_*, mu) &amp;=&amp; p( mathcal{D}| mu)p(x_*| mu)p( mu) p( mathcal{D}| mu) &amp;=&amp; Pi_{n=1}^{N} Bern(x_n| mu) p(x_*| mu) &amp;=&amp; Bern(x_*| mu) p( mu) &amp;=&amp; Beta( mu|a,b) end{eqnarray} $$&#20107;&#24460;&#20998;&#24067;&#12398;&#25512;&#35542; . 実際に$ mathcal{D}$を観測した後の事後分布$p( mu| mathcal{D})$を求める。 . . Note: モデルの事後分布は$p(x_*, mu| mathcal{D}) = p(x_*| mu)p( mu| mathcal{D})$だがデータからの学習に関わるのは$p( mu| mathcal{D})$の部分のみ。学習のみに推論を絞ってこちらを事後分布と呼ぶ場合も多い。本節でも$p( mu| mathcal{D})$を事後分布と呼ぶ。 . ベイズの定理を用いて、 . $$ begin{eqnarray} p( mu| mathcal{D}) &amp;=&amp; frac{p( mathcal{D}| mu)p( mu)}{p( mathcal{D})} &amp;=&amp; frac{ { Pi_{n=1}^{N}p(x_n| mu) }p( mu)}{p( mathcal{D})} &amp; propto&amp; { Pi_{n=1}^{N}p(x_n| mu) }p( mu) end{eqnarray} $$である。分母は正規化されていることを保証する項であり、分布形状を決めるのは分子の部分であるため3行目では省略している。ベルヌーイ分布もベータ分布も指数部分があり、対数をとると計算が楽になる。 . $$ begin{eqnarray} ln p( mu| mathcal{D}) &amp;=&amp; Sigma_{n=1}^{N} ln p(x_n| mu) + ln p( mu) + const.　(対数化により分母は定数項に) &amp;=&amp; Sigma_{n=1}^{N} ln( mu^{x_n} (1- mu)^{1-x_n}) + ln(C_B(a,b) mu^{a-1} (1- mu)^{b-1}) + const.　(ベルヌーイ分布, ベータ分布の式を代入) &amp;=&amp; Sigma_{n=1}^{N} x_n ln mu + Sigma_{n=1}^{N} (1-x_n) ln (1- mu) + (a-1) ln mu + (b-1) ln (1- mu) + const.　(C_B(a,b)は対数化によりconst.に吸収) &amp;=&amp; ( Sigma_{n=1}^{N} x_n + a - 1) ln mu + (N - Sigma_{n=1}^{N} x_n + b - 1) ln (1- mu) + const. end{eqnarray} $$対数を元に戻すと . $$ p( mu| mathcal{D}) propto mu^{( Sigma_{n=1}^{N} x_n + a - 1)} (1- mu)^{N - Sigma_{n=1}^{N} x_n + b - 1} $$でありこれはベータ分布の形である。なお定数項は正規化されることを保証する係数となっている。つまり . $$ begin{eqnarray} p( mu| mathcal{D}) &amp;=&amp; Beta( mu| hat{a}, hat{b}) ただし　 hat{a} &amp;=&amp; Sigma_{n=1}^{N} x_n + a hat{b} &amp;=&amp; N - Sigma_{n=1}^{N} x_n + b end{eqnarray} $$となる。 . . Note: このように、特定の確率分布のパラメータの事前分布とすることで、事後分布が事前分布と同じ形になる確率分布を共役事前分布という。ベルヌーイ分布の共役事前分布はベータ分布である。 . . Note: ベルヌーイ分布の場合は、成功確率パラメータである$ mu$をベータ分布で幅を持たせて推定できることがベイズ推論の意義となる。 . . Note: $N$はデータ点の個数、$ Sigma_{n=1}^{N} x_n$は値が1だったデータ点の個数である。ハイパーパラメータ$a,b$をデータの情報で更新しているという見方ができる。また、$N$が大きくなると、$a,b$が無視できる、すなわちハイパーパラメータが結果に影響しなくなることがわかる。 . &#20104;&#28204;&#20998;&#24067;&#12398;&#31639;&#20986; . 未知のデータ点$x_*$の予測分布$p(x_*| mathcal{D})$は$p(x_*, mu| mathcal{D}) = p(x_*| mu)p( mu| mathcal{D})$をパラメータ$ mu$について周辺化することで求まる。 . $$ begin{eqnarray} p(x_*| mathcal{D}) &amp;=&amp; int p(x_*| mu)p( mu| mathcal{D}) d mu &amp;=&amp; int Bern(x_*| mu) Beta( mu| hat{a}, hat{b}) d mu &amp;=&amp; C_B( hat{a}, hat{b}) int mu^{x_*} (1- mu)^{1-x_*} mu^{ hat{a}-1}(1- mu)^{ hat{b}-1}d mu &amp;=&amp; C_B( hat{a}, hat{b}) int mu^{x_* + hat{a} -1}(1- mu)^{1-x_*+ hat{b}-1}d mu end{eqnarray} $$ここでベータ分布の定義式から . $$ int mu^{x_* + hat{a} -1}(1- mu)^{1-x_*+ hat{b}-1}d mu = frac{1}{C_B(x_* + hat{a}, 1-x_* + hat{b})} $$となる。 . . Note: ベータ分布は確率分布なので積分した時1になる。つまり係数$C_B$以外の部分を積分した時の値は係数$C_B$の逆数である。$ int mu^{x_* + hat{a} -1}(1- mu)^{1-x_*+ hat{b}-1}d mu$はベータ分布の積分から係数$C_B$の部分を除いた形になっている。 . したがって、 . $$ begin{eqnarray} p(x_*| mathcal{D}) &amp;=&amp; frac{C_B( hat{a}, hat{b})}{C_B(x_* + hat{a}, 1-x_* + hat{b})} &amp;=&amp; frac{ Gamma( hat{a}+ hat{b}) Gamma(x_* + hat{a}) Gamma(1-x_* + hat{b})}{ Gamma( hat{a}) Gamma( hat{b}) Gamma( hat{a}+ hat{b}+1)} end{eqnarray} $$複雑な式になっているが$x_*$は0か1しかとり得ないことを利用するともっと単純に書ける。 . $$ begin{eqnarray} p(x_* = 1| mathcal{D}) &amp;=&amp; frac{ Gamma( hat{a}+ hat{b}) Gamma(1 + hat{a}) Gamma( hat{b})}{ Gamma( hat{a}) Gamma( hat{b}) Gamma( hat{a}+ hat{b}+1)} &amp;=&amp; frac{ Gamma( hat{a}+ hat{b}) hat{a} Gamma( hat{a}) Gamma( hat{b})}{ Gamma( hat{a}) Gamma( hat{b})( hat{a}+ hat{b}) Gamma( hat{a}+ hat{b})} &amp;=&amp; frac{ hat{a}}{ hat{a}+ hat{b}} p(x_* = 0| mathcal{D}) &amp;=&amp; frac{ Gamma( hat{a}+ hat{b}) Gamma( hat{a}) Gamma(1 + hat{b})}{ Gamma( hat{a}) Gamma( hat{b}) Gamma( hat{a}+ hat{b}+1)} &amp;=&amp; frac{ hat{b}}{ hat{a}+ hat{b}} end{eqnarray} $$より . $$ begin{eqnarray} p(x_*| mathcal{D}) &amp;=&amp; ( frac{ hat{a}}{ hat{a}+ hat{b}})^{x_*} ( frac{ hat{b}}{ hat{a}+ hat{b}})^{1-x_*} &amp;=&amp; ( frac{ hat{a}}{ hat{a}+ hat{b}})^{x_*} (1- frac{ hat{a}}{ hat{a}+ hat{b}})^{1-x_*} &amp;=&amp; Bern(x_*| frac{ hat{a}}{ hat{a}+ hat{b}}) &amp;=&amp; Bern(x_*| frac{ Sigma_{n=1}^{N}x_n + a}{N+a+b}) end{eqnarray} $$と予測分布はベルヌーイ分布の形で書ける。 . . Note: 予測分布についても、$N$が大きくなると、$a,b$が無視できる、すなわちハイパーパラメータが結果に影響しなくなることがわかる。また予測分布の形状が尤度関数と変わっておらず、$ mu$の点推定を行った場合の予測と結局同じことをやっているように見える(特にNが大きければ最尤推定と同じである)が、尤度関数の種類によっては予測分布の形と異なる場合がある。ポアソン分布→負の二項分布、精度未知の1次元ガウス分布→Studentのt分布などの例がある。また、事後分布として$ mu$の分布が得られていて、幅のある推定ができている。 . Julia&#12395;&#12424;&#12427;&#23455;&#35013; . Turing.jlのTutorialより。 . &#32032;&#26420;&#12395; . # パッケージのimport # 乱数生成のためのパッケージ using Random # グラフ描画用のパッケージ using Plots # 確率分布の関数を呼び出すパッケージ using Distributions . # 真の成功確率を0.5と置く p_true = 0.5 # 0~100までの数列 Ns = 0:100; . # 100回ベルヌーイ試行を行う Random.seed!(12) data = rand(Bernoulli(p_true), last(Ns)) # 最初の5回 data[1:5] . 5-element Array{Bool,1}: 1 0 1 1 0 . # 事前分布をベータ分布で置く。ハイパーパラメータはa=1,b=1とする prior_belief = Beta(1, 1); . #hide_output # アニメーションをつけるためにStatsPlotsパッケージをimport using StatsPlots # ベイズ推論の進行過程をアニメーションに animation = @gif for (i, N) in enumerate(Ns) # 表がでた回数(heads)と裏が出た回数(tails)を計算 heads = sum(data[1:i-1]) tails = N - heads # 事後確率分布 updated_belief = Beta(prior_belief.α + heads, prior_belief.β + tails) # 描画用の関数 plot(updated_belief, size = (500, 250), title = &quot;Updated belief after $N observations&quot;, xlabel = &quot;probability of heads&quot;, ylabel = &quot;&quot;, legend = nothing, xlim = (0,1), fill=0, α=0.3, w=3) vline!([p_true]) end; . . Turing.jl&#12434;&#20351;&#12387;&#12383;&#12495;&#12511;&#12523;&#12488;&#12491;&#12450;&#12531;&#12539;&#12514;&#12531;&#12486;&#12459;&#12523;&#12525;&#12395;&#12424;&#12427;&#36817;&#20284;&#35336;&#31639; . # パッケージのimport # Load Turing and MCMCChains. using Turing, MCMCChains # Load the distributions library. using Distributions # Load StatsPlots for density plots. using StatsPlots . # モデル設定 @model coinflip(y) = begin # 事前分布 p ~ Beta(1, 1) # 試行回数N N = length(y) for n in 1:N # 各試行の結果はベルヌーイ分布で決定する y[n] ~ Bernoulli(p) end end; . # HMCの設定 iterations = 1000 ϵ = 0.05 τ = 10 # HMCの実行 chain = sample(coinflip(data), HMC(ϵ, τ), iterations, progress=false); . # 結果のサマリ p_summary = chain[:p] plot(p_summary, seriestype = :histogram) . # 解析的に解いた事後分布 N = length(data) heads = sum(data) updated_belief = Beta(prior_belief.α + heads, prior_belief.β + N - heads) # HMCによる事後分布の近似を青で描画 p = plot(p_summary, seriestype = :density, xlim = (0,1), legend = :best, w = 2, c = :blue) # 解析的に解いた事後分布を緑で描画 plot!(p, range(0, stop = 1, length = 100), pdf.(Ref(updated_belief), range(0, stop = 1, length = 100)), xlabel = &quot;probability of heads&quot;, ylabel = &quot;&quot;, title = &quot;&quot;, xlim = (0,1), label = &quot;Closed-form&quot;, fill=0, α=0.3, w=3, c = :lightgreen) # 真の成功確率を赤で描画 vline!(p, [p_true], label = &quot;True probability&quot;, c = :red) . 1. 須山敦志. 杉山将. ベイズ推論による機械学習入門. 講談社, 2017.↩ .",
            "url": "https://vintea01.github.io/tpt-medical-it/bayes/2020/03/29/bayes_part2.html",
            "relUrl": "/bayes/2020/03/29/bayes_part2.html",
            "date": " • Mar 29, 2020"
        }
        
    
  
    
        ,"post10": {
            "title": "自分のサイトを作ろう",
            "content": "概要 . 公式のドキュメントにしたがって作成したデフォルトのサイトを自分のサイトにするための設定項目。 . 変更するファイル . _config.yml | _pages/about.md | images/favicon.ico | . _config.yml . サイト名などの主要な設定項目は_config.ymlに含まれている。変更するのは以下の要素。 . title . サイト名になる。 . description . サイトの概要。ブラウザのタブにtitleともに表示される。 . minima: social_links: . GitHubとTwitterアカウント。 . use_math . TeX記法を使う場合はtrueにしておく。 . show_description . ホーム画面に各記事の概要を表示する。デフォルトでfalse。 . default_badges . 記事にGitHubやBinder, Colabへのリンクバッジが貼られる。使わないならfalseにする。 . _pages/about.md . 自己紹介や団体紹介を書いておく。 . images/favicon.ico . ブラウザのタブに表示されるマーク。団体ロゴなどの画像ファイルの名前をfavicon.icoにすればいい。 .",
            "url": "https://vintea01.github.io/tpt-medical-it/markdown/2020/03/27/fastpages.html",
            "relUrl": "/markdown/2020/03/27/fastpages.html",
            "date": " • Mar 27, 2020"
        }
        
    
  
    
        ,"post11": {
            "title": "ベイズ勉強会 Part 1 ベイズ推論のワークフロー",
            "content": "ベイズ勉強会資料は『ベイズ推論による機械学習入門』1を元に、途中式計算をできるだけ省略せずに行ったものです。 . &#27010;&#35542;: &#12505;&#12452;&#12474;&#25512;&#35542;&#12398;&#12527;&#12540;&#12463;&#12501;&#12525;&#12540; . . Important: ベイズ推論の共通するワークフロー . 観測データ$ mathcal{D}$と観測されていない未知の変数$ mathbf{X}$の同時分布$p( mathcal{D}, mathbf{X})$を構築 | 事後分布$p( mathbf{X}| mathcal{D}) = frac{p( mathcal{D}, mathbf{X})}{p( mathcal{D})}$を求める。 | 今回はさらに事後分布を用いて予測分布を計算するところまでを見る。 . &#20104;&#28204;&#20998;&#24067; . 観測されたデータ$ mathcal{D}$に対して、パラメタ$ theta$を持つ確率分布でモデルを組み、新しいデータ$x_*$を予測したい。$ mathcal{D}$と$x_*$が独立に生成されるとすると、以下のような予測分布を用いることができる。 . $$p(x_*| mathcal{D}) = int p(x_*| theta)p( theta| mathcal{D}) d theta$$ . $ mathcal{D}$, $ theta$, $x_*$の関係をDAGで表すと次のようになる。 . . この時、$ mathcal{D}$と$x_*$はパラメタ$ theta$が与えられた条件の下での条件付き独立である。 . &#21516;&#26178;&#20998;&#24067;&#12398;&#35352;&#36848; . $ mathcal{D}$と$x_*$がパラメタ$ theta$が与えられた条件の下での条件付き独立であることから同時分布は以下のようになる。 $$ p( mathcal{D}, x_*, theta) = p( mathcal{D}| theta)p(x_*| theta)p( theta) $$ . . Note: $p( theta)$は2個必要なのではないかと思うかもしれない。サイコロの目によって動きが決まる駒が2つあり、同時に動かす状況を考えよう。コマの動きを決めるのにサイコロを振る回数は1回である。 . . Note: $p( mathcal{D}| theta)$の部分はパラメタからデータが生成される過程を記述している。これを$ theta$の関数として見た場合尤度関数と呼ぶ。この尤度関数を最大化する$ theta$を$ theta$の予測値とする方法を最尤推定という。 . . Note: $p( theta)$を事前分布という。同時確率は尤度関数×事前分布の形で書くことができる。 . &#20107;&#24460;&#20998;&#24067;&#12398;&#25512;&#35542; . データ$ mathcal{D}$だけが手元にある時、残りの変数の事後分布は $$ begin{eqnarray} p(x_*, theta| mathcal{D}) &amp;=&amp; frac{p( mathcal{D}, x_*, theta)}{p( mathcal{D})} &amp;=&amp; frac{p( mathcal{D}| theta)p(x_*| theta)p( theta)}{p( mathcal{D})} &amp;=&amp; p(x_*| theta)p( theta| mathcal{D}) end{eqnarray} $$ となる。 . . Note: ベイズの定理から$p( theta| mathcal{D}) = frac{p( mathcal{D}| theta)p( theta)}{p( mathcal{D})}$となることを用いた。 . . Note: $p( theta| mathcal{D})$を最大化する$ theta$を$ theta$の予測値とする方法を事後確率最大化推定(MAP推定)と呼ぶ。 . &#20104;&#28204;&#20998;&#24067;&#12398;&#31639;&#20986; . $ mathcal{D}$が決まった時の$x_*$の確率分布、すなわち予測分布$p(x_*| mathcal{D})$は$ theta$を積分除去することで得られる。 . $$p(x_*| mathcal{D}) = int p(x_*| theta)p( theta| mathcal{D}) d theta$$ . 以上がベイズ推論の予測までを含めた一連の流れである。次回から離散確率分布について具体的にやってみる。 . 1. 須山敦志. 杉山将. ベイズ推論による機械学習入門. 講談社, 2017.↩ .",
            "url": "https://vintea01.github.io/tpt-medical-it/bayes/2020/03/27/bayes_part1.html",
            "relUrl": "/bayes/2020/03/27/bayes_part1.html",
            "date": " • Mar 27, 2020"
        }
        
    
  

  
  

  
      ,"page1": {
          "title": "団体について",
          "content": "医療IT・数学同好会 Tea Partyは、情報技術・数学を医療に絡め、メンバーそれぞれの研究・趣味に活かしていく東京医科歯科大学のサークルです。週1程度でオンライン勉強会を行っています。 . 分野 . 微積分・線形代数 | 統計学(ベイズ統計学を含む) | 機械学習/深層学習 | バイオインフォマティクス | 因果推論 | . 連絡先 . Twitter: @tpt_ochanomizu . Gmail: tpt.ochanomizu@gmail.com .",
          "url": "https://vintea01.github.io/tpt-medical-it/about/",
          "relUrl": "/about/",
          "date": ""
      }
      
  

  

  
  

  

  
  

  

  
      ,"page7": {
          "title": "Twitter",
          "content": "{% twitter https://twitter.com/tpt_ochanomizu maxwidth=500 limit=5 %} .",
          "url": "https://vintea01.github.io/tpt-medical-it/timeline/",
          "relUrl": "/timeline/",
          "date": ""
      }
      
  

  
  

  
  

}