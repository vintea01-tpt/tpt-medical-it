<!DOCTYPE html>
<html lang="en"><head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1"><!-- Begin Jekyll SEO tag v2.6.1 -->
<title>ベイズ勉強会 Part 4 多次元ガウス分布のベイズ推論 | T/T</title>
<meta name="generator" content="Jekyll v4.0.0" />
<meta property="og:title" content="ベイズ勉強会 Part 4 多次元ガウス分布のベイズ推論" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="多次元ガウス分布のベイズ推論を実践する" />
<meta property="og:description" content="多次元ガウス分布のベイズ推論を実践する" />
<link rel="canonical" href="https://vintea01.github.io/tpt-medical-it/bayes/2020/04/06/bayes-part4.ipynb.html" />
<meta property="og:url" content="https://vintea01.github.io/tpt-medical-it/bayes/2020/04/06/bayes-part4.ipynb.html" />
<meta property="og:site_name" content="T/T" />
<meta property="og:image" content="https://vintea01.github.io/tpt-medical-it/images/dag1.png" />
<meta property="og:type" content="article" />
<meta property="article:published_time" content="2020-04-06T00:00:00-05:00" />
<script type="application/ld+json">
{"datePublished":"2020-04-06T00:00:00-05:00","dateModified":"2020-04-06T00:00:00-05:00","mainEntityOfPage":{"@type":"WebPage","@id":"https://vintea01.github.io/tpt-medical-it/bayes/2020/04/06/bayes-part4.ipynb.html"},"description":"多次元ガウス分布のベイズ推論を実践する","image":"https://vintea01.github.io/tpt-medical-it/images/dag1.png","@type":"BlogPosting","url":"https://vintea01.github.io/tpt-medical-it/bayes/2020/04/06/bayes-part4.ipynb.html","headline":"ベイズ勉強会 Part 4 多次元ガウス分布のベイズ推論","@context":"https://schema.org"}</script>
<!-- End Jekyll SEO tag -->
<link rel="stylesheet" href="/tpt-medical-it/assets/css/style.css"><link type="application/atom+xml" rel="alternate" href="https://vintea01.github.io/tpt-medical-it/feed.xml" title="T/T" /><link rel="shortcut icon" type="image/x-icon" href="/tpt-medical-it/images/favicon.ico"><!-- Begin Jekyll SEO tag v2.6.1 -->
<title>ベイズ勉強会 Part 4 多次元ガウス分布のベイズ推論 | T/T</title>
<meta name="generator" content="Jekyll v4.0.0" />
<meta property="og:title" content="ベイズ勉強会 Part 4 多次元ガウス分布のベイズ推論" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="多次元ガウス分布のベイズ推論を実践する" />
<meta property="og:description" content="多次元ガウス分布のベイズ推論を実践する" />
<link rel="canonical" href="https://vintea01.github.io/tpt-medical-it/bayes/2020/04/06/bayes-part4.ipynb.html" />
<meta property="og:url" content="https://vintea01.github.io/tpt-medical-it/bayes/2020/04/06/bayes-part4.ipynb.html" />
<meta property="og:site_name" content="T/T" />
<meta property="og:image" content="https://vintea01.github.io/tpt-medical-it/images/dag1.png" />
<meta property="og:type" content="article" />
<meta property="article:published_time" content="2020-04-06T00:00:00-05:00" />
<script type="application/ld+json">
{"datePublished":"2020-04-06T00:00:00-05:00","dateModified":"2020-04-06T00:00:00-05:00","mainEntityOfPage":{"@type":"WebPage","@id":"https://vintea01.github.io/tpt-medical-it/bayes/2020/04/06/bayes-part4.ipynb.html"},"description":"多次元ガウス分布のベイズ推論を実践する","image":"https://vintea01.github.io/tpt-medical-it/images/dag1.png","@type":"BlogPosting","url":"https://vintea01.github.io/tpt-medical-it/bayes/2020/04/06/bayes-part4.ipynb.html","headline":"ベイズ勉強会 Part 4 多次元ガウス分布のベイズ推論","@context":"https://schema.org"}</script>
<!-- End Jekyll SEO tag -->

<link href="https://unpkg.com/@primer/css/dist/primer.css" rel="stylesheet" />
<link rel="stylesheet" href="//use.fontawesome.com/releases/v5.0.7/css/all.css"><link type="application/atom+xml" rel="alternate" href="https://vintea01.github.io/tpt-medical-it/feed.xml" title="T/T" />
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.11.1/dist/katex.min.css" integrity="sha384-zB1R0rpPzHqg7Kpt0Aljp8JPLqbXI3bhnPWROx27a9N0Ll6ZP/+DiW/UqRcLbRjq" crossorigin="anonymous">
    <script type="text/javascript" async src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-MML-AM_CHTML"> </script>
    <script defer src="https://cdn.jsdelivr.net/npm/katex@0.11.1/dist/katex.min.js" integrity="sha384-y23I5Q6l+B6vatafAwxRu/0oK/79VlbSz7Q9aiSZUvyWYIYsd+qj+o24G5ZU2zJz" crossorigin="anonymous"></script>
    <script defer src="https://cdn.jsdelivr.net/npm/katex@0.11.1/dist/contrib/auto-render.min.js" integrity="sha384-kWPLUVMOks5AQFrykwIup5lo0m3iMkkHrD0uJ4H5cjeGihAutqP0yW0J6dpFiVkI" crossorigin="anonymous"></script>
    <script>
    document.addEventListener("DOMContentLoaded", function() {
        renderMathInElement( document.body, {
        delimiters: [
            {left: "$$", right: "$$", display: true},
            {left: "[%", right: "%]", display: true},
            {left: "$", right: "$", display: false}
        ]}
        );
    });
    </script>


<script>
function wrap_img(fn) {
    if (document.attachEvent ? document.readyState === "complete" : document.readyState !== "loading") {
        var elements = document.querySelectorAll(".post img");
        Array.prototype.forEach.call(elements, function(el, i) {
            if (el.getAttribute("title")) {
                const caption = document.createElement('figcaption');
                var node = document.createTextNode(el.getAttribute("title"));
                caption.appendChild(node);
                const wrapper = document.createElement('figure');
                wrapper.className = 'image';
                el.parentNode.insertBefore(wrapper, el);
                el.parentNode.removeChild(el);
                wrapper.appendChild(el);
                wrapper.appendChild(caption);
            }
        });
    } else { document.addEventListener('DOMContentLoaded', fn); }
}
window.onload = wrap_img;
</script>

<script>
    document.addEventListener("DOMContentLoaded", function(){
    // add link icon to anchor tags
    var elem = document.querySelectorAll(".anchor-link")
    elem.forEach(e => (e.innerHTML = '<i class="fas fa-link fa-xs"></i>'));
    });
</script>
</head>
<body><header class="site-header">

  <div class="wrapper"><a class="site-title" rel="author" href="/tpt-medical-it/">T/T</a><nav class="site-nav">
        <input type="checkbox" id="nav-trigger" class="nav-trigger" />
        <label for="nav-trigger">
          <span class="menu-icon">
            <svg viewBox="0 0 18 15" width="18px" height="15px">
              <path d="M18,1.484c0,0.82-0.665,1.484-1.484,1.484H1.484C0.665,2.969,0,2.304,0,1.484l0,0C0,0.665,0.665,0,1.484,0 h15.032C17.335,0,18,0.665,18,1.484L18,1.484z M18,7.516C18,8.335,17.335,9,16.516,9H1.484C0.665,9,0,8.335,0,7.516l0,0 c0-0.82,0.665-1.484,1.484-1.484h15.032C17.335,6.031,18,6.696,18,7.516L18,7.516z M18,13.516C18,14.335,17.335,15,16.516,15H1.484 C0.665,15,0,14.335,0,13.516l0,0c0-0.82,0.665-1.483,1.484-1.483h15.032C17.335,12.031,18,12.695,18,13.516L18,13.516z"/>
            </svg>
          </span>
        </label>

        <div class="trigger"><a class="page-link" href="/tpt-medical-it/about/">団体について</a><a class="page-link" href="/tpt-medical-it/search/">サイト内検索</a><a class="page-link" href="/tpt-medical-it/categories/">タグ一覧</a><a class="page-link" href="/tpt-medical-it/timeline/">Twitter</a></div>
      </nav></div>
</header>
<main class="page-content" aria-label="Content">
      <div class="wrapper">
        <article class="post h-entry" itemscope itemtype="http://schema.org/BlogPosting">

  <header class="post-header">
    <h1 class="post-title p-name" itemprop="name headline">ベイズ勉強会 Part 4 多次元ガウス分布のベイズ推論</h1><p class="page-description">多次元ガウス分布のベイズ推論を実践する</p><p class="post-meta post-meta-title"><time class="dt-published" datetime="2020-04-06T00:00:00-05:00" itemprop="datePublished">
        Apr 6, 2020
      </time>
       • <span class="read-time" title="Estimated read time">
    
    
      18 min read
    
</span></p>

    
      <p class="category-tags"><i class="fas fa-tags category-tags-icon"></i></i> 
      
        <a class="category-tags-link" href="/tpt-medical-it/categories/#bayes">bayes</a>
        
      
      </p>
    

    
      
        <div class="pb-5 d-flex flex-wrap flex-justify-end">
          <div class="px-2">

    <a href="https://github.com/Vintea01/tpt-medical-it/tree/master/_notebooks/2020-04-06-bayes-part4.ipynb.ipynb" role="button" target="_blank">
<img class="notebook-badge-image" src="/tpt-medical-it/assets/badges/github.svg" alt="View On GitHub">
    </a>
</div>

          
          
        </div>
      </header>

  <div class="post-content e-content" itemprop="articleBody">
    <ul class="section-nav">
<li class="toc-entry toc-h1"><a href="#多次元ガウス分布">多次元ガウス分布 </a></li>
<li class="toc-entry toc-h1"><a href="#平均未知">平均未知 </a>
<ul>
<li class="toc-entry toc-h2"><a href="#モデルの構築">モデルの構築 </a></li>
<li class="toc-entry toc-h2"><a href="#事後分布の推論">事後分布の推論 </a></li>
<li class="toc-entry toc-h2"><a href="#予測分布の導出">予測分布の導出 </a></li>
</ul>
</li>
<li class="toc-entry toc-h1"><a href="#精度行列未知">精度行列未知 </a>
<ul>
<li class="toc-entry toc-h2"><a href="#モデルの構築">モデルの構築 </a></li>
<li class="toc-entry toc-h2"><a href="#事後分布の推論">事後分布の推論 </a></li>
<li class="toc-entry toc-h2"><a href="#予測分布の導出">予測分布の導出 </a></li>
</ul>
</li>
<li class="toc-entry toc-h1"><a href="#平均・精度行列未知">平均・精度行列未知 </a>
<ul>
<li class="toc-entry toc-h2"><a href="#モデル構築">モデル構築 </a></li>
<li class="toc-entry toc-h2"><a href="#事後分布の推論">事後分布の推論 </a>
<ul>
<li class="toc-entry toc-h3"><a href="#平均の事後分布">平均の事後分布 </a></li>
<li class="toc-entry toc-h3"><a href="#精度の事後分布">精度の事後分布 </a></li>
<li class="toc-entry toc-h3"><a href="#事後分布をまとめる">事後分布をまとめる </a></li>
</ul>
</li>
<li class="toc-entry toc-h2"><a href="#予測分布の導出">予測分布の導出 </a></li>
</ul>
</li>
</ul><!--
#################################################
### THIS FILE WAS AUTOGENERATED! DO NOT EDIT! ###
#################################################
# file to edit: _notebooks/2020-04-06-bayes-part4.ipynb.ipynb
-->

<div class="container" id="notebook-container">
        
    
    
<div class="cell border-box-sizing code_cell rendered">

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>ベイズ勉強会資料は『ベイズ推論による機械学習入門』<sup id="fnref-1" class="footnote-ref"><a href="#fn-1">1</a></sup>を元に、途中式計算をできるだけ省略せずに行ったものです。</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h1 id="多次元ガウス分布">
<a class="anchor" href="#%E5%A4%9A%E6%AC%A1%E5%85%83%E3%82%AC%E3%82%A6%E3%82%B9%E5%88%86%E5%B8%83" aria-hidden="true"><span class="octicon octicon-link"></span></a>多次元ガウス分布<a class="anchor-link" href="#%E5%A4%9A%E6%AC%A1%E5%85%83%E3%82%AC%E3%82%A6%E3%82%B9%E5%88%86%E5%B8%83"> </a>
</h1>
<p>多次元ガウス分布はD次元ベクトル${\bf x} \in \mathbb{R}^D$を生成するための確率分布であり、以下の確率密度関数で表される。</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p></p>
<div class="flash flash-warn">
    <svg class="octicon octicon-zap octicon octicon-zap octicon octicon-zap octicon octicon-zap octicon octicon-zap octicon octicon-zap octicon octicon-zap octicon octicon-zap octicon octicon-zap octicon octicon-zap" viewbox="0 0 10 16" version="1.1" width="10" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M10 7H6l3-7-9 9h4l-3 7 9-9z"></path></svg>
    <strong>Important: </strong>多次元ガウス分布の確率密度関数 $$\frac{1}{\sqrt{(2\pi)^D |{\bf \Sigma} }|}\exp{\{-\frac{1}{2}({\bf x}-{\bf \mu})^\mathrm{T} {\bf \Sigma}^{-1} ({\bf x}-{\bf \mu})\} }$$
</div>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>${\bf \mu} \in \mathbb{R}^D$は平均パラメータ、${\bf \Sigma}$は共分散行列パラメータで$D \times D$の正定値行列である必要がある。</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p></p>
<div class="flash flash-warn">
    <svg class="octicon octicon-zap octicon octicon-zap octicon octicon-zap octicon octicon-zap octicon octicon-zap octicon octicon-zap octicon octicon-zap octicon octicon-zap octicon octicon-zap octicon octicon-zap octicon octicon-zap" viewbox="0 0 10 16" version="1.1" width="10" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M10 7H6l3-7-9 9h4l-3 7 9-9z"></path></svg>
    <strong>Important: </strong>正定値行列
</div>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<blockquote>
<blockquote>
<p>固有値が全て正の実正方行列を正定値行列と呼ぶ。実正方行列${\bf A}$が正定値行列である必要十分条件は任意の非ゼロベクトル${\bf x}$に関して、</p>
$${\bf x}^\mathrm{T} {\bf A}{\bf x} &gt; 0$$<p>が成り立つこと。正定値行列の逆行列も正定値行列である。また全ての固有値が正であることから、</p>
$$|{\bf A}| &gt; 0$$<p>が成り立つ。</p>
<p>また、対称行列であるので</p>
$${\bf A}^{\mathrm{T} } = {\bf A}$$<p>が成り立つ。</p>
</blockquote>
</blockquote>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>多次元ガウス分布を対数で表示すると、</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p></p>
<div class="flash flash-warn">
    <svg class="octicon octicon-zap octicon octicon-zap octicon octicon-zap octicon octicon-zap octicon octicon-zap octicon octicon-zap octicon octicon-zap octicon octicon-zap octicon octicon-zap octicon octicon-zap octicon octicon-zap octicon octicon-zap" viewbox="0 0 10 16" version="1.1" width="10" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M10 7H6l3-7-9 9h4l-3 7 9-9z"></path></svg>
    <strong>Important: </strong>多次元ガウス分布の対数表示 $$\ln \mathcal{N}({\bf x}|{\bf \mu},{\bf \Sigma})=-\frac{1}{2}\{({\bf x}-{\bf \mu})^\mathrm{T} {\bf \Sigma}^{-1}({\bf x}-{\bf \mu}) + \ln |{\bf \Sigma}| + D \ln 2\pi\}$$
</div>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>1次元ガウス分布と同様に分散の逆元として精度を定義できる。共分散行列$\bf{\Sigma}$の逆行列として精度行列$\bf{\Lambda}$を定義する。すなわち$\bf{\Lambda}=\bf{\Sigma}^{-1}$である。</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p></p>
<div class="flash flash-warn">
    <svg class="octicon octicon-zap octicon octicon-zap octicon octicon-zap octicon octicon-zap octicon octicon-zap octicon octicon-zap octicon octicon-zap octicon octicon-zap octicon octicon-zap octicon octicon-zap octicon octicon-zap octicon octicon-zap octicon octicon-zap" viewbox="0 0 10 16" version="1.1" width="10" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M10 7H6l3-7-9 9h4l-3 7 9-9z"></path></svg>
    <strong>Important: </strong>多次元ガウス分布を精度行列で表した場合 $$\frac{1}{\sqrt{(2\pi)^D} }|{\bf \Lambda}|^{\frac{1}{2} }\exp{\{-\frac{1}{2}({\bf x}-{\bf \mu})^\mathrm{T} {\bf \Lambda} ({\bf x}-{\bf \mu})\} }$$
</div>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p></p>
<div class="flash flash-warn">
    <svg class="octicon octicon-zap octicon octicon-zap octicon octicon-zap octicon octicon-zap octicon octicon-zap octicon octicon-zap octicon octicon-zap octicon octicon-zap octicon octicon-zap octicon octicon-zap octicon octicon-zap octicon octicon-zap octicon octicon-zap octicon octicon-zap" viewbox="0 0 10 16" version="1.1" width="10" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M10 7H6l3-7-9 9h4l-3 7 9-9z"></path></svg>
    <strong>Important: </strong>多次元ガウス分布の対数表示(精度行列で表した場合) $$\ln \mathcal{N}({\bf x}|{\bf \mu},{\bf \Lambda}^{-1})=-\frac{1}{2}\{({\bf x}-{\bf \mu})^\mathrm{T} {\bf \Lambda}({\bf x}-{\bf \mu}) - \ln |{\bf \Lambda}| + D\ln 2\pi\}$$
</div>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>この多次元ガウス分布のベイズ推論を行っていく。1次元ガウス分布と同様、平均パラメータ未知、精度パラメータ未知、両方未知の場合の順に行う。なお本稿では特に断り無い限り多次元ガウス分布のことをガウス分布と呼ぶ。</p>
<h1 id="平均未知">
<a class="anchor" href="#%E5%B9%B3%E5%9D%87%E6%9C%AA%E7%9F%A5" aria-hidden="true"><span class="octicon octicon-link"></span></a>平均未知<a class="anchor-link" href="#%E5%B9%B3%E5%9D%87%E6%9C%AA%E7%9F%A5"> </a>
</h1>
<p>D次元の確率変数${\bf x} \in \mathbb{R}^D$の平均パラメータ${\bf \mu} \in \mathbb{R}^D$のみが未知で、精度行列${\bf \Lambda} \in \mathbb{R}^{D \times D}$は既に与えられている、またはハイパーパラメータとして、ベイズ推論を行ってみる。N個のデータ${\bf X} = \{ {\bf x}_1,\dots,{\bf x}_N\}$が観測されていて、予測する未知の観測を${\bf x}_*$とおく。</p>
<h2 id="モデルの構築">
<a class="anchor" href="#%E3%83%A2%E3%83%87%E3%83%AB%E3%81%AE%E6%A7%8B%E7%AF%89" aria-hidden="true"><span class="octicon octicon-link"></span></a>モデルの構築<a class="anchor-link" href="#%E3%83%A2%E3%83%87%E3%83%AB%E3%81%AE%E6%A7%8B%E7%AF%89"> </a>
</h2>
<p>平均のみが未知の時は、ガウス分布を事前分布とすることで共役性が満たされることがわかっている。${\bf m} \in \mathbb{R}^D, {\bf \Lambda}_{\mu} \in \mathbb{R}^{D \times D}$をハイパーパラメータとして同時分布は次のようになる。</p>
$$
\begin{eqnarray}
    p({\bf X},{\bf x}_*,{\bf \mu}) &amp;=&amp; p({\bf X}|{\bf \mu})p({\bf x}_*|{\bf \mu})p({\bf \mu}) \\
    p({\bf X}|{\bf \mu}) &amp;=&amp; \Pi_{n=1}^{N} \mathcal{N}({\bf x}_n|{\bf \mu},{\bf \Lambda}^{-1}) \\
    p({\bf x}_*|{\bf \mu}) &amp;=&amp; \mathcal{N}({\bf x}_*|{\bf \mu},{\bf \Lambda}^{-1}) \\
    p({\bf \mu}) &amp;=&amp; \mathcal{N}({\bf \mu}|{\bf m},{\bf \Lambda}_{\mu}^{-1})
\end{eqnarray}
$$<h2 id="事後分布の推論">
<a class="anchor" href="#%E4%BA%8B%E5%BE%8C%E5%88%86%E5%B8%83%E3%81%AE%E6%8E%A8%E8%AB%96" aria-hidden="true"><span class="octicon octicon-link"></span></a>事後分布の推論<a class="anchor-link" href="#%E4%BA%8B%E5%BE%8C%E5%88%86%E5%B8%83%E3%81%AE%E6%8E%A8%E8%AB%96"> </a>
</h2>
<p>ベイズの定理を用いて事後分布$p({\bf \mu}|{\bf X})$は次のようになる。</p>
$$
\begin{eqnarray}
    p({\bf \mu}|{\bf X}) &amp;\propto&amp; p({\bf X}|{\bf \mu})p({\bf \mu}) \\
    &amp;=&amp; \{ \Pi_{n=1}^{N} p({\bf x}_n|{\bf \mu})\}p({\bf \mu}) \\
    &amp;=&amp; \Pi_{n=1}^{N} \{\mathcal{N}({\bf x}_n|{\bf \mu},{\bf \Lambda}^{-1})\} \mathcal{N}({\bf \mu}|{\bf m},{\bf \Lambda}_{\mu}^{-1})
\end{eqnarray}
$$<p>対数をとると</p>
$$
\begin{eqnarray}
    \ln p({\bf \mu}|{\bf X}) &amp;=&amp; \Sigma_{n=1}^{N} \ln \mathcal{N}({\bf x}_n|{\bf \mu},{\bf \Lambda}^{-1}) + \ln \mathcal{N}({\bf \mu}|{\bf m},{\bf \Lambda}_{\mu}^{-1}) + const. \\
    &amp;=&amp; -\frac{1}{2} \Sigma_{n=1}^{N} ({\bf x}_n-{\bf \mu})^\mathrm{T} {\bf \Lambda}({\bf x}_n-{\bf \mu}) - \frac{1}{2}({\bf \mu}-{\bf m})^\mathrm{T}{\bf \Lambda}_{\mu}({\bf \mu}-{\bf m}) + const. \\
    &amp;=&amp; -\frac{1}{2} \Sigma_{n=1}^{N} ({\bf x}_n^{\mathrm{T} }-{\bf \mu}^{\mathrm{T} }){\bf \Lambda}({\bf x}_n-{\bf \mu}) - \frac{1}{2}({\bf \mu}^{\mathrm{T} }-{\bf m}^{\mathrm{T} }) {\bf \Lambda}_{\mu}({\bf \mu}-{\bf m}) + const. \\
    &amp;=&amp; \frac{1}{2}\Sigma_{n=1}^{N}\{ {\bf x}_n^{\mathrm{T} }{\bf \Lambda}{\bf \mu}\} + \frac{1}{2} {\bf \mu}^{\mathrm{T} } {\bf \Lambda}\Sigma_{n=1}^{N} {\bf x}_n - \frac{N}{2} {\bf \mu}^{\mathrm{T} }{\bf \Lambda}{\bf \mu} - \frac{1}{2} {\bf \mu}^{\mathrm{T} }{\bf \Lambda}_{\mu}{\bf \mu} + \frac{1}{2}{\bf \mu}^{\mathrm{T} }{\bf \Lambda}_{\mu}{\bf m} + \frac{1}{2}{\bf m}^{\mathrm{T} }{\bf \Lambda}_{\mu}{\bf \mu} + const.
\end{eqnarray}
$$
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>ここで、${\bf x}_n^{\mathrm{T} }{\bf \Lambda}{\bf \mu}$は行数と列数について(1×D)×(D×D)×(D×1)=(1×1)よりスカラーなので次が成り立つ。</p>
$$
\begin{eqnarray}
    {\bf x}_n^{\mathrm{T} }{\bf \Lambda}{\bf \mu} &amp;=&amp; ({\bf x}_n^{\mathrm{T} }{\bf \Lambda}{\bf \mu})^{\mathrm{T} }　(スカラーを転置しても同じ) \\
    &amp;=&amp; {\bf \mu}^{\mathrm{T} } {\bf \Lambda}^{\mathrm{T} } {\bf x}_n　(これは公式通り) \\
    &amp;=&amp; {\bf \mu}^{\mathrm{T} } {\bf \Lambda} {\bf x}_n　({\bf \Lambda}は対称行列)
\end{eqnarray}
$$<p>${\bf m}^{\mathrm{T} }{\bf \Lambda}_{\mu} {\bf \mu}$についても同様であり、</p>
$$
\begin{eqnarray}
    \ln p({\bf \mu}|{\bf X}) &amp;=&amp; \frac{1}{2}\Sigma_{n=1}^{N}\{ {\bf x}_n^{\mathrm{T} }{\bf \Lambda}{\bf \mu}\} + \frac{1}{2} {\bf \mu}^{\mathrm{T} } {\bf \Lambda}\Sigma_{n=1}^{N} {\bf x}_n - \frac{N}{2} {\bf \mu}^{\mathrm{T} }{\bf \Lambda}{\bf \mu} - \frac{1}{2} {\bf \mu}^{\mathrm{T} }{\bf \Lambda}_{\mu}{\bf \mu} + \frac{1}{2}{\bf \mu}^{\mathrm{T} }{\bf \Lambda}_{\mu}{\bf m} + \frac{1}{2}{\bf m}^{\mathrm{T} }{\bf \Lambda}_{\mu}{\bf \mu} + const. \\
    &amp;=&amp; \frac{1}{2}{\bf \mu}^{\mathrm{T} } {\bf \Lambda}\Sigma_{n=1}^{N} {\bf x}_n + \frac{1}{2}{\bf \mu}^{\mathrm{T} } {\bf \Lambda}\Sigma_{n=1}^{N} {\bf x}_n - \frac{N}{2} {\bf \mu}^{\mathrm{T} }{\bf \Lambda}{\bf \mu} - \frac{1}{2} {\bf \mu}^{\mathrm{T} }{\bf \Lambda}_{\mu}{\bf \mu} + \frac{1}{2}{\bf \mu}^{\mathrm{T} }{\bf \Lambda}_{\mu}{\bf m} + + \frac{1}{2}{\bf \mu}^{\mathrm{T} }{\bf \Lambda}_{\mu}{\bf m} + const. \\
    &amp;=&amp; - \frac{1}{2}\{ {\bf \mu}^{\mathrm{T} } (N {\bf \Lambda}+{\bf \Lambda}_{\mu}){\bf \mu} - 2 {\bf \mu}^{\mathrm{T} }({\bf \Lambda} \Sigma_{n=1}^{N} {\bf x}_n + {\bf \Lambda}_{\mu} {\bf m})\} + const.
\end{eqnarray}
$$<p>${\bf \mu}$に関する上に凸の二次関数となり、ガウス分布であることがわかる。1次元と同様に逆算的に計算していく。</p>
<p>
$$p({\bf \mu}|{\bf X}) = \mathcal{N}({\bf \mu}|\hat{\bf m},\hat{\bf \Lambda}_{\bf \mu}^{-1})$$
</p>
<p>とおき、対数をとって${\bf \mu}$について整理すると</p>
$$
\begin{eqnarray}
    \ln p({\bf \mu}|{\bf X}) &amp;=&amp; -\frac{1}{2}\{({\bf \mu}-\hat{\bf m})^\mathrm{T} \hat{\bf \Lambda}_{\bf \mu} ({\bf \mu}-\hat{\bf m}) \} + const. \\
    &amp;=&amp; -\frac{1}{2} \{ {\bf \mu}^{\mathrm{T} } \hat{\bf \Lambda}_{\bf \mu} {\bf \mu} - \hat{\bf m}^{\mathrm{T} } \hat{\bf \Lambda}_{\bf \mu} {\bf \mu} - {\bf \mu}^{\mathrm{T} } \hat{\bf \Lambda}_{\bf \mu} \hat{\bf m} \} + const. \\
    &amp;=&amp; -\frac{1}{2} \{ {\bf \mu}^{\mathrm{T} } \hat{\bf \Lambda}_{\bf \mu} {\bf \mu}-2{\bf \mu}^{\mathrm{T} } \hat{\bf \Lambda}_{\bf \mu} \hat{\bf m} \} + const.
\end{eqnarray}
$$<p>対応関係を見れば</p>
$$
\begin{eqnarray}
    \hat{\bf \Lambda}_{\bf \mu} = N{\bf \Lambda}+{\bf \Lambda}_{\bf \mu} \\
    \hat{\bf m} = \hat{\bf \Lambda}_{\bf \mu}^{-1}({\bf \Lambda} \Sigma_{n=1}^{N} {\bf x}_n + {\bf \Lambda}_{\mu} {\bf m})
\end{eqnarray}
$$<p>と事後分布のハイパーパラメータが求まる。</p>
<h2 id="予測分布の導出">
<a class="anchor" href="#%E4%BA%88%E6%B8%AC%E5%88%86%E5%B8%83%E3%81%AE%E5%B0%8E%E5%87%BA" aria-hidden="true"><span class="octicon octicon-link"></span></a>予測分布の導出<a class="anchor-link" href="#%E4%BA%88%E6%B8%AC%E5%88%86%E5%B8%83%E3%81%AE%E5%B0%8E%E5%87%BA"> </a>
</h2>
<p>簡単のために学習前の事前分布を用いて予測分布を導出し、更新されたハイパーパラメータを代入することで学習後の予測分布を計算する。1次元の時と同様、ベイズの定理と対数化を利用し積分計算を避ける。</p>
<p>
$$\ln p({\bf x}_*) = \ln p({\bf x}_*|{\bf \mu}) - \ln p({\bf \mu}|{\bf x}_*) + const.$$
</p>
<p>$\ln p({\bf \mu}|{\bf x}_*)$は${\bf x}_*$を学習した後の事後分布と見なせるので、</p>
$$
\begin{eqnarray}
    p({\bf \mu}|{\bf x}_*) &amp;=&amp; \mathcal{N}({\bf \mu}|{\bf m}({\bf x}_*), ({\bf \Lambda}+{\bf \Lambda}_{\bf \mu})^{-1}) \\
    ただし　{\bf m}({\bf x}_*) &amp;=&amp; ({\bf \Lambda}+{\bf \Lambda}_{\bf \mu})^{-1} ({\bf \Lambda}{\bf x}_* + {\bf \Lambda}_{\bf \mu} {\bf m})
\end{eqnarray}
$$<p>したがって、</p>
$$
\begin{eqnarray}
    \ln p({\bf x}_*) &amp;=&amp; \ln p({\bf x}_*|{\bf \mu}) - \ln p({\bf \mu}|{\bf x}_*) + const. \\
    &amp;=&amp; -\frac{({\bf x}_*-{\bf \mu})^\mathrm{T}{\bf \Lambda}({\bf x}_*-{\bf \mu})}{2} + \frac{({\bf \mu}-{\bf m}({\bf x}_*))^\mathrm{T}({\bf \Lambda}+{\bf \Lambda}_{\mu})({\bf \mu}-{\bf m}({\bf x}_*))}{2} + const. \\
    &amp;=&amp; -\frac{1}{2}\{ {\bf x}_*^{\mathrm{T} }{\bf \Lambda}{\bf x}_* - {\bf x}_*^{\mathrm{T} }{\bf \Lambda}{\bf \mu} - {\bf \mu}^\mathrm{T}{\bf \Lambda}{\bf x}_* - {\bf m}({\bf x}_*)^\mathrm{T} ({\bf \Lambda}+{\bf \Lambda}_{\bf \mu}) {\bf m}({\bf x}_*) + {\bf m}({\bf x}_*)^\mathrm{T}({\bf \Lambda}+{\bf \Lambda}_{\bf \mu}){\bf \mu} + {\bf \mu}^\mathrm{T}({\bf \Lambda}+{\bf \Lambda}_{\bf \mu}){\bf m}({\bf x}_*) \} + const. \\
    &amp;=&amp; -\frac{1}{2}\{ {\bf x}_*^{\mathrm{T} }{\bf \Lambda}{\bf x}_* - 2 {\bf x}_*^{\mathrm{T} }{\bf \Lambda}{\bf \mu} - {\bf m}({\bf x}_*)^\mathrm{T} ({\bf \Lambda}+{\bf \Lambda}_{\bf \mu}) {\bf m}({\bf x}_*) + 2 {\bf \mu}^\mathrm{T}({\bf \Lambda}+{\bf \Lambda}_{\bf \mu}){\bf m}({\bf x}_*)\} + const. \\
    &amp;=&amp; -\frac{1}{2}\{ {\bf x}_*^{\mathrm{T} }{\bf \Lambda}{\bf x}_* - 2 {\bf x}_*^{\mathrm{T} }{\bf \Lambda}{\bf \mu} - {\bf m}({\bf x}_*)^\mathrm{T} ({\bf \Lambda}{\bf x}_* + {\bf \Lambda}_{\bf \mu}{\bf m}) + 2{\bf \mu}^\mathrm{T}{\bf \Lambda}{\bf x}_*\} + const. \\
    &amp;=&amp; -\frac{1}{2}\{ {\bf x}_*^{\mathrm{T} }{\bf \Lambda}{\bf x}_* - ({\bf \Lambda}{\bf x}_* + {\bf \Lambda}_{\bf \mu}{\bf m})^\mathrm{T} {\bf m}({\bf x}_*) \} + const.　({\bf m}({\bf x}_*)^\mathrm{T} ({\bf \Lambda}{\bf x}_* + {\bf \Lambda}_{\bf \mu}{\bf m})はスカラーなので転置しても変わらない) \\
    &amp;=&amp; -\frac{1}{2}\{ {\bf x}_*^{\mathrm{T} }{\bf \Lambda}{\bf x}_* - ({\bf \Lambda}{\bf x}_* + {\bf \Lambda}_{\bf \mu}{\bf m})^\mathrm{T} ({\bf \Lambda}+{\bf \Lambda}_{\bf \mu})^{-1} ({\bf \Lambda}{\bf x}_* + {\bf \Lambda}_{\bf \mu}{\bf m}) \} + const. \\
    &amp;=&amp; -\frac{1}{2}\{ {\bf x}_*^{\mathrm{T} }{\bf \Lambda}{\bf x}_* - ({\bf \Lambda}{\bf x}_*)^\mathrm{T}({\bf \Lambda}+{\bf \Lambda}_{\bf \mu})^{-1}{\bf \Lambda}{\bf x}_* - ({\bf \Lambda}{\bf x}_*)^\mathrm{T}({\bf \Lambda}+{\bf \Lambda}_{\bf \mu})^{-1}{\bf \Lambda}_{\bf \mu}{\bf m} - ({\bf \Lambda}_{\bf \mu}{\bf m})^\mathrm{T}({\bf \Lambda}+{\bf \Lambda}_{\bf \mu})^{-1}{\bf \Lambda}{\bf x}_*\} + const. \\
    &amp;=&amp; -\frac{1}{2}\{ {\bf x}_*^{\mathrm{T} }{\bf \Lambda}{\bf x}_* - {\bf x}_*^\mathrm{T}{\bf \Lambda}({\bf \Lambda}+{\bf \Lambda}_{\bf \mu})^{-1}{\bf \Lambda}{\bf x}_* - 2{\bf x}_*^\mathrm{T}{\bf \Lambda}({\bf \Lambda}+{\bf \Lambda}_{\bf \mu})^{-1}{\bf \Lambda}_{\bf \mu}{\bf m} \} + const. \\
    &amp;=&amp; -\frac{1}{2}\{ {\bf x}_*^{\mathrm{T} } ({\bf \Lambda}-{\bf \Lambda}({\bf \Lambda}+{\bf \Lambda}_{\bf \mu})^{-1}{\bf \Lambda}) {\bf x}_* - 2{\bf x}_*^\mathrm{T}{\bf \Lambda}({\bf \Lambda}+{\bf \Lambda}_{\bf \mu})^{-1}{\bf \Lambda}_{\bf \mu}{\bf m} \} + const.
\end{eqnarray}
$$<p>ここで</p>
$$
p({\bf x}_*) = \mathcal{N}({\bf x}_*|{\bf \mu}_*,{\bf \Lambda}_*^{-1})
$$<p>と書けるとすると</p>
$$
\ln p({\bf x}_*) = -\frac{1}{2} \{ {\bf x}_*^{\mathrm{T} } {\bf \Lambda}_{*} {\bf x}_* -2{\bf x}_*^{\mathrm{T} } {\bf \Lambda}_{*} {\bf \mu}_*\} + const.
$$<p>であるから、対応関係から</p>
$$
\begin{eqnarray}
    {\bf \Lambda}_* &amp;=&amp; {\bf \Lambda}-{\bf \Lambda}({\bf \Lambda}+{\bf \Lambda}_{\bf \mu})^{-1}{\bf \Lambda} \\
    {\bf \mu}_* &amp;=&amp; {\bf \Lambda}_*^{-1} {\bf \Lambda}({\bf \Lambda}+{\bf \Lambda}_{\bf \mu})^{-1}{\bf \Lambda}_{\bf \mu}{\bf m}
\end{eqnarray}
$$<p>ウッドベリーの公式を使うことで更に簡潔な形にできる。</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p></p>
<div class="flash flash-success">
    <svg class="octicon octicon-checklist octicon octicon-checklist" viewbox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M16 8.5l-6 6-3-3L8.5 10l1.5 1.5L14.5 7 16 8.5zM5.7 12.2l.8.8H2c-.55 0-1-.45-1-1V3c0-.55.45-1 1-1h7c.55 0 1 .45 1 1v6.5l-.8-.8c-.39-.39-1.03-.39-1.42 0L5.7 10.8a.996.996 0 000 1.41v-.01zM4 4h5V3H4v1zm0 2h5V5H4v1zm0 2h3V7H4v1zM3 9H2v1h1V9zm0-2H2v1h1V7zm0-2H2v1h1V5zm0-2H2v1h1V3z"></path></svg>
    <strong>Tip: </strong>ウッドベリーの公式 $$({\bf A}+{\bf U}{\bf B}{\bf V})^{-1} = {\bf A}^{-1} - {\bf A}^{-1}{\bf U}({\bf B}^{-1}+{\bf V}{\bf A}^{-1}{\bf U})^{-1}{\bf V}{\bf A}^{-1}$$
</div>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p></p>
<div class="flash flash-success">
    <svg class="octicon octicon-checklist octicon octicon-checklist octicon octicon-checklist" viewbox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M16 8.5l-6 6-3-3L8.5 10l1.5 1.5L14.5 7 16 8.5zM5.7 12.2l.8.8H2c-.55 0-1-.45-1-1V3c0-.55.45-1 1-1h7c.55 0 1 .45 1 1v6.5l-.8-.8c-.39-.39-1.03-.39-1.42 0L5.7 10.8a.996.996 0 000 1.41v-.01zM4 4h5V3H4v1zm0 2h5V5H4v1zm0 2h3V7H4v1zM3 9H2v1h1V9zm0-2H2v1h1V7zm0-2H2v1h1V5zm0-2H2v1h1V3z"></path></svg>
    <strong>Tip: </strong>ウッドベリーの公式(${\bf A},{\bf B}$の次元が等しく, ${\bf U},{\bf V}$が単位行列の場合) $$({\bf A}+{\bf B})^{-1} = {\bf A}^{-1} - {\bf A}^{-1}({\bf A}^{-1} + {\bf B}^{-1})^{-1} {\bf A}^{-1}$$
</div>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>${\bf \Lambda}_*$について、${\bf A}={\bf \Lambda}^{-1},{\bf B}={\bf \Lambda}_{\bf \mu}^{-1}$とおくと、</p>
$$
\begin{eqnarray}
    {\bf \Lambda}_* &amp;=&amp; {\bf \Lambda}-{\bf \Lambda}({\bf \Lambda}+{\bf \Lambda}_{\bf \mu})^{-1}{\bf \Lambda} \\
    &amp;=&amp; {\bf A}^{-1} - {\bf A}^{-1}({\bf A}^{-1} + {\bf B}^{-1})^{-1} {\bf A}^{-1} \\
    &amp;=&amp; ({\bf A}+{\bf B})^{-1} \\
    &amp;=&amp; ({\bf \Lambda}^{-1} + {\bf \Lambda}_{\mu}^{-1})^{-1}
\end{eqnarray}
$$<p>${\bf \mu}_*$は、${\bf \Lambda}_* = {\bf \Lambda}-{\bf \Lambda} ({\bf \Lambda}+{\bf \Lambda}_{\bf \mu})^{-1} {\bf \Lambda}$より</p>
$$
\begin{eqnarray}
    {\bf \Lambda}({\bf \Lambda}+{\bf \Lambda}_{\bf \mu})^{-1}{\bf \Lambda} &amp;=&amp; {\bf \Lambda} - {\bf \Lambda}_* \\
    {\bf \Lambda}({\bf \Lambda}+{\bf \Lambda}_{\bf \mu})^{-1} &amp;=&amp; ({\bf \Lambda} - {\bf \Lambda}_*){\bf \Lambda}^{-1}
\end{eqnarray}
$$<p>だから</p>
$$
\begin{eqnarray}
    {\bf \mu}_* &amp;=&amp; {\bf \Lambda}_*^{-1} {\bf \Lambda}({\bf \Lambda}+{\bf \Lambda}_{\bf \mu})^{-1}{\bf \Lambda}_{\bf \mu}{\bf m} \\
    &amp;=&amp; {\bf \Lambda}_*^{-1} ({\bf \Lambda} - {\bf \Lambda}_*){\bf \Lambda}^{-1}{\bf \Lambda}_{\bf \mu}{\bf m} \\
    &amp;=&amp; \{ {\bf \Lambda}_*^{-1}{\bf \Lambda}{\bf \Lambda}^{-1}{\bf \Lambda}_{\bf \mu} - {\bf \Lambda}_*^{-1}{\bf \Lambda}_* {\bf \Lambda}^{-1}{\bf \Lambda}_{\bf \mu} \}{\bf m} \\
    &amp;=&amp; \{ {\bf \Lambda}_*^{-1}{\bf \Lambda}_{\bf \mu} -  {\bf \Lambda}^{-1}{\bf \Lambda}_{\bf \mu} \}{\bf m} \\
    &amp;=&amp; \{ ({\bf \Lambda}^{-1} + {\bf \Lambda}_{\mu}^{-1}){\bf \Lambda}_{\bf \mu} -  {\bf \Lambda}^{-1}{\bf \Lambda}_{\bf \mu}\}{\bf m} \\
    &amp;=&amp; {\bf I}_D {\bf m} = {\bf m}
\end{eqnarray}
$$<p>まとめると、</p>
$$
\begin{eqnarray}
    {\bf \Lambda}_* &amp;=&amp; ({\bf \Lambda}^{-1} + {\bf \Lambda}_{\mu}^{-1})^{-1} \\
    {\bf \mu}_* &amp;=&amp; {\bf m}
\end{eqnarray}
$$<p>これらに、更新されたハイパーパラメータ$\hat{\bf m},\hat{\bf \Lambda}_{\bf \mu}$を代入して学習後の予測分布$p({\bf x}_*|{\bf X})$が求まる。</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h1 id="精度行列未知">
<a class="anchor" href="#%E7%B2%BE%E5%BA%A6%E8%A1%8C%E5%88%97%E6%9C%AA%E7%9F%A5" aria-hidden="true"><span class="octicon octicon-link"></span></a>精度行列未知<a class="anchor-link" href="#%E7%B2%BE%E5%BA%A6%E8%A1%8C%E5%88%97%E6%9C%AA%E7%9F%A5"> </a>
</h1>
<h2 id="モデルの構築">
<a class="anchor" href="#%E3%83%A2%E3%83%87%E3%83%AB%E3%81%AE%E6%A7%8B%E7%AF%89" aria-hidden="true"><span class="octicon octicon-link"></span></a>モデルの構築<a class="anchor-link" href="#%E3%83%A2%E3%83%87%E3%83%AB%E3%81%AE%E6%A7%8B%E7%AF%89"> </a>
</h2>
<p>多次元ガウス分布の精度行列は正定値行列である必要がある。$D \times D$の正定値行列を生成する確率分布にウィシャート分布がある。</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p></p>
<div class="flash flash-warn">
    <svg class="octicon octicon-zap octicon octicon-zap octicon octicon-zap octicon octicon-zap octicon octicon-zap octicon octicon-zap octicon octicon-zap octicon octicon-zap octicon octicon-zap octicon octicon-zap octicon octicon-zap octicon octicon-zap octicon octicon-zap octicon octicon-zap octicon octicon-zap" viewbox="0 0 10 16" version="1.1" width="10" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M10 7H6l3-7-9 9h4l-3 7 9-9z"></path></svg>
    <strong>Important: </strong>ウィシャート分布の確率密度関数 $$\mathcal{W}({\bf \Lambda}|\nu,{\bf W}) = C_\mathcal{W} (\nu, {\bf W})|{\bf \Lambda}|^{\frac{\nu-D-1}{2} } exp\{ -\frac{1}{2} Tr({\bf W}^{-1} {\bf \Lambda})\}$$
</div>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>$\nu$は自由度パラメータで、$\nu &gt; D - 1$を満たす必要がある。また、パラメータ${\bf W}$は$D \times D$の正定値行列である。$Tr()$はトレースといい、行列の対角成分の和をとる演算である。ウィシャート分布も対数化することで計算の見通しが良くなる。</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p></p>
<div class="flash flash-warn">
    <svg class="octicon octicon-zap octicon octicon-zap octicon octicon-zap octicon octicon-zap octicon octicon-zap octicon octicon-zap octicon octicon-zap octicon octicon-zap octicon octicon-zap octicon octicon-zap octicon octicon-zap octicon octicon-zap octicon octicon-zap octicon octicon-zap octicon octicon-zap octicon octicon-zap" viewbox="0 0 10 16" version="1.1" width="10" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M10 7H6l3-7-9 9h4l-3 7 9-9z"></path></svg>
    <strong>Important: </strong>ウィシャート分布の対数化 $$\ln \mathcal{W} ({\bf \Lambda}|\nu,{\bf W}) = \frac{\nu-D-1}{2} \ln |{\bf \Lambda}| - \frac{1}{2} Tr({\bf W}^{-1} {\bf \Lambda}) + \ln C_\mathcal{W} (\nu, {\bf W})$$
</div>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p></p>
<div class="flash flash-warn">
    <svg class="octicon octicon-zap octicon octicon-zap octicon octicon-zap octicon octicon-zap octicon octicon-zap octicon octicon-zap octicon octicon-zap octicon octicon-zap octicon octicon-zap octicon octicon-zap octicon octicon-zap octicon octicon-zap octicon octicon-zap octicon octicon-zap octicon octicon-zap octicon octicon-zap octicon octicon-zap" viewbox="0 0 10 16" version="1.1" width="10" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M10 7H6l3-7-9 9h4l-3 7 9-9z"></path></svg>
    <strong>Important: </strong>対数化された正規化項 $$\ln C_\mathcal{W} (\nu, {\bf W}) = - \frac{\nu}{2} \ln |{\bf W}| - \ln \frac{\nu D}{2} \ln 2 - \frac{D(D-1)}{4} \ln \pi - \Sigma_{d=1}^{D} \ln \Gamma(\frac{\nu+1+d}{2})$$
</div>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p></p>
<div class="flash flash-success">
    <svg class="octicon octicon-checklist octicon octicon-checklist octicon octicon-checklist octicon octicon-checklist" viewbox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M16 8.5l-6 6-3-3L8.5 10l1.5 1.5L14.5 7 16 8.5zM5.7 12.2l.8.8H2c-.55 0-1-.45-1-1V3c0-.55.45-1 1-1h7c.55 0 1 .45 1 1v6.5l-.8-.8c-.39-.39-1.03-.39-1.42 0L5.7 10.8a.996.996 0 000 1.41v-.01zM4 4h5V3H4v1zm0 2h5V5H4v1zm0 2h3V7H4v1zM3 9H2v1h1V9zm0-2H2v1h1V7zm0-2H2v1h1V5zm0-2H2v1h1V3z"></path></svg>
    <strong>Tip: </strong>トレースについて成り立つ等式 $$\begin{eqnarray} Tr({\bf A}) &amp;=&amp; Tr({\bf A}^\mathrm{T}) \\ Tr({\bf A} + {\bf B}) &amp;=&amp; Tr({\bf A}) + Tr({\bf B}) \\ Tr({\bf AB}) &amp;=&amp; Tr({\bf BA}) \end{eqnarray}$$
</div>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>さて、このウィシャート分布を用いてモデルを構築すると次のようになる。</p>
$$
\begin{eqnarray}
    p({\bf X},{\bf x}_*,{\bf \Lambda}) &amp;=&amp; p({\bf X}|{\bf \Lambda})p({\bf x}_*|{\bf \Lambda})p({\bf \Lambda}) \\
    p({\bf x}_*|{\bf \Lambda}) &amp;=&amp; \mathcal{N}({\bf x}_* |{\bf \mu}, {\bf \Lambda}^{-1}) \\
    p({\bf X}|{\bf \Lambda}) &amp;=&amp; \Pi_{n=1}^{N} \mathcal{N}({\bf x}_n |{\bf \mu}, {\bf \Lambda}^{-1}) \\
    p({\bf \Lambda}) &amp;=&amp; \mathcal{W}({\bf \Lambda}|\nu, {\bf W})
\end{eqnarray}
$$<h2 id="事後分布の推論">
<a class="anchor" href="#%E4%BA%8B%E5%BE%8C%E5%88%86%E5%B8%83%E3%81%AE%E6%8E%A8%E8%AB%96" aria-hidden="true"><span class="octicon octicon-link"></span></a>事後分布の推論<a class="anchor-link" href="#%E4%BA%8B%E5%BE%8C%E5%88%86%E5%B8%83%E3%81%AE%E6%8E%A8%E8%AB%96"> </a>
</h2>
<p>データ${\bf X}$を観測した後の事後分布は</p>
$$
p({\bf \Lambda}|{\bf X}) \propto p({\bf X}|{\bf \Lambda}) p({\bf \Lambda})
$$<p>ゆえ対数化すると</p>
$$
\begin{eqnarray}
    \ln p({\bf \Lambda}|{\bf X}) &amp;=&amp; \Sigma_{n=1}^{N} \ln \mathcal{N} ({\bf x}_n|{\bf \mu}, {\bf \Lambda}^{-1}) + \ln \mathcal{W}({\bf \Lambda} |\nu, {\bf W}) + const. \\
    &amp;=&amp; - \frac{1}{2} \{ \Sigma_{n=1}^{N} ({\bf x}_n-{\bf \mu})^\mathrm{T} {\bf \Lambda}({\bf x}_n-{\bf \mu}) -  N \ln |{\bf \Lambda}| \} + \frac{\nu-D-1}{2} \ln |{\bf \Lambda}| - \frac{1}{2} Tr({\bf W}^{-1} {\bf \Lambda}) + const. \\
    &amp;=&amp; \frac{N+\nu-D-1}{2} \ln |{\bf \Lambda}| - \frac{1}{2} \Sigma_{n=1}^{N} Tr \{ ({\bf x}_n-{\bf \mu})^\mathrm{T} {\bf \Lambda}({\bf x}_n-{\bf \mu}) \} - \frac{1}{2} Tr({\bf W}^{-1} {\bf \Lambda}) + const.　(スカラーのトレースをとっても同じ) \\
    &amp;=&amp; \frac{N+\nu-D-1}{2} \ln |{\bf \Lambda}| - \frac{1}{2} \Sigma_{n=1}^{N} Tr \{ ({\bf x}_n-{\bf \mu})({\bf x}_n-{\bf \mu})^\mathrm{T} {\bf \Lambda} \} - \frac{1}{2} Tr({\bf W}^{-1} {\bf \Lambda}) + const.　(トレース内では対角成分が同じであれば順番を入れ替えても問題ない) \\
    &amp;=&amp; \frac{N+\nu-D-1}{2} \ln |{\bf \Lambda}| - \frac{1}{2} Tr \left[ \{ \Sigma_{n=1}^{N} ({\bf x}_n-{\bf \mu})({\bf x}_n-{\bf \mu})^\mathrm{T} + {\bf W}^{-1} \} {\bf \Lambda} \right] + const.　(トレースの和は和のトレース)
\end{eqnarray}
$$<p>ウィシャート分布との対応を見れば、</p>
$$
\begin{eqnarray}
    p({\bf \Lambda}|{\bf X}) &amp;=&amp; \mathcal{W}({\bf \Lambda}|\hat{\nu}, \hat{\bf W}) \\
    ただし　\hat{\bf W}^{-1} &amp;=&amp; \Sigma_{n=1}^{N} ({\bf x}_n - {\bf \mu})({\bf x}_n - {\bf \mu})^\mathrm{T} + {\bf W}^{-1} \\
    \hat{\nu} &amp;=&amp; N + \nu
\end{eqnarray}
$$<p>となる。</p>
<h2 id="予測分布の導出">
<a class="anchor" href="#%E4%BA%88%E6%B8%AC%E5%88%86%E5%B8%83%E3%81%AE%E5%B0%8E%E5%87%BA" aria-hidden="true"><span class="octicon octicon-link"></span></a>予測分布の導出<a class="anchor-link" href="#%E4%BA%88%E6%B8%AC%E5%88%86%E5%B8%83%E3%81%AE%E5%B0%8E%E5%87%BA"> </a>
</h2>
<p>事前分布と事後分布の形が同じなので、表記がシンプルになるよう学習前のハイパーパラメータで予測分布を計算し、後で代入する。</p>
<p>積分計算を避け、ベイズの定理と対数を利用する。学習前の予測分布$p({\bf x}_*)$は、</p>
$$
\ln p({\bf x}_*) = \ln p({\bf x}_*|{\bf \Lambda}) - \ln p({\bf \Lambda}|{\bf x}_*) + const.
$$<p>と表せる。事後分布の結果を流用して</p>
$$
\begin{eqnarray}
    p({\bf \Lambda}|{\bf x}_*) &amp;=&amp; \mathcal{W}({\bf \Lambda}|1+\nu , {\bf W}({\bf x}_*)) \\
    ただし　{\bf W} ({\bf x}_*)^{-1} &amp;=&amp; ({\bf x}_* - {\bf \mu})({\bf x}_* - {\bf \mu})^\mathrm{T} + {\bf W}^{-1}
\end{eqnarray}
$$<p>よって</p>
$$
\begin{eqnarray}
    \ln p({\bf x}_*) &amp;=&amp; \ln p({\bf x}_*|{\bf \Lambda}) - \ln p({\bf \Lambda}|{\bf x}_*) + const. \\
    &amp;=&amp; -\frac{1}{2} \left[ ({\bf x}_* -{\bf \mu})^\mathrm{T} {\bf \Lambda} ({\bf x}_* -{\bf \mu}) - Tr \{ {\bf W}({\bf x}_*)^{-1}{\bf \Lambda} \} - (\nu + 1) \ln |{\bf W} ({\bf x}_*)| \right] + const.
\end{eqnarray}
$$<p>行列式、トレースの性質を使いながら計算を進める。</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p></p>
<div class="flash flash-success">
    <svg class="octicon octicon-checklist octicon octicon-checklist octicon octicon-checklist octicon octicon-checklist octicon octicon-checklist" viewbox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M16 8.5l-6 6-3-3L8.5 10l1.5 1.5L14.5 7 16 8.5zM5.7 12.2l.8.8H2c-.55 0-1-.45-1-1V3c0-.55.45-1 1-1h7c.55 0 1 .45 1 1v6.5l-.8-.8c-.39-.39-1.03-.39-1.42 0L5.7 10.8a.996.996 0 000 1.41v-.01zM4 4h5V3H4v1zm0 2h5V5H4v1zm0 2h3V7H4v1zM3 9H2v1h1V9zm0-2H2v1h1V7zm0-2H2v1h1V5zm0-2H2v1h1V3z"></path></svg>
    <strong>Tip: </strong>行列式の性質 $$\begin{eqnarray} |c{\bf A}| &amp;=&amp; c^N |{\bf A}| \\ |{\bf A}^\mathrm{T}| &amp;=&amp; |{\bf A}| \\ |{\bf A}{\bf B}| &amp;=&amp; |{\bf A}| |{\bf B}| \\ |{\bf A}^{-1}| &amp;=&amp; |{\bf A}|^{-1} \\ |{\bf I}_N + {\bf C} {\bf D}^\mathrm{T} | &amp;=&amp; |{\bf I}_M + {\bf C}^\mathrm{T} {\bf D}|　(この{\bf C}と{\bf D}はN \times M行列) \end{eqnarray}$$
</div>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
$$
\begin{eqnarray}
    \ln p({\bf x}_*) &amp;=&amp; -\frac{1}{2} \left[ Tr \{ ({\bf x}_* -{\bf \mu})^\mathrm{T} {\bf \Lambda} ({\bf x}_* -{\bf \mu})) \} - Tr \{ ({\bf x}_* - {\bf \mu})({\bf x}_* - {\bf \mu})^\mathrm{T} {\bf \Lambda}) \} + (\nu + 1) \ln |{\bf W} ({\bf x}_*)^{-1}| \right] + const. \\
    &amp;=&amp; - \frac{1+\nu}{2} \ln |({\bf x}_* - {\bf \mu})({\bf x}_* - {\bf \mu})^\mathrm{T} + {\bf W}^{-1}| + const. \\
    &amp;=&amp; - \frac{1+\nu}{2} \ln |{\bf W}^{-1} \{ {\bf W} ({\bf x}_* - {\bf \mu})({\bf x}_* - {\bf \mu})^\mathrm{T} + {\bf I}_D \}| + const. \\
    &amp;=&amp; - \frac{1+\nu}{2} \ln |{\bf W}^{-1}| |{\bf I}_D + {\bf W} ({\bf x}_* - {\bf \mu})({\bf x}_* - {\bf \mu})^\mathrm{T}| + const. \\
    &amp;=&amp; - \frac{1+\nu}{2} \ln |{\bf I}_D + {\bf W} ({\bf x}_* - {\bf \mu})({\bf x}_* - {\bf \mu})^\mathrm{T} | + const. \\
    &amp;=&amp; - \frac{1+\nu}{2} \ln |{\bf I}_1 + \{ {\bf W} ({\bf x}_* - {\bf \mu}) \}^\mathrm{T} ({\bf x}_* - {\bf \mu}) | + const.　(D \times 1行列になっている) \\
    &amp;=&amp; - \frac{1+\nu}{2} \ln \{ 1 + ({\bf x}_* - {\bf \mu})^\mathrm{T} {\bf W} ({\bf x}_* - {\bf \mu}) \} + const.
\end{eqnarray}
$$<p>これは多次元のStudentのt分布になっている。</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p></p>
<div class="flash flash-warn">
    <svg class="octicon octicon-zap octicon octicon-zap octicon octicon-zap octicon octicon-zap octicon octicon-zap octicon octicon-zap octicon octicon-zap octicon octicon-zap octicon octicon-zap octicon octicon-zap octicon octicon-zap octicon octicon-zap octicon octicon-zap octicon octicon-zap octicon octicon-zap octicon octicon-zap octicon octicon-zap octicon octicon-zap" viewbox="0 0 10 16" version="1.1" width="10" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M10 7H6l3-7-9 9h4l-3 7 9-9z"></path></svg>
    <strong>Important: </strong>多次元のStudentのt分布: $$St({\bf x} | {\bf \mu}_s , {\bf \Lambda}_s , \nu_s) = \frac{\Gamma(\frac{\nu_s + D}{2})}{\Gamma(\frac{\nu_s}{2})} \frac{|{\bf \Lambda}_s|^{\frac{1}{2} } } {(\pi \nu_s)^{\frac{D}{2} }} \left\{ 1 + \frac{1}{\nu_s} ({\bf x} - {\bf \mu}_s)^\mathrm{T} {\bf \Lambda}_s ({\bf x} - {\bf \mu}_s) \right\}^{- \frac{\nu_s + D}{2} }$$
</div>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>これを対数化して${\bf x}$に関わる項だけ抜き出すと、</p>
$$
\ln St({\bf x} | {\bf \mu}_s , {\bf \Lambda}_s , \nu_s) = - \frac{\nu_s + D}{2} \ln \left\{ 1 + \frac{1}{\nu_s} ({\bf x} - {\bf \mu}_s)^\mathrm{T} {\bf \Lambda}_s ({\bf x} - {\bf \mu}_s) \right\} + const.
$$<p>対応を見ると学習前の予測分布$p({\bf x}_*)$は次のように表せる。</p>
$$
\begin{eqnarray}
    p({\bf x}_*) &amp;=&amp; St({\bf x} | {\bf \mu}_s , {\bf \Lambda}_s , \nu_s) \\
    ただし　{\bf \mu}_s &amp;=&amp; {\bf \mu} \\
    {\bf \Lambda}_s &amp;=&amp; (1-D+\nu){\bf W} \\
    \nu_s &amp;=&amp; 1-D+\nu
\end{eqnarray}
$$<p>学習後の予測分布$p({\bf x}_* | {\bf X})$はこれに更新されたハイパーパラメータを代入することで求まる。</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h1 id="平均・精度行列未知">
<a class="anchor" href="#%E5%B9%B3%E5%9D%87%E3%83%BB%E7%B2%BE%E5%BA%A6%E8%A1%8C%E5%88%97%E6%9C%AA%E7%9F%A5" aria-hidden="true"><span class="octicon octicon-link"></span></a>平均・精度行列未知<a class="anchor-link" href="#%E5%B9%B3%E5%9D%87%E3%83%BB%E7%B2%BE%E5%BA%A6%E8%A1%8C%E5%88%97%E6%9C%AA%E7%9F%A5"> </a>
</h1>
<h2 id="モデル構築">
<a class="anchor" href="#%E3%83%A2%E3%83%87%E3%83%AB%E6%A7%8B%E7%AF%89" aria-hidden="true"><span class="octicon octicon-link"></span></a>モデル構築<a class="anchor-link" href="#%E3%83%A2%E3%83%87%E3%83%AB%E6%A7%8B%E7%AF%89"> </a>
</h2>
<p>平均パラメータの事前分布をガウス分布、精度パラメータの事前分布をウィシャート分布と別々に決めてもいいが、ガウス・ウィシャート分布が尤度関数がガウス分布の場合の共役事前分布として知られている。</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p></p>
<div class="flash flash-warn">
    <svg class="octicon octicon-zap octicon octicon-zap octicon octicon-zap octicon octicon-zap octicon octicon-zap octicon octicon-zap octicon octicon-zap octicon octicon-zap octicon octicon-zap octicon octicon-zap octicon octicon-zap octicon octicon-zap octicon octicon-zap octicon octicon-zap octicon octicon-zap octicon octicon-zap octicon octicon-zap octicon octicon-zap octicon octicon-zap" viewbox="0 0 10 16" version="1.1" width="10" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M10 7H6l3-7-9 9h4l-3 7 9-9z"></path></svg>
    <strong>Important: </strong>ガウス・ウィシャート分布 $$NW({\bf \mu}, {\bf \Lambda}|{\bf m},\beta,\nu,{\bf W}) = \mathcal{N}({\bf \mu}|{\bf m}, (\beta {\bf \Lambda})^{-1}) \mathcal{W} ({\bf \Lambda}|\nu, {\bf W})$$
</div>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>ガウス・ウィシャート分布を事前分布とした場合のモデルは次のようになる。</p>
$$
\begin{eqnarray}
    p({\bf X},{\bf x}_*,{\bf \mu}, {\bf \Lambda}) &amp;=&amp; p({\bf X}|{\bf \mu}, {\bf \Lambda})p({\bf x}_*|{\bf \mu}, {\bf \Lambda}) p({\bf \mu}) p({\bf \Lambda}) \\
    p({\bf \mu}, {\bf \Lambda}) &amp;=&amp; NW({\bf \mu}, {\bf \Lambda}|{\bf m},\beta,\nu,{\bf W})
\end{eqnarray}
$$
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="事後分布の推論">
<a class="anchor" href="#%E4%BA%8B%E5%BE%8C%E5%88%86%E5%B8%83%E3%81%AE%E6%8E%A8%E8%AB%96" aria-hidden="true"><span class="octicon octicon-link"></span></a>事後分布の推論<a class="anchor-link" href="#%E4%BA%8B%E5%BE%8C%E5%88%86%E5%B8%83%E3%81%AE%E6%8E%A8%E8%AB%96"> </a>
</h2>
<p>データ${\bf X}$を観測した後の事後分布を求める。</p>
$$
\begin{eqnarray}
    p({\bf \mu}, {\bf \Lambda}| {\bf X}) &amp;=&amp; \frac{p({\bf X}, {\bf \mu}, {\bf \Lambda})}{p({\bf X})} \\
    &amp;=&amp; \frac{p({\bf \mu}|{\bf \Lambda}, {\bf X}) p({\bf \Lambda}|{\bf X}) p({\bf X}) }{p({\bf X})} \\
    &amp;=&amp; p({\bf \mu}|{\bf \Lambda}, {\bf X}) p({\bf \Lambda}|{\bf X})
\end{eqnarray}
$$<p>1次元の場合と同様に、平均と精度の事後分布を別々に求めてみる。</p>
<h3 id="平均の事後分布">
<a class="anchor" href="#%E5%B9%B3%E5%9D%87%E3%81%AE%E4%BA%8B%E5%BE%8C%E5%88%86%E5%B8%83" aria-hidden="true"><span class="octicon octicon-link"></span></a>平均の事後分布<a class="anchor-link" href="#%E5%B9%B3%E5%9D%87%E3%81%AE%E4%BA%8B%E5%BE%8C%E5%88%86%E5%B8%83"> </a>
</h3>
<p>平均未知の場合の事後分布で精度行列を$\beta {\bf \Lambda}$とおくことにより求まる。</p>
$$
\begin{eqnarray}
    p({\bf \mu}|{\bf \Lambda}, {\bf X}) &amp;=&amp; \mathcal{N}({\bf \mu}|\hat{\bf m}, (\hat{\beta} {\bf \Lambda})^{-1}) \\
    ただし　\hat{\beta} &amp;=&amp; N + \beta \\
    \hat{\bf m} &amp;=&amp; \frac{1}{\hat{\beta}}(\Sigma_{n=1}^{N} {\bf x}_n + \beta {\bf m})
\end{eqnarray}
$$
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p></p>
<div class="flash">
    <svg class="octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info" viewbox="0 0 14 16" version="1.1" width="14" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M6.3 5.69a.942.942 0 01-.28-.7c0-.28.09-.52.28-.7.19-.18.42-.28.7-.28.28 0 .52.09.7.28.18.19.28.42.28.7 0 .28-.09.52-.28.7a1 1 0 01-.7.3c-.28 0-.52-.11-.7-.3zM8 7.99c-.02-.25-.11-.48-.31-.69-.2-.19-.42-.3-.69-.31H6c-.27.02-.48.13-.69.31-.2.2-.3.44-.31.69h1v3c.02.27.11.5.31.69.2.2.42.31.69.31h1c.27 0 .48-.11.69-.31.2-.19.3-.42.31-.69H8V7.98v.01zM7 2.3c-3.14 0-5.7 2.54-5.7 5.68 0 3.14 2.56 5.7 5.7 5.7s5.7-2.55 5.7-5.7c0-3.15-2.56-5.69-5.7-5.69v.01zM7 .98c3.86 0 7 3.14 7 7s-3.14 7-7 7-7-3.12-7-7 3.14-7 7-7z"></path></svg>
    <strong>Note: </strong>この部分の式変形 $$\begin{eqnarray} {\bf \Lambda}_{\bf \mu} &amp;=&amp; \beta {\bf \Lambda},　 \hat{\bf \Lambda}_{\bf \mu} = \hat{\beta} {\bf \Lambda}　とおいて平均未知の式を見れば、 \\ \hat{\beta} {\bf \Lambda} &amp;=&amp; N {\bf \Lambda} + \beta {\bf \Lambda}　ゆえ \\ \hat{\beta} &amp;=&amp; N + \beta \\ \hat{\bf m} &amp;=&amp; \frac{1}{\hat{\beta} } \hat{\bf \Lambda}^{-1} ({\bf \Lambda} \Sigma_{n=1}^{N} {\bf x}_n + \beta {\bf \Lambda} {\bf m}) \\ &amp;=&amp; \frac{1}{\hat{\beta} }(\Sigma_{n=1}^{N} {\bf x}_n + \beta {\bf m}) \end{eqnarray}$$
</div>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="精度の事後分布">
<a class="anchor" href="#%E7%B2%BE%E5%BA%A6%E3%81%AE%E4%BA%8B%E5%BE%8C%E5%88%86%E5%B8%83" aria-hidden="true"><span class="octicon octicon-link"></span></a>精度の事後分布<a class="anchor-link" href="#%E7%B2%BE%E5%BA%A6%E3%81%AE%E4%BA%8B%E5%BE%8C%E5%88%86%E5%B8%83"> </a>
</h3>
<p>ベイズの定理より、</p>
$$
p({\bf \mu}, {\bf \Lambda}| {\bf X}) = \frac{p({\bf X}|{\bf \mu}, {\bf \Lambda})p({\bf \mu},{\bf \Lambda})}{p({\bf X})}
$$<p>が成り立つので、</p>
$$
\begin{eqnarray}
    p({\bf \mu}|{\bf \Lambda}, {\bf X}) p({\bf \Lambda}|{\bf X}) &amp;=&amp; \frac{p({\bf X}|{\bf \mu}, {\bf \Lambda})p({\bf \mu},{\bf \Lambda})}{p({\bf X})} \\
    p({\bf \Lambda}|{\bf X}) &amp;=&amp; \frac{p({\bf X}|{\bf \mu}, {\bf \Lambda})p({\bf \mu},{\bf \Lambda})}{p({\bf X})p({\bf \mu}|{\bf \Lambda}, {\bf X})} \\
    \ln p({\bf \Lambda}|{\bf X}) &amp;=&amp; \ln p({\bf X}|{\bf \mu}, {\bf \Lambda}) + \ln p({\bf \mu},{\bf \Lambda}) - \ln p({\bf \mu}|{\bf \Lambda}, {\bf X}) + const. \\
    &amp;=&amp; \Sigma_{n=1}^{N} \ln \mathcal{N}({\bf x}_n|{\bf \mu}, {\bf \Lambda}^{-1}) + \ln NW({\bf \mu}, {\bf \Lambda}|{\bf m},\beta,\nu,{\bf W}) - \ln \mathcal{N}({\bf \mu}|\hat{\bf m}, (\hat{\beta} {\bf \Lambda})^{-1}) + const. \\
    &amp;=&amp; \Sigma_{n=1}^{N} \ln \mathcal{N}({\bf x}_n|{\bf \mu}, {\bf \Lambda}^{-1}) + \ln \mathcal{N}({\bf \mu}|{\bf m}, (\beta {\bf \Lambda})^{-1}) + \ln \mathcal{W} ({\bf \Lambda}|\nu, {\bf W}) - \ln \mathcal{N}({\bf \mu}|\hat{\bf m}, (\hat{\beta} {\bf \Lambda})^{-1}) + const. \\
    &amp;=&amp; - \frac{1}{2} \{ \Sigma_{n=1}^{N} ({\bf x}_n - {\bf \mu})^\mathrm{T} {\bf \Lambda} ({\bf x}_n - {\bf \mu}) - N \ln |{\bf \Lambda}| \} - \frac{\beta}{2} ({\bf \mu} - {\bf m})^\mathrm{T} {\bf \Lambda} ({\bf \mu} - {\bf m}) + \frac{1}{2} \ln |\beta {\bf \Lambda}| + \frac{\nu-D-1}{2} \ln |{\bf \Lambda}| - \frac{1}{2} Tr({\bf W}^\mathrm{T} {\bf \Lambda}) + \frac{\hat{\beta}}{2} ({\bf \mu} - \hat{\bf m})^\mathrm{T} {\bf \Lambda} ({\bf \mu} - \hat{\bf m}) - \frac{1}{2} \ln |\hat{\beta} {\bf \Lambda}| + const. \\
    &amp;=&amp; - \frac{1}{2} \{ \Sigma_{n=1}^{N} ({\bf x}_n - {\bf \mu})^\mathrm{T} {\bf \Lambda} ({\bf x}_n - {\bf \mu}) - N \ln |{\bf \Lambda}| \} - \frac{\beta}{2} ({\bf \mu} - {\bf m})^\mathrm{T} {\bf \Lambda} ({\bf \mu} - {\bf m}) + \frac{1}{2} \ln |{\bf \Lambda}| + \frac{\nu-D-1}{2} \ln |{\bf \Lambda}| - \frac{1}{2} Tr({\bf W}^{-1} {\bf \Lambda}) + \frac{\hat{\beta}}{2} ({\bf \mu} - \hat{\bf m})^\mathrm{T} {\bf \Lambda} ({\bf \mu} - \hat{\bf m}) - \frac{1}{2} \ln |{\bf \Lambda}| + const.　(|\beta {\bf \Lambda}|=\beta^{D} |{\bf \Lambda}|だが対数を取っているのでconst.に吸収させている。) \\
    &amp;=&amp; \frac{N+\nu-D-1}{2} \ln |{\bf \Lambda}| - \frac{1}{2} Tr \left[ \{ \Sigma_{n=1}^{N} {\bf x}_n {\bf x}_n^\mathrm{T} + \beta {\bf m} {\bf m}^\mathrm{T} - \hat{\beta} \hat{\bf m} \hat{\bf m}^\mathrm{T} + {\bf W}^{-1} \} {\bf \Lambda} \right] + const.　(スカラーはトレースを取ってまとめた)
\end{eqnarray}
$$<p>と整理できる。これをウィシャート分布の定義式と対応関係を取って</p>
$$
\begin{eqnarray}
    p({\bf \Lambda}|{\bf X}) &amp;=&amp; \mathcal{W}({\bf \Lambda}|\hat{\nu},\hat{\bf W}) \\
    ただし　\hat{\bf W}^{-1} &amp;=&amp; \Sigma_{n=1}^{N} {\bf x}_n {\bf x}_n^\mathrm{T} + \beta {\bf m} {\bf m}^\mathrm{T} - \hat{\beta} \hat{\bf m} \hat{\bf m}^\mathrm{T} + {\bf W}^{-1} \\
    \hat{\nu} &amp;=&amp; N + \nu
\end{eqnarray}
$$<h3 id="事後分布をまとめる">
<a class="anchor" href="#%E4%BA%8B%E5%BE%8C%E5%88%86%E5%B8%83%E3%82%92%E3%81%BE%E3%81%A8%E3%82%81%E3%82%8B" aria-hidden="true"><span class="octicon octicon-link"></span></a>事後分布をまとめる<a class="anchor-link" href="#%E4%BA%8B%E5%BE%8C%E5%88%86%E5%B8%83%E3%82%92%E3%81%BE%E3%81%A8%E3%82%81%E3%82%8B"> </a>
</h3>
<p>以上をまとめて事後分布は次のようになる。</p>
$$
\begin{eqnarray}
    p({\bf \mu}, {\bf \Lambda}|{\bf X}) &amp;=&amp; NW({\bf \mu}, {\bf \Lambda}| \hat{\bf m}, \hat{\beta}, \hat{\nu}, \hat{\bf W}) \\
    ただし　\hat{\beta} &amp;=&amp; N + \beta \\
    \hat{\bf m} &amp;=&amp; \frac{1}{\hat{\beta}}(\Sigma_{n=1}^{N} {\bf x}_n + \beta {\bf m}) \\
    ただし　\hat{\bf W}^{-1} &amp;=&amp; \Sigma_{n=1}^{N} {\bf x}_n {\bf x}_n^\mathrm{T} + \beta {\bf m} {\bf m}^\mathrm{T} - \hat{\beta} \hat{\bf m} \hat{\bf m}^\mathrm{T} + {\bf W}^{-1} \\
    \hat{\nu} &amp;=&amp; N + \nu
\end{eqnarray}
$$
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="予測分布の導出">
<a class="anchor" href="#%E4%BA%88%E6%B8%AC%E5%88%86%E5%B8%83%E3%81%AE%E5%B0%8E%E5%87%BA" aria-hidden="true"><span class="octicon octicon-link"></span></a>予測分布の導出<a class="anchor-link" href="#%E4%BA%88%E6%B8%AC%E5%88%86%E5%B8%83%E3%81%AE%E5%B0%8E%E5%87%BA"> </a>
</h2>
<p>今回も積分による導出を避けベイズの定理と対数で予測分布を導出する。また、記述がシンプルになるので事前分布を用いた予測分布を導出し後で更新されたハイパーパラメータを代入する。</p>
<p>ベイズの定理により、予測分布$p({\bf x}_*)$は次のように表せる。</p>
$$
\ln p({\bf x}_*) = \ln p({\bf x}_*|{\bf \mu}, {\bf \Lambda}) - \ln p({\bf \mu}, {\bf \Lambda}|{\bf x}_*) + const.
$$<p>$\ln p({\bf \mu}, {\bf \Lambda}|{\bf x}_*)$は事後分布の計算結果を流用して</p>
$$
\begin{eqnarray}
    p({\bf \mu}, {\bf \Lambda}|{\bf x}_*) &amp;=&amp; \mathcal{N}({\bf \mu}|{\bf m}({\bf x}_*), ((1+\beta){\bf \Lambda})^{-1}) \mathcal{W} ({\bf \Lambda}|1+\nu,{\bf W}({\bf x}_*)) \\
    ただし　{\bf m}({\bf x}_*) &amp;=&amp; \frac{ {\bf x}_* + \beta {\bf m} }{1+\beta} \\
    {\bf W}({\bf x}_*)^{-1} &amp;=&amp; \frac{\beta}{1+\beta} ({\bf x}_* - {\bf m})({\bf x}_* - {\bf m})^\mathrm{T} + {\bf W}^{-1}
\end{eqnarray}
$$
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p></p>
<div class="flash">
    <svg class="octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info" viewbox="0 0 14 16" version="1.1" width="14" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M6.3 5.69a.942.942 0 01-.28-.7c0-.28.09-.52.28-.7.19-.18.42-.28.7-.28.28 0 .52.09.7.28.18.19.28.42.28.7 0 .28-.09.52-.28.7a1 1 0 01-.7.3c-.28 0-.52-.11-.7-.3zM8 7.99c-.02-.25-.11-.48-.31-.69-.2-.19-.42-.3-.69-.31H6c-.27.02-.48.13-.69.31-.2.2-.3.44-.31.69h1v3c.02.27.11.5.31.69.2.2.42.31.69.31h1c.27 0 .48-.11.69-.31.2-.19.3-.42.31-.69H8V7.98v.01zM7 2.3c-3.14 0-5.7 2.54-5.7 5.68 0 3.14 2.56 5.7 5.7 5.7s5.7-2.55 5.7-5.7c0-3.15-2.56-5.69-5.7-5.69v.01zM7 .98c3.86 0 7 3.14 7 7s-3.14 7-7 7-7-3.12-7-7 3.14-7 7-7z"></path></svg>
    <strong>Note: </strong>${\bf W}({\bf x}_*)$の導出。 $$\begin{eqnarray} \\ {\bf W}({\bf x}_*)^{-1} &amp;=&amp; {\bf x}_* {\bf x}_*^\mathrm{T} + \beta {\bf m}{\bf m}^\mathrm{T} - (1+\beta) {\bf m}({\bf x}_*) {\bf m}({\bf x}_*)^\mathrm{T} + {\bf W}^{-1} \\ &amp;=&amp; {\bf x}_* {\bf x}_*^\mathrm{T} + \beta {\bf m}{\bf m}^\mathrm{T} - \frac{1}{1+\beta} ({\bf x}_* + \beta {\bf m}) ({\bf x}_* + \beta {\bf m})^\mathrm{T} + {\bf W}^{-1} \\ &amp;=&amp; (1-\frac{1}{1+\beta}){\bf x}_* {\bf x}_*^\mathrm{T} - \frac{\beta}{1+\beta} {\bf x}_* {\bf m}^\mathrm{T} - \frac{\beta}{1+\beta} {\bf x}_*^\mathrm{T} {\bf m} + (\beta - \frac{\beta^2}{1+\beta}) {\bf m} {\bf m}^\mathrm{T} + {\bf W}^{-1} \\ &amp;=&amp; \frac{\beta}{1+\beta} ({\bf x}_* - {\bf m})({\bf x}_* - {\bf m})^\mathrm{T} + {\bf W}^{-1} \\ \end{eqnarray}$$
</div>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>これを使って計算する。</p>
$$
\begin{eqnarray}
    \ln p({\bf x}_*) &amp;=&amp; \ln p({\bf x}_*|{\bf \mu}, {\bf \Lambda}) - \ln p({\bf \mu}, {\bf \Lambda}|{\bf x}_*) + const. \\
    &amp;=&amp; \ln \mathcal{N} ({\bf x}_*|{\bf \mu}, {\bf \Lambda}^{-1}) - \ln \mathcal{N}({\bf \mu}|{\bf m}({\bf x}_*), ((1+\beta){\bf \Lambda})^{-1}) - \ln \mathcal{W} ({\bf \Lambda}|1+\nu,{\bf W}({\bf x}_*)) + const. \\
    &amp;=&amp; -\frac{1}{2} ({\bf x}_* - {\bf \mu})^\mathrm{T} {\bf \Lambda} ({\bf x}_* - {\bf \mu}) + \frac{1+\beta}{2} ({\bf \mu}-{\bf m}({\bf x}_*))^\mathrm{T} {\bf \Lambda} ({\bf \mu}-{\bf m}({\bf x}_*)) + \frac{1}{2} Tr({\bf W}({\bf x}_*)^{-1} {\bf \Lambda}) + \frac{1+\nu}{2} \ln |{\bf W}({\bf x}_*)| + cosnt. \\
    &amp;=&amp; - \frac{1}{2} Tr \left[ \{ ({\bf x}_* - {\bf \mu})({\bf x}_* - {\bf \mu})^\mathrm{T} - (1+\beta) ({\bf \mu}-{\bf m}({\bf x}_*)) ({\bf \mu}-{\bf m}({\bf x}_*))^\mathrm{T} - {\bf W}({\bf x}_*)^{-1} \} {\bf \Lambda} \right] - \frac{1+\nu}{2} \ln |{\bf W}({\bf x}_*)^{-1}|
\end{eqnarray}
$$<p>トレースの計算。和のトレースはトレースの和であることを利用し、${\bf x}_*$に関わらない部分はconst.にまとめる。</p>
$$
\begin{eqnarray}
    トレース部分 &amp;=&amp; Tr \left[ \{ ({\bf x}_* - {\bf \mu})({\bf x}_* - {\bf \mu})^\mathrm{T} - (1+\beta) ({\bf \mu}-{\bf m}({\bf x}_*)) ({\bf \mu}-{\bf m}({\bf x}_*))^\mathrm{T} - {\bf W}({\bf x}_*)^{-1} \} {\bf \Lambda} \right] \\
    &amp;=&amp; Tr \left[ \{ {\bf x}_* {\bf x}_*^\mathrm{T} - {\bf \mu} {\bf x}_*^\mathrm{T} - {\bf x}_* {\bf \mu}^\mathrm{T} + (1+\beta) {\bf \mu} {\bf m}({\bf x}_*)^\mathrm{T} + (1+\beta) {\bf m}({\bf x}_*) {\bf \mu}^\mathrm{T} - (1+\beta) {\bf m}({\bf x}_*) {\bf m}({\bf x}_*)^\mathrm{T} - \frac{\beta}{1+\beta} {\bf x}_* {\bf x}_*^\mathrm{T} + \frac{\beta}{1+\beta} {\bf m} {\bf x}_*^\mathrm{T} + \frac{\beta}{1+\beta} {\bf x}_* {\bf m}^\mathrm{T}  \} {\bf \Lambda} \right] + cosnt. \\
    &amp;=&amp; Tr \left[ \{ {\bf x}_* {\bf x}_*^\mathrm{T} - {\bf \mu} {\bf x}_*^\mathrm{T} - {\bf x}_* {\bf \mu}^\mathrm{T} + {\bf \mu} {\bf x}_*^\mathrm{T} + {\bf x}_* {\bf \mu}^\mathrm{T} - \frac{1}{1+\beta}({\bf x}_* + \beta {\bf m})({\bf x}_*^\mathrm{T} + \beta {\bf m}^\mathrm{T}) -  \frac{\beta}{1+\beta} {\bf x}_* {\bf x}_*^\mathrm{T} + \frac{\beta}{1+\beta} {\bf m} {\bf x}_*^\mathrm{T} + \frac{\beta}{1+\beta} {\bf x}_* {\bf m}^\mathrm{T} \} {\bf \Lambda} \right] + cosnt. \\
    &amp;=&amp; const.
\end{eqnarray}
$$<p>結局${\bf x}_*$に関わる部分は消えてしまう。</p>
$$
\begin{eqnarray}
    \ln p({\bf x}_*) &amp;=&amp; - \frac{1+\nu}{2} \ln |{\bf W}({\bf x}_*)^{-1}| + const. \\
    &amp;=&amp; - \frac{1+\nu}{2} \ln |\frac{\beta}{1+\beta} ({\bf x}_* - {\bf m})({\bf x}_* - {\bf m})^\mathrm{T} + {\bf W}^{-1}| + const. \\
    &amp;=&amp; - \frac{1+\nu}{2} \ln \{ 1 + \frac{\beta}{1+\beta} ({\bf x}_* - {\bf m})^\mathrm{T} {\bf W} ({\bf x}_* - {\bf m}) \} + const.　(精度未知の時と同様に式変形を行った。)
\end{eqnarray}
$$<p>これは多次元のStudentのt分布の対数表現である。対応をとって</p>
$$
\begin{eqnarray}
    p({\bf x}_*) &amp;=&amp; St({\bf x}_* | {\bf \mu}_s, {\bf \Lambda}_s, \nu_s) \\
    ただし　{\bf \mu}_s &amp;=&amp; {\bf m} \\
    {\bf \Lambda}_s &amp;=&amp; \frac{(1-D+\nu)\beta}{1+\beta} {\bf W} \\
    \nu_s &amp;=&amp; 1 - D + \nu
\end{eqnarray}
$$<p>となる。学習後の予測分布は更新されたハイパーパラメータを代入することで求まる。</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p></p>
<div class="footnotes"><p id="fn-1">1. <a href="https://www.kspub.co.jp/book/detail/1538320.html">須山敦志. 杉山将. ベイズ推論による機械学習入門. 講談社, 2017.</a><a href="#fnref-1" class="footnote footnotes">↩</a></p></div>

</div>
</div>
</div>
</div>



  </div><!-- from https://github.com/utterance/utterances -->
<script src="https://utteranc.es/client.js"
        repo="Vintea01/tpt-medical-it"
        issue-term="title"
        label="blogpost-comment"
        theme="github-light"
        crossorigin="anonymous"
        async>
</script><a class="u-url" href="/tpt-medical-it/bayes/2020/04/06/bayes-part4.ipynb.html" hidden></a>
</article>
      </div>
    </main><footer class="site-footer h-card">
  <data class="u-url" href="/tpt-medical-it/"></data>

  <div class="wrapper">

    <div class="footer-col-wrapper">
      <div class="footer-col">
        <p class="feed-subscribe">
          <a href="/tpt-medical-it/feed.xml">
            <svg class="svg-icon orange">
              <use xlink:href="/tpt-medical-it/assets/minima-social-icons.svg#rss"></use>
            </svg><span>Subscribe</span>
          </a>
        </p>
      </div>
      <div class="footer-col">
        <p>Medical/Dental students playing with Information Technologies and Mathematics.</p>
      </div>
    </div>

    <div class="social-links"><ul class="social-media-list"><li><a rel="me" href="https://github.com/Vintea01" title="Vintea01"><svg class="svg-icon grey"><use xlink:href="/tpt-medical-it/assets/minima-social-icons.svg#github"></use></svg></a></li><li><a rel="me" href="https://twitter.com/tpt_ochanomizu" title="tpt_ochanomizu"><svg class="svg-icon grey"><use xlink:href="/tpt-medical-it/assets/minima-social-icons.svg#twitter"></use></svg></a></li></ul>
</div>

  </div>

</footer>
</body>

</html>
